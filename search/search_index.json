{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":"<p> VisionAI Toolkit for Workplace Safety https://docs.visionify.ai </p> <p> </p> <p>VisionAI is an enterprise-grade Computer Vision platform for Workplace Safety by Visionify. This guide provides comprehensive overview to deploy &amp; use VisionAI Solution in your organization.</p> \ud83d\ude80 Quick Start <p>Deploy VisionAI in your environment in under 15 minutes.</p> Get Started \u2192 \ud83d\udca1 Use Cases <p>Explore real-world applications and success stories.</p> Learn More \u2192 \ud83d\udd12 Security &amp; Privacy <p>Enterprise-grade security and compliance features.</p> View Details \u2192 \ud83c\udfa5 Camera Setup <p>Guidelines for optimal camera placement and configuration.</p> Camera Setup Guide \u2192 \ud83c\udfaf Deployment Options <p>Cloud, Hybrid &amp; Enterprise deployment options.</p> Deployment Options \u2192 \ud83d\udee0\ufe0f Troubleshooting <p>Common camera, configuration &amp; dashboard issues and solutions.</p> Troubleshooting Guide \u2192"},{"location":"#featured-use-cases","title":"Featured Use Cases","text":"PPE Compliance Area Controls Forklift Safety Emergency Events"},{"location":"#user-guides","title":"User Guides","text":"Camera Placement Guide <p>How to configure your cameras for optimal performance.</p> Learn More \u2192 Deployment Options <p>Learn about cloud, hybrid &amp; enterprise deployment options.</p> Learn More \u2192 Security &amp; Privacy <p>Enterprise-grade security with SOC-2 Type 2 compliance.</p> Learn More \u2192"},{"location":"#next-steps","title":"Next Steps","text":"<ul> <li>Quick Start</li> <li>Camera Placement Guide</li> <li>Supported Scenarios</li> <li>Camera Management</li> <li>FAQs</li> </ul>"},{"location":"#contact-information","title":"Contact Information","text":"contact_phone Sales Inquiries <p>Get in touch with our sales team for demos and pricing information.</p> <ul> <li>Email: sales@visionify.ai</li> <li>Phone: +1 720-449-1124</li> </ul> support_agent Technical Support <p>Need help? Visit our support portal or contact our technical team.</p> <ul> <li>https://support.visionify.ai</li> <li>support@visionify.ai</li> </ul> calendar_month Schedule a Demo <p>See VisionAI in action with a personalized demo from our team.</p> event                 Book Your Demo              arrow_upward"},{"location":"company/about/","title":"About Us","text":"<p>Based in Denver, CO, Visionify develops advanced Computer Vision solutions for Workplace Safety and Compliance, with a specialized focus on enhancing safety in Manufacturing Operations.</p> Safety Reimagined         At Visionify, we are dedicated to transforming Environmental, Health, and Safety (EHS) standards through our powerful Vision AI applications. Our Vision AI suite offers workplace safety and compliance solutions that are designed to detect potential hazards, monitor worker safety and prevent accidents. These ready-to-use, pre-trained apps, purpose-built for manufacturing environments, can be easily accessed through a user-friendly web-based interface.       What We Do  We help companies establish a Proactive Safety Culture         We help companies establish a robust safety culture with our Workplace Safety Platform. Our solutions provide real-time hazard detection and automated alerts to proactively prevent incidents and ensure compliance with safety regulations. Our out-of-box solutions integrate seamlessly with existing systems to monitor workplace safety continuously. With Visionify, organizations can enhance operational safety, reduce risks, and maintain regulatory compliance efficiently.       Our Mission          Visionify aims to provide the most advanced computer vision solutions that enhance workplace safety and compliance. We are committed to helping businesses of all sizes create a safe and compliant working environment by leveraging the power of computer vision technology. Through our innovative solutions, we strive to reduce workplace accidents and injuries, improve compliance with safety regulations, and increase overall productivity.       Our Vision          Visionify aspires to be a leading expert in computer vision solutions for workplace safety and compliance. We strive to create safer, healthier and compliant workplaces through the power of innovative technology and offer seamless interactive experiences. We envision a future where workplace safety and compliance are top priorities for businesses, and we are dedicated to driving this cultural shift by upholding excellence, integrity, and progressive innovation."},{"location":"company/about/#contact-information","title":"Contact Information","text":"contact_phone Sales Inquiries <p>Get in touch with our sales team for demos and pricing information.</p> <ul> <li>Email: sales@visionify.ai</li> <li>Phone: +1 720-449-1124</li> </ul> support_agent Technical Support <p>Need help? Visit our support portal or contact our technical team.</p> <ul> <li>https://support.visionify.ai</li> <li>support@visionify.ai</li> </ul> calendar_month Schedule a Demo <p>See VisionAI in action with a personalized demo from our team.</p> event                 Book Your Demo"},{"location":"company/careers/","title":"Careers","text":""},{"location":"company/careers/#innovation-drives-success-at-visionify","title":"Innovation drives success at Visionify","text":"<p>At Visionify, we are passionate about the products we make. That's why our team is always thinking of how to make them better. We love our careers at Visionify. Join us!</p>"},{"location":"company/careers/#open-positions","title":"Open Positions","text":"Computer Vision &amp; AI Engineer <p>Join our team to develop cutting-edge computer vision solutions for workplace safety. You'll work on creating and implementing AI models that help prevent accidents and save lives.</p> Apply Now Python Software Engineer <p>Help build robust backend systems and APIs that power our AI solutions. You'll be working with modern Python frameworks and contributing to our core platform development.</p> Apply Now Full Stack Engineer <p>Create seamless user experiences by developing both frontend and backend components. You'll work on our web applications and help improve our product interface.</p> Apply Now"},{"location":"company/careers/#why-visionify","title":"Why Visionify?","text":"Startup Culture <p>Get to wear multiple hats and receive high rewards in terms of stock options benefits.</p> Engaging Projects <p>Work on cutting edge computer vision and AI models that push the boundaries of technology.</p> Good Cause <p>Any single life we save, we will remember it. It's not just about money.</p> Continuous Growth <p>Switch between different roles in the organization &amp; contribute where you feel is important.</p> Intense Work Culture <p>Every day is an adventure. Be part of an exciting journey.</p>"},{"location":"company/careers/#how-to-apply","title":"How to Apply","text":"<ul> <li>Ready to join our team? Send your resume to hr@visionify.ai</li> <li>We look forward to hearing from you!</li> </ul>"},{"location":"company/careers/#contact-information","title":"Contact Information","text":"contact_phone Sales Inquiries <p>Get in touch with our sales team for demos and pricing information.</p> <ul> <li>Email: sales@visionify.ai</li> <li>Phone: +1 720-449-1124</li> </ul> support_agent Technical Support <p>Need help? Visit our support portal or contact our technical team.</p> <ul> <li>https://support.visionify.ai</li> <li>support@visionify.ai</li> </ul> calendar_month Schedule a Demo <p>See VisionAI in action with a personalized demo from our team.</p> event                 Book Your Demo"},{"location":"company/contact/","title":"Contact","text":"contact_phone Sales Inquiries <p>Get in touch with our sales team for demos and pricing information.</p> <ul> <li>Email: sales@visionify.ai</li> <li>Phone: +1 720-449-1124</li> </ul> support_agent Technical Support <p>Need help? Visit our support portal or contact our technical team.</p> <ul> <li>https://support.visionify.ai</li> <li>support@visionify.ai</li> </ul> calendar_month Schedule a Demo <p>See VisionAI in action with a personalized demo from our team.</p> event                 Book Your Demo"},{"location":"company/privacy-policy/","title":"Visionify Privacy Policy","text":"<p>Last Updated: Sep 4, 2024</p> <p>Visionify Inc. (\"we,\" \"us,\" or \"our\") is committed to protecting the privacy and security of personal information. This Privacy Policy outlines our practices regarding the collection, use, and protection of information collected from users of our VisionAI Workplace Safety Solutions (the \"Services\") and visitors to our website.</p>"},{"location":"company/privacy-policy/#1-information-we-collect","title":"1. Information We Collect","text":"<p>We collect data necessary to provide our Services effectively. The types of information we collect include:</p> <ul> <li> <p>Video Data: Our Services use CCTV and other surveillance footage from customer sites to train and improve our workplace safety models. This data is processed solely for safety monitoring, compliance, and model training purposes and does not include any personally identifiable information (PII).</p> </li> <li> <p>Usage Data: We collect non-personal information, such as device information, IP addresses, and interaction data, to monitor system performance and improve our Services. This data is collected in aggregate and does not identify individual users.</p> </li> <li> <p>Contact Information: When you contact us through our website, we may collect your name, email address, phone number, and other contact details to respond to your inquiries and provide support.</p> </li> </ul>"},{"location":"company/privacy-policy/#2-how-we-use-information","title":"2. How We Use Information","text":"<p>We use the information collected for the following purposes:</p> <ul> <li> <p>To Provide and Enhance Services: Video data is processed to improve safety analytics, detect workplace hazards, and train our models to become more accurate and reliable.</p> </li> <li> <p>To Improve System Performance: Usage data allows us to monitor system health, troubleshoot issues, and improve overall performance.</p> </li> <li> <p>To Communicate with You: Contact information is used to respond to inquiries, provide support, and keep you informed about updates, new features, or changes to our Services.</p> </li> </ul>"},{"location":"company/privacy-policy/#3-data-sharing-and-disclosure","title":"3. Data Sharing and Disclosure","text":"<p>Visionify does not share any personal information or video data with third parties except in the following situations:</p> <ul> <li> <p>With Customer Authorization: We may share video data with authorized customer representatives for monitoring and compliance purposes.</p> </li> <li> <p>With Sub-processors: We engage third-party service providers (e.g., cloud storage providers) to perform certain functions on our behalf. These providers only have access to video data as required to perform their services and are obligated to maintain confidentiality.</p> </li> <li> <p>For Legal Compliance: We may disclose information to comply with legal requirements, respond to lawful requests, or protect our rights and property.</p> </li> </ul>"},{"location":"company/privacy-policy/#4-data-retention-and-deletion","title":"4. Data Retention and Deletion","text":"<ul> <li> <p>Video Data: We retain video data collected from customer sites only for the duration required for processing and model training. Video data is anonymized and stored without any PII, ensuring that individual identities cannot be determined.</p> </li> <li> <p>Usage Data: Usage data is stored for as long as necessary to maintain system performance and improve our Services.</p> </li> <li> <p>Contact Information: Contact information is retained as long as needed to respond to inquiries or fulfill other service-related communications.</p> </li> </ul> <p>Upon termination of service agreements, we will delete all video data within 30 days or as otherwise required by contractual obligations with our customers.</p>"},{"location":"company/privacy-policy/#5-security-of-your-information","title":"5. Security of Your Information","text":"<p>We take appropriate technical and organizational measures to secure information from unauthorized access, disclosure, or destruction. This includes encryption of data in transit, secure access protocols, and restricted access to data based on role and need.</p>"},{"location":"company/privacy-policy/#6-international-data-transfers","title":"6. International Data Transfers","text":"<p>For customers based in the European Economic Area (EEA) or other regions with data transfer restrictions, we use Standard Contractual Clauses or other approved mechanisms to transfer data to our facilities or authorized third parties outside of those regions.</p>"},{"location":"company/privacy-policy/#7-your-data-privacy-rights","title":"7. Your Data Privacy Rights","text":"<p>Depending on your location, you may have certain rights regarding your information:</p> <ul> <li>Right to Access: You may request access to information we hold about you.</li> <li>Right to Rectify: You may request corrections to any inaccuracies in your information.</li> <li>Right to Erasure: You may request deletion of information we hold, subject to our legal and contractual obligations.</li> <li>Right to Object: You may object to data processing in certain circumstances.</li> </ul> <p>To exercise any of these rights, please contact us at legal@visionify.ai.</p>"},{"location":"company/privacy-policy/#8-use-of-cookies","title":"8. Use of Cookies","text":"<p>Our website may use cookies to enhance user experience, track usage patterns, and improve website functionality. Users can manage cookie preferences through their browser settings.</p>"},{"location":"company/privacy-policy/#9-changes-to-this-privacy-policy","title":"9. Changes to This Privacy Policy","text":"<p>We may update this Privacy Policy to reflect changes in our practices or relevant laws. We encourage users to review this page periodically. Any changes will be posted with a revised \"Last Updated\" date, and significant changes will be communicated through our website.</p>"},{"location":"company/privacy-policy/#10-contact-us","title":"10. Contact Us","text":"<p>If you have questions or concerns about this Privacy Policy or our data processing practices, please contact us at:</p> <p>Visionify Inc. Email: legal@visionify.ai Address: Visionify Inc., 1499 W 120<sup>th</sup> Ave, Ste 110, Westminster, CO 80234</p>"},{"location":"company/terms-and-conditions/","title":"Website Terms of Use","text":"<p>Last Updated: Sep 4, 2024</p> <p>Welcome to the Visionify Inc. website (\u201cSite\u201d). These Terms of Use (\u201cTerms\u201d) govern your access to and use of our website, located at https://visionify.ai. By accessing or using the Site, you agree to be bound by these Terms. If you do not agree with any part of these Terms, please do not use our Site.</p>"},{"location":"company/terms-and-conditions/#1-acceptance-of-terms","title":"1. Acceptance of Terms","text":"<p>By accessing, browsing, or using this Site, you acknowledge that you have read, understood, and agree to be bound by these Terms, as well as Visionify\u2019s Privacy Policy. These Terms apply to all visitors, users, and others who access or use the Site (\u201cUsers\u201d).</p>"},{"location":"company/terms-and-conditions/#2-use-of-site-content","title":"2. Use of Site Content","text":"<p>The content on this Site, including but not limited to text, images, video, and other media, is provided solely for informational purposes. Visionify grants you a limited, non-exclusive, non-transferable license to access and view the Site content solely for personal and non-commercial use. Unauthorized use, reproduction, modification, or distribution of any content from this Site is prohibited.</p>"},{"location":"company/terms-and-conditions/#3-user-conduct","title":"3. User Conduct","text":"<p>You agree to use the Site only for lawful purposes and in compliance with these Terms. Specifically, you agree not to: - Use the Site in any way that could harm, disable, overburden, or impair Visionify\u2019s servers or networks. - Engage in any activity that interferes with another User\u2019s access or use of the Site. - Attempt to gain unauthorized access to any portion of the Site, Visionify\u2019s systems, or networks. - Use any automated systems (such as bots or spiders) to access the Site without Visionify\u2019s prior written permission.</p>"},{"location":"company/terms-and-conditions/#4-intellectual-property-rights","title":"4. Intellectual Property Rights","text":"<p>All content, trademarks, service marks, and logos on this Site, including the Visionify name and logo, are the property of Visionify or its licensors and are protected by copyright, trademark, and other intellectual property laws. Unauthorized use of Visionify\u2019s intellectual property is strictly prohibited.</p>"},{"location":"company/terms-and-conditions/#5-privacy-and-data-collection","title":"5. Privacy and Data Collection","text":"<p>Visionify collects and uses information as described in our Privacy Policy. By using this Site, you consent to our collection, use, and sharing of your information as set forth in the Privacy Policy. Visionify does not collect any personally identifiable information (PII) from video data, as all data processed is anonymized and used solely to improve workplace safety solutions.</p>"},{"location":"company/terms-and-conditions/#6-third-party-links","title":"6. Third-Party Links","text":"<p>The Site may contain links to third-party websites or services that are not owned or controlled by Visionify. Visionify is not responsible for the content, privacy policies, or practices of any third-party websites or services. You acknowledge and agree that Visionify shall not be liable, directly or indirectly, for any damage or loss caused by your use of any third-party sites.</p>"},{"location":"company/terms-and-conditions/#7-disclaimer-of-warranties","title":"7. Disclaimer of Warranties","text":"<p>The Site and all content provided on it are offered on an \"AS IS\" and \"AS AVAILABLE\" basis without any warranties of any kind, either express or implied, including, but not limited to, implied warranties of merchantability, fitness for a particular purpose, and non-infringement. Visionify does not guarantee that the Site will be uninterrupted, secure, or free from errors or viruses.</p>"},{"location":"company/terms-and-conditions/#8-limitation-of-liability","title":"8. Limitation of Liability","text":"<p>To the fullest extent permitted by law, Visionify and its officers, directors, employees, and affiliates shall not be liable for any indirect, incidental, special, consequential, or punitive damages, including, but not limited to, loss of profits, data, or goodwill, arising from your use of or inability to use the Site.</p>"},{"location":"company/terms-and-conditions/#9-indemnification","title":"9. Indemnification","text":"<p>You agree to indemnify, defend, and hold harmless Visionify and its affiliates, officers, agents, and employees from and against any claims, liabilities, damages, losses, and expenses, including reasonable attorneys' fees, arising out of or in any way connected with your access to or use of the Site, your violation of these Terms, or your violation of any rights of another.</p>"},{"location":"company/terms-and-conditions/#10-modifications-to-the-terms","title":"10. Modifications to the Terms","text":"<p>Visionify reserves the right to modify or update these Terms at any time, at our sole discretion. Any changes to these Terms will be posted on this page with the revised \"Last Updated\" date. Your continued use of the Site after any changes constitutes acceptance of the new Terms.</p>"},{"location":"company/terms-and-conditions/#11-termination","title":"11. Termination","text":"<p>Visionify reserves the right to terminate or suspend your access to the Site, without prior notice or liability, for any reason, including your breach of these Terms.</p>"},{"location":"company/terms-and-conditions/#12-governing-law-and-jurisdiction","title":"12. Governing Law and Jurisdiction","text":"<p>These Terms and any disputes arising from or relating to these Terms or your use of the Site shall be governed by the laws of the State of Colorado, without regard to its conflict of law provisions. Any legal action or proceeding related to these Terms shall be brought exclusively in a court of competent jurisdiction in Denver, Colorado.</p>"},{"location":"company/terms-and-conditions/#13-contact-us","title":"13. Contact Us","text":"<p>For questions or concerns about these Terms, please contact us at:</p> <p>Visionify Inc. Email: info@visionify.ai Address: Visionify Inc., 1499 W 120<sup>th</sup> Ave, Ste 110, Westminster, CO 80234</p>"},{"location":"overview/camera-placement-guide/","title":"Camera Placement Guide","text":"<p>Use your existing camera to integrate with VisionAI platform </p> <p>Proper camera placement is essential to ensure that all areas of the workplace are adequately covered.</p>"},{"location":"overview/camera-placement-guide/#general-guiudelines","title":"General guiudelines","text":"<p>When positioning cameras for various use situations, take into account the following general guidelines: </p> <ul> <li>Lighting: Install cameras underneath a light fittings so that they do not obscure the cameras.</li> <li>Backlighting: Avoid mounting cameras near to window or other areas to protect from backlighting issue. It affects image quality.</li> <li>Local policies: Take into account local placement policies and laws.</li> <li>Authorization: The installation of cameras should be authorized by a designated person or department within the organization. </li> <li>Maintenance: Cameras should be regularly maintained and checked to ensure they are functioning properly. The policy should specify who is responsible for maintaining the cameras and how often they should be checked.</li> </ul> <p>Note</p> <p>Overall, it's important to develop local policies for camera mounting that balance the need for surveillance with the protection of privacy rights. The policies should be reviewed and updated regularly to ensure they remain relevant and effective.</p>"},{"location":"overview/camera-placement-guide/#key-factors","title":"Key factors","text":"<p>When setting up cameras there are three key factors to consider: </p> <ol> <li>Camera height</li> <li>Camera-to-focal-point distance, and </li> <li>Camera angle relative to the floor plane.</li> </ol> <p>It's crucial to identify the direction in which the majority of people are walking in relation to the camera's field of view. This direction is important for optimal system performance.</p> <p></p>"},{"location":"overview/camera-placement-guide/#camera-height","title":"Camera height","text":"<p>Camera height is an important consideration when determining the field of view for workplace safety cameras. For example, cameras should be placed high enough to capture the entire area of interest, but not so high that the camera view becomes distorted or difficult to interpret. Additionally, the height of the camera should take into account any obstacles or obstructions that may block the camera's field of view.</p>"},{"location":"overview/camera-placement-guide/#camera-to-focal-point-distance","title":"Camera-to-focal-point distance","text":"<p>The camera-to-focal-point distance is the distance between the camera lens and the focal point of the area being monitored. This distance is important because it determines the level of detail captured by the camera. If the camera is too far away from the focal point, the resulting image may lack the necessary detail to accurately capture safety hazards or other important information.</p> <p></p> <p>This distance is measured on the floor plane.</p> <p></p> <p>From above, it looks like this:</p> <p></p> <p>The following illustration simulates camera views from the closest and farthest camera-to-focal-point distances.</p> Closest Farthest"},{"location":"overview/camera-placement-guide/#camera-angle-mounting-ranges","title":"Camera angle mounting ranges","text":"<p>The angle of the camera relative to the floor plane is important for capturing accurate footage of safety hazards and other workplace activities. For example, cameras should be positioned to capture a wide field of view, but not at such an extreme angle that the resulting image becomes distorted or difficult to interpret. Additionally, the angle of the camera should take into account the direction that people are walking in relation to the camera field of view, as this can impact the performance of the system.</p> <p>The following illustration simulates camera views using the leftmost (-) and rightmost (+) mounting angle recommendations:</p> Leftmost view Rightmost view <p>The following illustration shows camera placement and mounting angles from a birds-eye view.</p> <p></p> <p>It's important to carefully consider camera height, camera-to-focal-point distance, and camera angle relative to the floor plane. Taking these factors into account can help ensure that cameras are positioned to capture accurate footage of workplace hazards and other important safety information.</p>"},{"location":"overview/camera-placement-guide/#camera-view","title":"Camera View","text":"<p>The camera view refers to the field of vision captured by a camera. The camera view is determined by the placement of the camera and its angle of view.</p> <p>There are two primary modes of camera placement that are considered for VisionAI workplace safety scenarios:</p> <ul> <li>Ceiling-mounted and </li> <li>Straight-mounted.</li> </ul>"},{"location":"overview/camera-placement-guide/#ceiling-mounted-cameras","title":"Ceiling-mounted cameras","text":"<ul> <li>Ceiling-mounted cameras are typically installed on the ceiling or high up on a wall and are pointed downwards. They provide a wide-angle view of the area below.</li> <li>These cameras are ideal for monitoring larger areas, such as open workspaces, warehouses, or production floors, where a bird's eye view is necessary to capture all activities in the space.</li> <li>These cameras can also be used in areas where there are obstructions that would block the view of a straight-mounted camera.</li> <li> <p>These cameras can cover larger areas with fewer cameras, making them cost-effective and efficient.</p> <p>The following illustration provides simulations for the camera ceiling views.</p> Example 1 Example 2 </li> </ul>"},{"location":"overview/camera-placement-guide/#straight-mounted-cameras","title":"Straight-mounted cameras","text":"<ul> <li>Straight-mounted cameras are mounted at eye level or lower on a wall or a stand and are pointed straight ahead. They  provide more focused view of the area in front of them. </li> <li>These cameras are ideal for monitoring smaller areas, such as corridors, entrances and exits,  where a more focused view is required for capturing specific activities. </li> <li>These cameras are also useful for capturing facial features and other details as they are closer to the subject being monitored.</li> <li> <p>One of the advantages of straight-mounted cameras is that they are often easier to install and adjust, and they allow for more detailed and accurate identification of individuals. </p> <p>The following illustration provides simulations for the camera front views.</p> Example 1 Example 2 </li> </ul> <p>When determining which mode of camera placement to use, it's important to consider the specific needs of required use case. Factors such as the size of the area to be monitored, the level of detail required, and the presence of obstructions should all be taken into account to ensure that the cameras are installed in the most effective and efficient manner possible.</p>"},{"location":"overview/camera-placement-guide/#next-steps","title":"Next Steps","text":"<ul> <li>Quick Start</li> <li>Camera Placement Guide</li> <li>Supported Scenarios</li> <li>Camera Management</li> <li>FAQs</li> </ul>"},{"location":"overview/camera-placement-guide/#contact-information","title":"Contact Information","text":"contact_phone Sales Inquiries <p>Get in touch with our sales team for demos and pricing information.</p> <ul> <li>Email: sales@visionify.ai</li> <li>Phone: +1 720-449-1124</li> </ul> support_agent Technical Support <p>Need help? Visit our support portal or contact our technical team.</p> <ul> <li>https://support.visionify.ai</li> <li>support@visionify.ai</li> </ul> calendar_month Schedule a Demo <p>See VisionAI in action with a personalized demo from our team.</p> event                 Book Your Demo"},{"location":"overview/cameras/","title":"Cameras","text":"1 videocam Supported Cameras <p>View compatible IP cameras and required specifications</p> 2 add_circle Adding Cameras <p>Learn how to add and configure new cameras</p> 3 info Camera Details <p>View and manage camera information</p> 4 view_agenda Scenarios <p>Configure detection scenarios for each camera</p> 5 event Events <p>View and manage detected events</p> 6 live_tv Livestream <p>Access real-time camera feeds</p> 7 record_voice_over Recording <p>Configure and manage video recordings</p> 8 delete Remove Camera <p>Learn how to remove cameras from the system</p>"},{"location":"overview/cameras/#supported-cameras","title":"Supported Cameras","text":"<p>VisionAI supports a wide range of IP cameras including:</p> <ul> <li>ONVIF-compliant IP cameras</li> <li>RTSP stream cameras</li> <li>HTTP stream cameras</li> <li>USB cameras (when connected to edge device)</li> <li>LTE Network Cameras</li> </ul> <p>Please refer to Supported Cameras Guide for more details on supported cameras. Regardless of the camera type, the following are the minimum requirements:</p> <ul> <li>Resolution: 1080p (1920x1080)</li> <li>Frame rate: 20 fps</li> <li>Intranet bandwidth per camera: 2MBPS</li> <li>Protocol support: RTSP, ONVIF, or HTTP</li> <li>Network connectivity: Ethernet, WiFi or LTE</li> </ul>"},{"location":"overview/cameras/#adding-cameras","title":"Adding Cameras","text":"<p>Connecting your cameras to VisionAI is straightforward. Follow these steps to integrate your existing camera infrastructure:</p> 1. Go to Cameras Page <p>Navigate to the Cameras page from the main dashboard. Here you'll see all your connected cameras and their status.</p> 2. Add New Camera <p>Click on the \"Add Camera\" button to begin the integration process. VisionAI supports IP cameras, CCTV systems, and NVR/DVR setups.</p> 3. Provide Camera Details <p>Enter your camera details including name, RTSP URL, and location. Test the connection to ensure proper setup before saving.</p> <p>Note</p> <ol> <li>Test your Camera RTSP URL to make sure it is playing. You can test it using VLC Player.</li> <li>Initially, you will see a blank screen for camera. The screenshot for the camera will update once the camera is connected.</li> </ol>"},{"location":"overview/cameras/#camera-details","title":"Camera Details","text":"<p>You can click on any camera to view its details.</p> 1. Click on a Camera <p>Click on a camera to view its details. The camera details page will show the status of the camera, the AI scenarios applied to the camera, recent events, livestream options, recording options and more.</p> 2. View Recent Events <p>On the camera details page - we show the last 8 events for the camera. We also show the total number of events in the last 24hrs, 7 days, or 30 days. To dig more into events, you can visit the Events page.</p> 3. View/Edit AI Scenarios <p>View or Edit the AI scenarios configured for the camera. Currently applied scenarios are highlighted on the right.</p> 4. View Livestream <p>Click on the view live-stream button to view the live-inference view of the camera.</p> 5. Record Inference Video <p>Record live inference video from the camera. The recorded video is available under the Recordings tab.</p> 6. View Camera Status <p>Sometimes cameras might not be streaming. This page will show you the status of the camera.</p>"},{"location":"overview/cameras/#camera-scenarios","title":"Camera Scenarios","text":"<p>You can configure scenarios from the camera details page. </p> 1. View/Edit AI Scenarios <p>Camera Details page shows all the AI scenarios avaialble for the camera. You can add a new scenario by clicking the \"Add Scenario\" button.</p> 2. Add AI Scenario <p>Adding AI scenario is a 3 step process. First, you select the scenario. We support a wide variety of scenarios. Once you click on Get this - it will walk you through setting up zones &amp; detection parameters for the scenario."},{"location":"overview/cameras/#camera-events","title":"Camera Events","text":"<p>Most recent 8 events for the camera are shown on the camera details page. You can view details about each event by clicking on the event. For filtering/sorting events from all cameras - please visit the Events page.</p> 1. Click on a Camera <p>Click on a camera to view its details. The camera details page will show the status of the camera, the AI scenarios applied to the camera, recent events, livestream options, recording options and more.</p> 2. View Recent Events <p>On the camera details page - we show the last 8 events for the camera. We also show the total number of events in the last 24hrs, 7 days, or 30 days. To dig more into events, you can visit the Events page.</p>"},{"location":"overview/cameras/#livestream","title":"Livestream","text":"<p>Livestream allows you to access real-time camera feeds from the camera. We support inference live-stream - that way you can see what we are inferencing in real-time:</p> View Livestream <p>Click on the view live-stream button to view the live-inference view of the camera.</p>"},{"location":"overview/cameras/#recording","title":"Recording","text":"<p>Recording feature allows to record 10 minutes of video. Just click on the record video button at the right corner of the camera details page.</p> Record Video <p>Click on the record video button at the right corner of the camera details page. The recorded video is available under the Recordings tab.</p>"},{"location":"overview/cameras/#camera-removal","title":"Camera Removal","text":"<p>To remove a camera from the system, you can navigate to Camera Listing Page. From here, you see an option to remove the camera.</p> <p>Data Retention</p> <p>Camera removal doesn't automatically delete historical data. Configure data retention policies separately.</p>"},{"location":"overview/cameras/#next-steps","title":"Next Steps","text":"<ul> <li>Quick Start</li> <li>Camera Placement Guide</li> <li>Supported Scenarios</li> <li>Camera Management</li> <li>FAQs</li> </ul>"},{"location":"overview/cameras/#contact-information","title":"Contact Information","text":"contact_phone Sales Inquiries <p>Get in touch with our sales team for demos and pricing information.</p> <ul> <li>Email: sales@visionify.ai</li> <li>Phone: +1 720-449-1124</li> </ul> support_agent Technical Support <p>Need help? Visit our support portal or contact our technical team.</p> <ul> <li>https://support.visionify.ai</li> <li>support@visionify.ai</li> </ul> calendar_month Schedule a Demo <p>See VisionAI in action with a personalized demo from our team.</p> event                 Book Your Demo              arrow_upward"},{"location":"overview/faqs/","title":"VisionAI platform FAQs","text":"<p>Learn more about the platform</p>"},{"location":"overview/faqs/#what-is-visional","title":"What is VisionAl?","text":"<p>VisionAI is an Enterprise Application from Visionify for Workplace Safety. We use latest state of the art Computer Vision models, and our solution works with your existing CCTV camera infrastructure. </p>"},{"location":"overview/faqs/#what-scenarios-do-you-support","title":"What scenarios do you support?","text":"<p>VisionAI supports a variety of use-cases focused on common workplace and employee health &amp; safety scenarios. You can learn more about the scenarios here.</p>"},{"location":"overview/faqs/#do-i-need-to-install-get-new-cameras-to-run-this-system","title":"Do I need to install get new cameras to run this system?","text":"<p>No! You do not need any new camera or hardware to run this system. VisionAl works with your existing security camera infrastructure. We support RTSP, RTMP, HLS, ONVIF and other common video platforms. Current safety surveillance systems are just record and playback \u2013 we can bring a lot of operational and safety insights from the current camera systems.</p>"},{"location":"overview/faqs/#is-it-free-to-use-how-does-the-licensing-work","title":"Is it Free to use? How does the licensing work?","text":"<p>No, VisionAI is a licensed product. Please contact us through sales@visionify.ai to get started.</p>"},{"location":"overview/faqs/#do-you-offer-a-free-trial","title":"Do you offer a free trial?","text":"<p>Yes, we do offer a Free Video POC trial. Please contact us through sales@visionify.ai to get started.</p>"},{"location":"overview/faqs/#privacy-security-questions","title":"Privacy &amp; Security Questions","text":""},{"location":"overview/faqs/#how-does-visionai-protect-personal-privacy","title":"How does VisionAI protect personal privacy?","text":"<p>VisionAI offers comprehensive privacy protection through multiple features:</p> <ul> <li>Automated face blurring in video feeds</li> <li>Text and document blurring capabilities</li> <li>Screen content obscuring</li> <li>License plate blurring</li> <li>Real-time processing without storing personal data</li> </ul>"},{"location":"overview/faqs/#is-visionai-gdpr-compliant","title":"Is VisionAI GDPR compliant?","text":"<p>Yes, VisionAI is designed with privacy regulations in mind, including GDPR and SOC-2 Type-2. Our privacy measures ensure that personal identifiable information (PII) is protected through automated blurring and data protection protocols.</p>"},{"location":"overview/faqs/#what-types-of-sensitive-information-can-be-protected","title":"What types of sensitive information can be protected?","text":"<p>Our system can automatically detect and blur:</p> <ul> <li>Faces and personal identifiers</li> <li>Computer screens and displays</li> <li>Documents and sensitive text</li> <li>License plates</li> <li>Signs and notices containing confidential information</li> </ul>"},{"location":"overview/faqs/#where-is-the-video-processing-done","title":"Where is the video processing done?","text":"<p>All video processing is done at the edge (on your local network) to ensure maximum privacy and security. No sensitive data leaves your premises unless explicitly configured otherwise.</p>"},{"location":"overview/faqs/#can-the-blurred-information-be-recovered","title":"Can the blurred information be recovered?","text":"<p>No, once information is blurred by our system, it cannot be recovered. The blurring process is permanent and irreversible to ensure complete privacy protection.</p>"},{"location":"overview/faqs/#how-accurate-is-the-privacy-protection","title":"How accurate is the privacy protection?","text":"<p>Our privacy protection features achieve:</p> <ul> <li>97% detection accuracy for text and documents</li> <li>95% accuracy for face detection and blurring</li> <li>99% system uptime</li> <li>Real-time processing capabilities</li> </ul>"},{"location":"overview/faqs/#can-we-customize-which-elements-get-blurred","title":"Can we customize which elements get blurred?","text":"<p>Yes, the system is fully customizable. You can specify:</p> <ul> <li>Which types of information to blur</li> <li>Specific zones or areas for privacy protection</li> <li>Different privacy rules for different cameras</li> <li>Custom privacy policies per location</li> </ul>"},{"location":"overview/faqs/#how-can-i-customize-the-models-to-work-in-my-environment","title":"How can I customize the models to work in my environment?","text":"<p>Visionify models are robust &amp; have been trained with a wide variety of industry specific data. They would work out of the box for most of the scenarios. We also support customization of models to work in your environment. </p>"},{"location":"overview/faqs/#how-many-scenarios-can-i-use-on-a-camera","title":"How many scenarios can I use on a camera?","text":"<p>We recommend up to 3 scenarios per camera. Otherwise the performance of the system will degrade.</p>"},{"location":"overview/faqs/#how-can-i-get-started","title":"How can I get started?","text":"<p>Please contact our sales team at sales@visionify.ai to get started.</p>"},{"location":"overview/faqs/#next-steps","title":"Next Steps","text":"<ul> <li>Quick Start</li> <li>Camera Placement Guide</li> <li>Supported Scenarios</li> <li>Camera Management</li> <li>FAQs</li> </ul>"},{"location":"overview/faqs/#contact-information","title":"Contact Information","text":"contact_phone Sales Inquiries <p>Get in touch with our sales team for demos and pricing information.</p> <ul> <li>Email: sales@visionify.ai</li> <li>Phone: +1 720-449-1124</li> </ul> support_agent Technical Support <p>Need help? Visit our support portal or contact our technical team.</p> <ul> <li>https://support.visionify.ai</li> <li>support@visionify.ai</li> </ul> calendar_month Schedule a Demo <p>See VisionAI in action with a personalized demo from our team.</p> event                 Book Your Demo              arrow_upward"},{"location":"overview/finding-rtsp-urls/","title":"Finding RTSP URLs for IP Cameras","text":"<p>RTSP (Real Time Streaming Protocol) URLs are essential for connecting IP cameras to VisionAI. This guide will help you locate the correct RTSP URL format for various camera manufacturers.</p>"},{"location":"overview/finding-rtsp-urls/#general-format","title":"General Format","text":"<p>Most RTSP URLs follow this basic structure: <code>rtsp://username:password@camera-ip-address:port/stream-path</code></p>"},{"location":"overview/finding-rtsp-urls/#camera-manufacturers","title":"Camera Manufacturers","text":""},{"location":"overview/finding-rtsp-urls/#hikvision","title":"Hikvision","text":"<p>Default RTSP URL formats:</p> <ul> <li>Main Stream: <code>rtsp://username:password@camera-ip:554/h264/ch1/main/av_stream</code></li> <li>Sub Stream: <code>rtsp://username:password@camera-ip:554/h264/ch1/sub/av_stream</code></li> </ul> <p>Additional Notes:</p> <ul> <li>Default credentials: admin/12345</li> <li>Port 554 is standard</li> <li>Newer models might use h265 instead of h264 in the URL</li> </ul>"},{"location":"overview/finding-rtsp-urls/#dahua","title":"Dahua","text":"<p>Default RTSP URL formats:</p> <ul> <li>Main Stream: <code>rtsp://username:password@camera-ip:554/cam/realmonitor?channel=1&amp;subtype=0</code></li> <li>Sub Stream: <code>rtsp://username:password@camera-ip:554/cam/realmonitor?channel=1&amp;subtype=1</code></li> </ul> <p>Additional Notes:</p> <ul> <li>Default credentials: admin/admin</li> <li>Channel numbers start from 1</li> <li>Some models use port 554, others might use 37777</li> </ul>"},{"location":"overview/finding-rtsp-urls/#axis","title":"Axis","text":"<p>Default RTSP URL formats:</p> <ul> <li>MJPEG: <code>rtsp://username:password@camera-ip/axis-media/media.amp</code></li> <li>H.264: <code>rtsp://username:password@camera-ip/axis-media/media.amp?videocodec=h264</code></li> </ul> <p>Additional Notes:</p> <ul> <li>Default credentials: root/pass</li> <li>AXIS IP Utility can help locate cameras</li> <li>Comprehensive VAPIX documentation available</li> </ul>"},{"location":"overview/finding-rtsp-urls/#amcrest","title":"Amcrest","text":"<p>Default RTSP URL formats:</p> <ul> <li>Main Stream: <code>rtsp://username:password@camera-ip:554/cam/realmonitor?channel=1&amp;subtype=0</code></li> <li>Sub Stream: <code>rtsp://username:password@camera-ip:554/cam/realmonitor?channel=1&amp;subtype=1</code></li> </ul> <p>Additional Notes:</p> <ul> <li>Default credentials: admin/admin</li> <li>Similar format to Dahua (uses same protocol)</li> <li>Amcrest IP Config Tool helps find camera IPs</li> </ul>"},{"location":"overview/finding-rtsp-urls/#avigilon","title":"Avigilon","text":"<p>Default RTSP URL format:</p> <ul> <li>Main Stream: <code>rtsp://username:password@camera-ip:554/defaultPrimary?streamType=u</code></li> </ul> <p>Additional Notes:</p> <ul> <li>Default credentials vary by installation</li> <li>Avigilon Camera Configuration Tool helps configure cameras</li> <li>Contact support for specific camera models</li> </ul>"},{"location":"overview/finding-rtsp-urls/#verkada","title":"Verkada","text":"<p>Note: Verkada cameras use a proprietary cloud-based system and don't support direct RTSP connections by default. To integrate with VisionAI: 1. Contact Verkada support for API access 2. Use Command API integration 3. Consider alternative camera options if direct RTSP access is required</p>"},{"location":"overview/finding-rtsp-urls/#finding-your-cameras-ip-address","title":"Finding Your Camera's IP Address","text":"<ol> <li> <p>Network Scanner Method:</p> <ul> <li>Use tools like Advanced IP Scanner</li> <li>Angry IP Scanner</li> <li>ONVIF Device Manager</li> </ul> </li> <li> <p>Router Method:</p> <ul> <li>Log into your router's admin panel</li> <li>Look for connected devices or DHCP client list</li> <li>Identify camera by MAC address (usually on camera label)</li> </ul> </li> <li> <p>Manufacturer Tools:</p> <ul> <li>Most manufacturers provide their own IP finding tools</li> <li>Usually available on their support websites</li> <li>Often combine discovery and configuration features</li> </ul> </li> </ol>"},{"location":"overview/finding-rtsp-urls/#troubleshooting-tips","title":"Troubleshooting Tips","text":"<ol> <li> <p>Connection Issues:</p> <ul> <li>Verify camera is on same network as VisionAI</li> <li>Check username/password</li> <li>Ensure ports are open (usually 554)</li> <li>Try both HTTP and HTTPS variants</li> </ul> </li> <li> <p>Stream Quality:</p> <ul> <li>Main streams provide highest quality but require more bandwidth</li> <li>Sub streams are good for remote viewing</li> <li>Match stream resolution to your needs</li> </ul> </li> <li> <p>Security:</p> <ul> <li>Always change default passwords</li> <li>Use strong passwords</li> <li>Consider network segregation for cameras</li> <li>Keep firmware updated</li> </ul> </li> </ol>"},{"location":"overview/finding-rtsp-urls/#testing-rtsp-urls","title":"Testing RTSP URLs","text":"<p>You can test RTSP URLs using:</p> <ul> <li>VLC Media Player</li> <li>RTSP Simple Player</li> <li>ONVIF Device Manager</li> </ul>"},{"location":"overview/finding-rtsp-urls/#additional-resources","title":"Additional Resources","text":"<ul> <li>ONVIF Device Manager - Universal tool for IP cameras</li> <li>Security Camera Reviews - Detailed camera information</li> <li>IP Video Market - Camera comparison tool</li> <li>VisionAI Documentation - Main documentation</li> </ul>"},{"location":"overview/quick-start/","title":"Quick Start Guide","text":"<p>VisionAI is an enterprise-grade computer vision platform that transforms your existing camera infrastructure into an intelligent workplace safety system. This guide will walk you through the setup process and help you get started with your first safety monitoring deployment.</p> 1 login Sign In <p>Create your enterprise account and set up team access</p> 2 videocam Cameras <p>Connect your existing camera infrastructure</p> 3 memory AI Scenarios <p>Select and customize safety monitoring scenarios</p> 4 view_agenda Events <p>Select and customize safety monitoring scenarios</p> 5 list_alt_check Tasks <p>Detailing the tasks assigned, their progress, and recommendations for improvement</p> 6 speed_camera Views <p>It allows administrators to create custom views that provide a structured way to monitor surveillance data efficiently</p> 7 notifications_active Alerts <p>Set up notifications and response workflows</p> 8 dashboard Dashboard <p>Monitor safety metrics in real-time</p> 9 query_stats Sites Comparison <p>This report provides a summary of site comparison insights</p>"},{"location":"overview/quick-start/#prerequisites","title":"Prerequisites","text":"<ul> <li>Active enterprise subscription or trial account. Contact Sales.</li> <li>Access to your organization's CCTV/camera infrastructure.</li> <li>RTSP URLs for your cameras. You can test RTSP URLs using VLC Player.</li> </ul>"},{"location":"overview/quick-start/#step-1-account-setup","title":"Step 1: Sign In","text":"<p>Getting started with VisionAI is simple. Here's how to activate your enterprise account:</p> 1. Activate Your Account <p>Once you've signed up for enterprise account, you will receive an activation email from Visionify team.</p> 2. Password Setup <p>Accept the invite from email &amp; activate the account. Set your own password here.</p> 3. Sign In <p>After successfully setting up your password, you should be able to log in to the Visionify dashboard using your username and password.</p>"},{"location":"overview/quick-start/#step-2-camera-integration","title":"Step 2: Camera Onboarding","text":"<p>Connecting your cameras to VisionAI is straightforward. Follow these steps to integrate your existing camera infrastructure:</p> 1. Go to Cameras Page <p>Navigate to the Cameras page from the main dashboard. Click on the \"Add Camera\" button to begin the integration process. VisionAI supports IP cameras, CCTV systems, and NVR/DVR setups.</p> 2. Add New Camera Details <p>Enter your camera details including name, RTSP URL, and location. Test the connection to ensure proper setup before saving.</p> 3. Cameras List <p>Here you'll see all your connected cameras along with their current status. Use the available filters on the Cameras page to view cameras by area.</p> <p>Note</p> <ol> <li>Test your Camera RTSP URL to make sure it is playing. You can test it using VLC Player.</li> <li>Initially, you will see a blank screen for camera. The screenshot for the camera will update once the camera is connected.</li> </ol>"},{"location":"overview/quick-start/#step-3-scenario-configuration","title":"Step 3: Configuring AI Scenarios","text":"1 Initiate Scenario Setup <p>Click \"Add New Scenario\" on camera details page to begin configuration.</p> 2 Select a Scenario <p>Choose from available safety scenarios by clicking \"Get This\" button.</p> 3 Set Up Monitoring Zones <p>Draw and adjust monitoring zones directly on camera feed.</p> 4 Configure Pause Times <p>Set break periods to pause detection during scheduled downtimes.</p> 5 Fine-tune Settings <p>Adjust confidence thresholds and duration, then click \"Apply\".</p> <p>Tip</p> <p>Start with the default parameters and adjust them later based on the specific needs of your environment. These settings can always be modified at any time.</p>"},{"location":"overview/quick-start/#step-4-events-dashboard","title":"Step 4: Events","text":"<p>Setting up safety monitoring scenarios in VisionAI is straightforward. Follow these steps to configure your first scenario:</p> 1. Events Listing <p>Navigate to the Events page to review specific safety incidents. Filter events by time range, scenarios, event types, or specific cameras &amp; Area Wise ,Shift Wise. Each event includes a 12-second video clip for detailed investigation and analysis.</p> 2. Event Details <p>On the Event Details page, you can view a 12-second video clip of the event. You can click thumbs up/down to vote on the event. Additionally, you can leave a review, mark the event as accurate or inaccurate, and view the severity level of the event\u2014categorized as Low, Moderate, or High\u2014to better understand its criticality.</p> <p>Tip</p> <p>Start with the default parameters and adjust them later based on the specific needs of your environment. These settings can always be modified at any time.</p>"},{"location":"overview/quick-start/#step-5-task-Management","title":"Step 5: Tasks","text":"<p>The VisionAI Task Management is essential to ensure work is organized, responsibilities are clear, and progress is tracked effectively within the application:</p> Task Overview <p>Access the Dashboard from the left navigation menu to view key Task.Task Management helps users create, assign, track, and manage tasks within the application. It ensures that all work items are organized, progress is monitored, and responsibilities are clear.</p> <p>Tip</p> <p>Use clear titles and due dates when creating tasks to ensure easy tracking and accountability. Regularly update task statuses to keep your team informed and aligned.</p>"},{"location":"overview/quick-start/#step-6-view-access","title":"Step 6: Views","text":"<p>The purpose of the Views feature is to provide customized dashboards for specific cameras, areas, or events, enabling quick access to incident insights and performance metrics for faster decision-making.</p> Views Overview <p>Access the Dashboard from the left navigation menu to view key Views.The purpose of the Views page is to allow users to create and monitor customized event dashboards for specific cameras, areas, or events, enabling quick access to relevant incident data and performance metrics.</p> <p>Tip</p> <p>Create separate views for high-priority areas or event types to quickly monitor critical incidents without filtering through all data\u2014this saves time and improves response efficiency.</p>"},{"location":"overview/quick-start/#step-7-alert-configuration","title":"Step 7: Alerts","text":"<p>Configure comprehensive notification settings through your dedicated observability platform at <code>customername.visionify.ai/observability</code>. VisionAI offers multiple alert types to ensure your team stays informed of safety events:</p> 1. Daily Digest Emails <p>Set up automated daily summaries of safety events, incidents, and compliance metrics. Perfect for management oversight and trend analysis.</p> 2. Periodic Reports <p>Schedule detailed reports with CSV attachments, delivered via email or Microsoft Teams. Customize reports by area, camera, or specific event types for targeted insights.</p> 3. Text Message Alerts <p>Enable real-time SMS notifications for immediate awareness of critical safety events. Ideal for urgent situations requiring immediate attention.</p> 4. Whatsapp Message Alerts <p>Enable real-time Whatsapp notifications for immediate awareness of critical safety events. Ideal for urgent situations requiring immediate attention.</p> 5. Teams Alerts <p>Enable real-time Teams notifications for immediate awareness of critical safety events. Ideal for urgent situations requiring immediate attention.</p> 6. Speaker Based Alerts <p>Configure automated audio announcements for real-time safety notifications in your facility. Perfect for immediate on-site response to safety events.</p> <p>Tip</p> <p>Combine multiple alert types for comprehensive coverage. For example, use speaker alerts for immediate on-site response, while keeping management informed through daily digests and periodic reports.</p>"},{"location":"overview/quick-start/#step-8-dashboard-access","title":"Step 8: Dashboard","text":"<p>The VisionAI dashboard provides comprehensive insights into your safety metrics and events. Here's how to navigate and utilize the dashboard effectively:</p> Safety Metrics Overview <p>Access the Dashboard from the left navigation menu to view key safety metrics. Select custom time ranges to analyze trends across weeks, months, or specific date ranges. Track compliance rates, incident counts, and safety improvements over time.</p> <p>Tip</p> <p>Use the dashboard's filtering capabilities to focus on specific areas or types of safety events. This helps in identifying patterns and addressing recurring safety concerns promptly.</p>"},{"location":"overview/quick-start/#step-9-sites-comparison","title":"Step 9: Sites Comparison","text":"<p>The VisionAI The Sites for Comparison page is to enable users to analyze and evaluate safety performance across different locations, helping identify high-risk areas, improvement opportunities, and trends over time.</p> Sites Comparison Overview <p>Access the Dashboard from the left navigation menu to view key Sites Comparision.We can select and compare up to five sites to view key metrics such as Time Between Events, Total Events, and Reviewed Events, along with detailed charts like Events Overview and Severity Breakdown, enabling data-driven decision-making and proactive safety management..</p> <p>Tip</p> <p>Use the \"Sites Comparison\" feature regularly to monitor underperforming locations\u2014tracking metrics like time between incidents and reviewed event rates can help prioritize safety audits and training efforts effectively.</p>"},{"location":"overview/quick-start/#contact-information","title":"Contact Information","text":"contact_phone Sales Inquiries <p>Get in touch with our sales team for demos and pricing information.</p> <ul> <li>Email: sales@visionify.ai</li> <li>Phone: +1 720-449-1124</li> </ul> support_agent Technical Support <p>Need help? Visit our support portal or contact our technical team.</p> <ul> <li>https://support.visionify.ai</li> <li>support@visionify.ai</li> </ul> calendar_month Schedule a Demo <p>See VisionAI in action with a personalized demo from our team.</p> event                 Book Your Demo              arrow_upward"},{"location":"overview/scenarios/","title":"Scenarios","text":"<p>Scenarios (also referred to as <code>use cases</code>) form the building blocks of VisionAI platform. These scenarios are organized into <code>Suites</code>. Below we talk about different suites and the scenarios that are part of them.</p> <ul> <li>All scenarios are available as pick-n-choose scenarios. You can pick the scenarios you want based on your business needs. Each scenario is independently tested.</li> <li>Some scenarios require zones to be defined - you can define zones through the VisionAI web-application.</li> <li>Events provided by these scenarios are given below. Events are sent to Redis, MQTT &amp; WebSocket endpoints for custom integrations.</li> <li>Currently supported scenarios are highlighted by a \u2705. Roadmap scenarios are highlighted by a \ud83d\udcc5.</li> </ul> <p>Below image also provides a summary of all the scenarios that are supported by VisionAI.</p> <p> </p> Visionify Supported AI Scenarios <p>New scenario request</p> <p>This chapter lists down all the scenarios that are supported by the VisionAI platform. We are always looking to expand our suite - please send a request to us about any additional scenarios you need.</p>"},{"location":"overview/scenarios/#ppe-compliance","title":"PPE Compliance","text":"<p>PPE Compliance is our core application. We support most of the common types of PPEs used in manufacturing &amp; construction industry. This suite is sometimes also referred to by <code>Worker Health and Safety</code>.</p> <p>PPE compliance is the first step towards a comprehensive safety program. Workers sometimes forget to wear PPEs like helmets, gloves, safety boots, high-vis vests, goggles, masks, coveralls etc., due to lack of awareness or complacency. PPE Compliance helps you ensure that workers are wearing the required PPEs.</p> <p>Ensuring PPE Compliance can yield significant benefits. It can help reduce the number of accidents and injuries in the workplace, improve productivity, and enhance the overall safety culture of the organization.</p> <p> </p> PPE Compliance Sample Event <p>Table: PPE Compliance Events and Detection Details</p> Status Scenario name Supported Events Event Details More Info \u2705 PPE Compliance <code>No Helmet</code> Person detected without helmet PPE Compliance <code>No Gloves</code> Person detected without gloves <code>No Safety Boots</code> Person detected without safety boots <code>No High-Vis Vest</code> Person detected without high-vis vest <code>No Goggles</code> Person detected without goggles <code>No Mask</code> Person detected without mask <code>No Cap</code> Person detected without cap <code>No Apron</code> Person detected without apron <code>No Hairnet</code> Person detected without hairnet <code>No Face Shield</code> Person detected without face shield (Welding) <code>No Coveralls</code> Person detected without coveralls <code>No Safety Harness</code> Personal Fall Arrest System (PFAS) <code>No Earmuffs</code> Person detected without earmuffs"},{"location":"overview/scenarios/#area-controls","title":"Area Controls","text":"<p>Area controls is a core scenario of the VisionAI application. With this scenario - we can enable different area and time related use-cases. Area control scenarios require a zone to be configured for each of the different events.</p> <p>For example, if we want to setup a Pedestrian Pathway, or create a Man-Machine area that is restricted during certain hours - we can do that with area control scenarios.</p> <p>Deploying Area Control scenarios requires understanding of the camera area and the type of work performed there. We recommend that you look at the video clips from the camera, and tune the scenario accordingly.</p> <p> </p> Restricted Zone Violation Example Event <p>Table: Area Control Events and Detection Details</p> Scenario name Supported? Event Event Details More Info Area Controls \u2705 <code>Restricted Area</code> Person in Restricted Area More details \u2705 <code>Perimeter Control</code> Person in Secure Perimeter \u2705 <code>Time Limited Areas</code> Person in zone for more than X mins \u2705 <code>Confined Space Monitoring</code> Person in confined space for more than X mins \u2705 <code>Min Worker Zone</code> No Person in Mandatory Personnel Zone \u2705 <code>Max Worker Zone</code> Grouping/Crowding detected \ud83d\udcc5 <code>Person under Suspended Load</code> Person under suspended load \u2705 <code>Pedestrian Pathway</code> Person outside of pedestrian pathway \u2705 <code>Person in Vehicle Pathway</code> Person detected in vehicle pathway"},{"location":"overview/scenarios/#forklift-safety","title":"Forklift Safety","text":"<p>Visionify's Forklift Safety suite detects near-misses between forklifts &amp; people, forklift-speed limit, and dedicated pathways for forklifts &amp; people. This scenario is useful for areas where forklifts are operated.</p> <p>Forklift Safety also implements other best practices like Wearning Seatbelts, Stop sign compliance etc.</p> <p>Our forklift safety suite can be considered as a passive safety system. It does not actively prevent any accidents, but it does help you identify areas that need attention. The goal of the Forklift Safety Suite is to make your team aware of the risks, so you can data driven changes to make your workplace safer.</p> <p> </p> Forklift Safety Violation Example Event <p>Table: Forklift Safety Events and Detection Details</p> Scenario name Supported? Event Event Details More Info Forklift Safety \u2705 <code>Forklift Person interaction</code> Forklift Person Near-Miss More details \u2705 <code>Forklift Forklift interaction</code> Forklift Forklift Near-Miss \u2705 <code>Forklift Speed Limit</code> Forklift Speed Limit Violation \u2705 <code>Forklift Stop Sign Compliance</code> Forklift Stop Sign Compliance Violation \u2705 <code>Dedicated Forklift Pathway</code> Forklift outside of dedicated pathway \u2705 <code>Person in Forklift Pathway</code> Person in Forklift Pathway \ud83d\udcc5 <code>Forklift Max-height Violation</code> Forklift Max-height Violation \ud83d\udcc5 <code>Forklift with Pins Up</code> Forklift with Pins Up \u2705 <code>Forklift and People Heatmap</code> Forklift and People Heatmap"},{"location":"overview/scenarios/#emergency-events","title":"Emergency Events","text":"<p>Emergency events detection is critical for workplace safety. This suite focuses on detecting various emergency situations that require immediate attention, such as smoke, fire, slip, trip and falls, any person-down events resulting from exhaustion and heat-stroke. Early detection of these events can help prevent accidents and enable quick response times.</p> <p>Alert Notifications</p> <p>Visionify's system can be configured to send out an alert when any of these emergency events are detected. This alert can be sent as a Text Message, Email or a notification through Microsoft Teams.</p> <p> </p> Smoke and Fire Detection Example Event <p>Table: Emergency Events and Detection Details</p> Scenario name Supported? Event Event Details More Info Emergency Events \u2705 <code>Smoke Event Detected</code> Smoke Event Detected More details \u2705 <code>Fire Event Detected</code> Fire Event Detected More details \u2705 <code>Person Down</code> Slip, trip, fall, or other Person Down Events More details"},{"location":"overview/scenarios/#heatmaps-and-occupancy-metrics","title":"Heatmaps and Occupancy Metrics","text":"<p>Occupancy metrics suite provides use-cases for person counting, heatmaps (density maps) of people &amp; forklifts, desk occupancy, station occupancy and mobile phone usage metrics. </p> <p>Visionify's occupancy metrics suite can be used with the rest of our suite to enable different compliance policies or collect general planning data for your organization.</p> <p> </p> People &amp; Forklift Heatmap Event <p>Table: Occupancy Metrics Events and Detection Details</p> Scenario name Supported? Event Event Details More Info Occupancy Metrics \u2705 <code>People Headcount</code> People Headcount More details \u2705 <code>People &amp; Forklift Heatmap</code> Periodic Heatmap Event \u2705 <code>Desk Occupancy</code> Desk Occupancy \u2705 <code>Station Occupancy</code> Station Occupancy \u2705 <code>Phone Usage Metrics</code> Station Occupancy"},{"location":"overview/scenarios/#housekeeping","title":"Housekeeping","text":"<p>Visionify's Housekeeping Suite provides various hazard identifications on the work floor. These metrics include identifying spills and leaks on the floor, unattended objects, boxes or pallets on the floor, identifying door open/close events, blocked exits monitoring, missing fire-extinguishers etc. </p> <p>Housekeeping suite provides organization a second set of eyes for their regular audits. By identifying hazards early, this suite tends to avoid accidents and injuries.</p> <p> </p> Spills and Leaks Detection Example Event <p>Table: Housekeeping Events and Detection Details</p> Scenario name Supported? Event Event Details More Info Housekeeping \u2705 <code>Spills &amp; Leaks</code> Spills and Leaks More details \u2705 <code>Unattended Objects</code> Unattended Objects \u2705 <code>Unattended Pallet/Box</code> Unattended Pallet/Box \u2705 <code>Clean Pathway</code> Clean Pathway \u2705 <code>Blocked Exits</code> Blocked Exits \u2705 <code>Missing Fire Extinguisher</code> Missing Fire Extinguisher Event \u2705 <code>Door Open/Close</code> Door Open/Close Event"},{"location":"overview/scenarios/#behavioral-safety-suite","title":"Behavioral Safety Suite","text":"<p>Visionify's Behavioral Safety Suite focuses on identifying and correcting unsafe behaviors before they lead to accidents. This suite monitors various behavioral patterns including running in work areas, climbing on equipment or railings, smoking/vaping in prohibited areas, consuming food/drinks in restricted zones, and mobile phone usage in unsafe conditions. </p> <p>By detecting these unsafe behaviors early, organizations can provide timely interventions and training to promote safer work practices. The Behavioral Safety suite serves as a proactive tool for safety managers to reinforce safety protocols and maintain workplace discipline.</p> <p> </p> Mobile Phone Usage Detection Example Event <p>Table: Behavioral Safety Events and Detection Details</p> Scenario name Supported? Event Event Details More Info Behavioral Safety \u2705 <code>Running Detection</code> Person running in work area More details \u2705 <code>Climbing Detection</code> Person climbing on equipment/railings \u2705 <code>Smoking/Vaping Detection</code> Person smoking or vaping in prohibited area \u2705 <code>Food/Drinks Detection</code> Person with food/drinks in restricted area \u2705 <code>Mobile Phone Usage</code> Person using phone in unsafe conditions"},{"location":"overview/scenarios/#staircase-safety","title":"Staircase Safety","text":"<p>Visionify's Staircase Safety Suite focuses on preventing accidents and injuries in one of the most common yet hazardous areas of any facility - staircases. This suite monitors various unsafe behaviors including failure to use handrails, running on stairs, using mobile phones while climbing/descending, and skipping steps. These behaviors are leading causes of workplace accidents, often resulting in serious injuries.</p> <p>By identifying these risky behaviors in real-time, organizations can take proactive measures to prevent staircase-related incidents. The suite helps safety managers enforce proper staircase usage protocols and create awareness about safe staircase practices among employees.</p> <p>Table: Staircase Safety Events and Detection Details</p> Scenario name Supported? Event Event Details More Info Staircase Safety \u2705 <code>No Bannister Usage</code> Person not holding handrail while using stairs More details \u2705 <code>Running on Stairs</code> Person running on staircase \u2705 <code>Phone Usage on Stairs</code> Person using mobile phone while on stairs \u2705 <code>Skipping Steps</code> Person skipping steps while using stairs"},{"location":"overview/scenarios/#employee-privacy-face-blurring","title":"Employee Privacy (Face Blurring)","text":"<p>For a majority of organizations - employee privacy is a top concern. Along with employee privacy, the organization needs to make sure that any data does not leave the premises. Any faces detected through Vision AI system need to be blurred, along with text, signage, computer screens and other sensitive information.</p> <p>Before any other scenarios are run, or before we store or process the images - the images are pre-processed through this privacy suite. As such, privacy suite is treated differently from other scenarios. Below examples provide a high-level overview of the privacy suite.</p> <p>Table: Privacy Suite Events and Detection Details</p> Status Scenario name Details Details \u2705 <code>face-blurring</code> Blur any faces detected More details \u2705 <code>text-blurring</code> Blue any text detected (paper, computer screens etc) \u2705 <code>license-plate-blurring</code> Blur any license plates detected \ud83d\udcc5 <code>signs-blurring</code> Blur any signs detected \ud83d\udcc5 <code>obstructed-camera</code> If camera feed is obstructed, send an alert"},{"location":"overview/scenarios/#company-policies","title":"Company Policies","text":"<p>Company policies include specific scenarios that are relevant to your company. These could include scenarios like no-smoking/no-vaping zones, no food or drinks in certain areas, or no cell phones/pictures in certain areas. Some of these scenarios overlap with occupancy metrics, but they are still useful to have here as separate scenarios.</p> <p>Table: Company Policies Events and Detection Details</p> Status Scenario name Supported Events Details \ud83d\udcc5 <code>no-food-or-drinks-allowed</code> <code>Person with food detected</code> <code>Person with drinks detected</code> <code>Spill event detected</code> More details \ud83d\udcc5 <code>no-phone-text-pictures</code> <code>Cellphone usage detected</code> <code>Person detected taking pictures</code> More details \u2705 <code>no-smoking-or-vaping</code> <code>Smoking event detected</code> <code>Vaping event detected</code> More details \ud83d\udcc5 <code>no-children-pets-visitors</code> <code>Children detected</code> <code>Pets detected</code> <code>Visitors detected</code> More details"},{"location":"overview/scenarios/#suspicious-activity-detection","title":"Suspicious Activity detection","text":"<p>Suspicious activity detection suite includes knives &amp; firearms detection, graffitti &amp; vandalism detection etc.</p> <p>Table: Suspicious Activity Events and Detection Details</p> Status Scenario name Supported Events Details \ud83d\udcc5 <code>vandalism-graffiti</code> Vandalism or Graffiti detected More details \u2705 <code>firearms-knives</code> Firearm or Knife detected` More details"},{"location":"overview/scenarios/#next-steps","title":"Next Steps","text":"<ul> <li>Quick Start</li> <li>Camera Placement Guide</li> <li>Supported Scenarios</li> <li>Camera Management</li> <li>FAQs</li> </ul>"},{"location":"overview/scenarios/#contact-information","title":"Contact Information","text":"contact_phone Sales Inquiries <p>Get in touch with our sales team for demos and pricing information.</p> <ul> <li>Email: sales@visionify.ai</li> <li>Phone: +1 720-449-1124</li> </ul> support_agent Technical Support <p>Need help? Visit our support portal or contact our technical team.</p> <ul> <li>https://support.visionify.ai</li> <li>support@visionify.ai</li> </ul> calendar_month Schedule a Demo <p>See VisionAI in action with a personalized demo from our team.</p> event                 Book Your Demo              arrow_upward"},{"location":"overview/web-app-userguide/","title":"Visionai Web Application Instructions","text":""},{"location":"overview/web-app-userguide/#visionai-advanced-ai-for-enhanced-workplace-safety","title":"VisionAI: Advanced AI for Enhanced Workplace Safety","text":"<p>VisionAI by Visionify offers a dynamic web application designed to enhance workplace safety through advanced AI technology. VisionAI ensures enhanced workplace safety with minimal setup.</p>"},{"location":"overview/web-app-userguide/#main-functionalities-of-the-visionai-web-application","title":"Main Functionalities of the VisionAI Web Application:","text":""},{"location":"overview/web-app-userguide/#1camera-onboarding","title":"1.Camera Onboarding:","text":"<p>Easily onboard any IP cameras into the VisionAI system for complete workplace safety monitoring.</p>"},{"location":"overview/web-app-userguide/#2ai-scenario-management","title":"2.AI Scenario Management:","text":"<p>Pick and choose AI scenarios to run on your IP cameras, customized to your safety needs.</p>"},{"location":"overview/web-app-userguide/#3event-and-notification-configuration","title":"3.Event and Notification Configuration:","text":"<p>Configure events and set up notifications via email, text, and Teams to stay informed in real-time.</p>"},{"location":"overview/web-app-userguide/#4violation-recording","title":"4.Violation Recording:","text":"<p>Set up event-specific video recordings to capture and retain evidence of safety violations.</p> <p>VisionAI helps organizations enhance their safety measures by using advanced AI technology. This technology makes it easier to monitor and manage safety, ensuring that the workplace is both safer and meets regulations.</p>"},{"location":"overview/web-app-userguide/#basic-usage","title":"Basic Usage","text":"<ol> <li>Please open localhost in the browser.</li> <li>Use your default username/password as master/master.</li> <li>After this, you will be asked to create a new admin user. Please use a strong password and create an admin user.</li> </ol>"},{"location":"overview/web-app-userguide/#cameras","title":"Cameras","text":"<p>Once you are signed in, you will see a blank dashboard page.  Let\u2019s add an IP camera to the system. In order to do this, 1. Go to the \u201cCameras\u201d tab on the left menu bar. 2. Then Click on the  + button.</p> <p></p> <p>A new pop-up window will appear to add cameras. You can enter the camera name, description, and RTSP URL for the camera. The RTSP URL can be obtained from the Camera or NVR documentation. You can ignore the other fields as they are optional. Click on \u201cAdd\u201d button.</p> <p></p> <p>Once you have added the camera, it should appear on the Cameras window and should show the initial streaming for the camera. Add any additional cameras in a similar fashion. Once all cameras have been added, the front-screen should look like this:</p> <p></p>"},{"location":"overview/web-app-userguide/#scenarios","title":"Scenarios","text":"<p>Once you are signed in, you will see a blank dashboard page.  You may select any scenario from the list of active scenarios.</p> <p></p> <p>This shows details about the Scenario.You can now click on the \u201cGet this\u201d button again to apply the scenario to cameras.</p> <p></p> <p>In the next page, Select the Cameras for which you want to apply this scenario. Click \u201cSave and Next\u201d</p> <p></p> <p>Next, ensure you check the config box to proceed to the camera thumbnail. On the camera thumbnail page, create a zone directly. After creating the zone, click the \"Submit\" button to save your changes. Then, proceed by clicking on the \"Next\" button.</p> <p></p> <p>In the following step, mark the \"Select Events\" option, then click the \"Next\" button. You have successfully applied the scenario to the camera.</p> <p></p>"},{"location":"overview/web-app-userguide/#events","title":"Events","text":"<p>This page will show the list of events that have occurred in the selected time frame.</p> <p></p>"},{"location":"overview/web-app-userguide/#graphs","title":"Graphs","text":"<p>This page summarizes the events that occurred in the form of graphical representation.</p> <p></p> <p></p> <p></p>"},{"location":"overview/web-app-userguide/#settings","title":"Settings","text":"<ol> <li>User</li> </ol> <p>To enter the user settings, first locate and click on the user profile button at the top right corner of the screen. In the dropdown menu that appears, select 'Settings.' This action will open the user management page, allowing you to customize your preferences. On the user management  page, click on the 'Add User' button to create a new user.</p> <p></p> <p>This action will open the user management page. Click on the '+ Add User' button to create a new user.</p> <p></p> <p>After clicking on the '+ Add User' button, a user fields box will open. Fill in the required fields and click on the 'Submit' button.</p> <p></p> <p>An invitation email will be sent to the provided email address. The user should then create a password by accepting the invitation through the email.</p>"},{"location":"overview/web-app-userguide/#company","title":"Company","text":""},{"location":"overview/web-app-userguide/#step-1-navigate-to-the-company-section","title":"Step 1: Navigate to the Company Section","text":"<p>Log in to the system and go to the Company section from the main dashboard at user profile.</p>"},{"location":"overview/web-app-userguide/#step-2-select-the-site-option","title":"Step 2: Select the \"Site\" Option","text":"<p>In the Company section, click on the \"Site\" option. This will take you to the site management area.</p>"},{"location":"overview/web-app-userguide/#step-3-add-a-new-site","title":"Step 3: Add a New Site","text":"<p>In the Site section, you will see an option labeled \"Add New Site\". Click on this option, which will open a form where you can input the details for the new site.</p>"},{"location":"overview/web-app-userguide/#step-4-fill-in-the-required-site-details","title":"Step 4: Fill in the Required Site Details","text":"<p>Fill in all the required details in the form, such as: Site name Address Other relevant site information</p>"},{"location":"overview/web-app-userguide/#step-5-configure-site-options","title":"Step 5: Configure Site Options","text":"<p>After adding the site, you will have several configuration options for customizing the site:</p>"},{"location":"overview/web-app-userguide/#face-blur-option","title":"Face Blur Option:","text":"<p>If you prefer not to display faces in the site footage or data, enable the \"Face Blur\" option. This will automatically blur any faces captured in the data.</p>"},{"location":"overview/web-app-userguide/#full-body-blur-option","title":"Full Body Blur Option:","text":"<p>If you want to blur the entire body of individuals, enable the \"Full Body Blur\" option. This will blur the bodies of people in the site data or footage.</p>"},{"location":"overview/web-app-userguide/#site-map-upload","title":"Site Map Upload:","text":"<p>You can upload a site map to visually represent the site layout. To do this: Drag and drop the site map file into the designated area for map uploads. Ensure the file is in a supported format (e.g., PNG, JPG, or PDF).</p>"},{"location":"overview/web-app-userguide/#step-6-save-and-submit","title":"Step 6: Save and Submit","text":"<p>After entering all the site details and configuring the options: Review the information and configurations. Click on the Save button to save the site details and settings.</p>"},{"location":"overview/web-app-userguide/#step-7-final-step","title":"Step 7: Final Step","text":"<p>After saving, the new site, along with the selected configuration options (such as face/body blurring and site map), will be successfully added to the system.</p>"},{"location":"overview/web-app-userguide/#additional-notes","title":"Additional Notes:","text":"<p>Ensure that all required fields are completed before saving the site. If you encounter any issues or need to update the site later, you can always return to the \"Site\" section to make changes.</p> <p></p>"},{"location":"reference/alerts/","title":"Alerts &amp; Notifications","text":"<p>VisionAI provides comprehensive notification capabilities to ensure your team stays informed of safety events in real-time. This guide covers the various alert types and configuration options available through your Visionify App.</p>"},{"location":"reference/alerts/#alert-types","title":"Alert Types","text":"Daily Digest <p>Daily safety summary email.</p> Features: <ul> <li>Last Day summary</li> <li>Summary metrics</li> <li>Watch Trends</li> <li>Larger audience</li> </ul> Best For: <ul> <li>Safety managers</li> <li>Facility supervisors</li> <li>Management teams</li> </ul> Periodic Reports <p>Hourly, daily Email/Teams report.</p> Features: <ul> <li>CSV exports</li> <li>Custom schedules</li> <li>Area filtering</li> <li>Teams integration</li> </ul> Report Types: <ul> <li>Compliance data</li> <li>Incident reports</li> <li>Area analysis</li> </ul> Text Message <p>Instant SMS Alert for critical events.</p> Features: <ul> <li>Instant delivery</li> <li>Priority levels</li> <li>Team escalation</li> <li>Response tracking</li> </ul> Use Cases: <ul> <li>Emergency events</li> <li>Critical violations</li> <li>Urgent responses</li> </ul> Speaker <p>On-site audio alerts for immediate action.</p> Features: <ul> <li>Custom messages</li> <li>Multiple languages</li> <li>Zone-specific</li> <li>Volume control</li> </ul> Applications: <ul> <li>PPE violations</li> <li>Area restrictions</li> <li>Safety reminders</li> </ul>"},{"location":"reference/alerts/#alert-configuration","title":"Alert Configuration","text":"<p>Configure comprehensive notification settings through your dedicated observability platform at <code>customername.visionify.ai/observability</code>. VisionAI offers multiple alert types to ensure your team stays informed of safety events:</p> 1. Daily Digest Emails <p>Set up automated daily summaries of safety events, incidents, and compliance metrics. Perfect for management oversight and trend analysis.</p> 2. Periodic Reports <p>Schedule detailed reports with CSV attachments, delivered via email or Microsoft Teams. Customize reports by area, camera, or specific event types for targeted insights.</p> 3. Text Message Alerts <p>Enable real-time SMS notifications for immediate awareness of critical safety events. Ideal for urgent situations requiring immediate attention.</p> 4. Speaker Based Alerts <p>Configure automated audio announcements for real-time safety notifications in your facility. Perfect for immediate on-site response to safety events.</p> <p>Tip</p> <p>Combine multiple alert types for comprehensive coverage. For example, use speaker alerts for immediate on-site response, while keeping management informed through daily digests and periodic reports.</p>"},{"location":"reference/alerts/#next-steps","title":"Next Steps","text":"<ul> <li>Quick Start</li> <li>Camera Placement Guide</li> <li>Supported Scenarios</li> <li>Camera Management</li> <li>FAQs</li> </ul>"},{"location":"reference/alerts/#contact-information","title":"Contact Information","text":"Sales Inquiries <p>Get in touch with our sales team for demos and pricing information.</p> <ul> <li>Email: sales@visionify.ai</li> <li>Phone: +1 720-449-1124</li> </ul> Technical Support <p>Need help? Visit our support portal or contact our technical team.</p> <ul> <li>https://support.visionify.ai</li> <li>support@visionify.ai</li> </ul> Schedule a Demo <p>See VisionAI in action with a personalized demo from our team.</p> Book Your Demo"},{"location":"reference/azure-managed-app/","title":"Azure Managed App","text":"<p>VisionAI Azure Managed Application is a  pre-built cloud solution that is deployed through Azure Marketplace to an Azure environment for end customers. </p>"},{"location":"reference/azure-managed-app/#overview","title":"Overview","text":"<p>VisionAI Azure Managed application is designed to provide a fast and secure way to deliver applications and services to customers while ensuring consistency and control.</p> <p>Basically, Managed Applications is a packaged solution that include all the necessary resources and components, such as virtual machines, storage accounts, networking resources, and security configurations. </p>"},{"location":"reference/azure-managed-app/#access-visionai-app","title":"Access VisionAI App","text":"<p>VisionAI Azure App is accessible by logging into Azure Market Place.</p> <p> It shows its Overview, different plans and ratings. Once we click, Get it Now. Following screen appears.</p> <p></p> <p>Enter all your information and click on Continue. It takes you to your dashboard as:</p> <p></p> <p>In Basics tab, Enter your project details in the following screen.</p> <p></p> <p>If you have empty resource group, please select that otherwise create new by clicking on Create new.</p> <p></p> <p>Verify Virtual Machine Settings. Click on Review+create. It takes some time to perform validation.</p> <p>The Managed Applications can be customized with branding, pricing, and support offerings, allowing MSPs to differentiate their offerings and provide added value to their customers.</p> <p>In summary, Azure Managed Applications offer a simplified and streamlined way to deploy and manage pre-built cloud solutions, enabling customers to focus on their core business functions while leaving the management and maintenance of the underlying infrastructure to Microsoft.</p>"},{"location":"reference/changelog/","title":"Changelog","text":""},{"location":"reference/changelog/#visionai-changelog","title":"VisionAI Changelog","text":""},{"location":"reference/changelog/#030-december-18-2024","title":"0.3.0  December 18, 2024","text":"<ul> <li>\ud83c\udfa8 New layout for the site</li> <li>\ud83d\udd25 New JS/CSS to make readability better</li> <li>\ud83d\ude9a New navigation structure</li> <li>\ud83d\udcdd Added changelog</li> </ul>"},{"location":"reference/changelog/#020-february-14-2023","title":"0.2.0  February 14, 2023","text":"<ul> <li>\ud83d\udc9a Migrate all documentation to public site.</li> <li>\ud83c\udfa8 Added documentation for difference scenarios.</li> <li>\ud83d\ude9a Support for occupancy monitoring scenario.</li> <li>\ud83d\udd25 Support for better smoke-and-fire detection scenario.</li> </ul>"},{"location":"reference/changelog/#020-february-14-2023_1","title":"0.2.0  February 14, 2023","text":"<ul> <li>\ud83d\udc9a Migrate all documentation to public site.</li> <li>\ud83c\udfa8 Added documentation for difference scenarios.</li> <li>\ud83d\ude9a Support for occupancy monitoring scenario.</li> <li>\ud83d\udd25 Support for better smoke-and-fire detection scenario.</li> </ul>"},{"location":"reference/changelog/#0118-february-14-2023","title":"0.1.18  February 14, 2023","text":"<ul> <li>\ud83d\udc9a Added support for grafana and redis servers.</li> <li>\ud83c\udfa8 Added support for event engine, and publishing to redis</li> <li>\ud83d\ude9a Added commands for <code>visionai init|status|stop</code> which can install all dependencies.</li> <li>\ud83d\udd25 Removed dependency on torch and OpenCV packages. Now the package size goes down significantly.</li> <li>\ud83d\udcdd Updated documentation to reflect the changes.</li> <li>\u2728 Docker networking changes - now all containers connect to bridge network.</li> <li>\ud83d\udd25 Added support for slip-and-fall detection model.</li> <li>\ud83d\udd25 Added support for phone detection and people taking pictures scenarios.</li> </ul>"},{"location":"reference/changelog/#0117-february-9-2023","title":"0.1.17 February 9, 2023","text":"<ul> <li>\ud83d\udccc Added support for <code>visionai web start|stop|status</code> commands with API server support.</li> <li>Ensure We can pull visionify/visionai-api to local machine</li> <li>Run this as a container with model-repo/ and config/ folder shared.</li> <li>Ensure back-to-back stop/start would work.</li> <li>Ensure we can just do <code>web start</code> without doing <code>web install</code></li> <li>Removed <code>web install</code> as it can cause confusion</li> </ul>"},{"location":"reference/changelog/#0116-february-8-2023","title":"0.1.16 February 8, 2023","text":"<ul> <li>\u2728 Support for <code>visionai web start|stop|status</code> commands.</li> <li>\ud83c\udfa8 Pull latest images from dockerhub before starting web server.</li> <li>\ud83d\ude9a Support for alias for all commands (like <code>visionai camera add</code> and <code>visionai cameras add</code>)</li> <li>\ud83d\udd25 Add support for <code>face-blur</code> scenario. You can test it with <code>visionai scenario test face-blur</code> now.</li> <li>\ud83d\udcdd Tested support for Ubuntu (with NVIDIA graphics card), MacOS, and Windows 10.</li> </ul>"},{"location":"reference/changelog/#0115-february-7-2023","title":"0.1.15 February 7, 2023","text":"<ul> <li>\ud83d\udc1b On linux we were using incorrect nvidia_smi package.</li> <li>\ud83c\udfa8 Add support for common spelling errors during commands (like scenarios instead of scenario)</li> <li>\ud83d\ude9a Move scenario.json file to this repo - so everything is in one place.</li> </ul>"},{"location":"reference/changelog/#0114-february-3-2023","title":"0.1.14 February 3, 2023","text":"<ul> <li>\u2728 Support for <code>visionai scenario test</code> command.</li> <li>\u2728 Support for Triton server running on MacOS (tested)</li> <li>\ud83d\udd25 Simplified scenario command names (don't have to specify --name anymore)</li> <li>\ud83d\udcdd Renamed all cli files to _app - to avoid confusion between models.py &amp; models/ module.</li> <li>\ud83d\udcdd Move add-scenario and remove-scenario to camera module (these are camera operations.)</li> <li>\ud83d\udd25 Show nice progress bar while any docker image is being pulled.</li> <li>\ud83e\uddea Added results.show() method to detection that uses cv2.imshow() to show the results locally.</li> </ul>"},{"location":"reference/changelog/#0112-january-31-2023","title":"0.1.12 January 31, 2023","text":"<ul> <li>\u2728 Support for managing triton server</li> <li>\ud83c\udfa8 Start/stop triton server from CLI.</li> <li>\ud83d\udcdd Get/print models status coming from triton.</li> <li>\ud83d\udd25 Implemented pretty printing through rich library for models</li> <li>\ud83e\uddea CI Tests to test both before &amp; after package creation</li> <li>\ud83d\udc1b Fix versioning bug (that broke the previous version)</li> </ul>"},{"location":"reference/changelog/#0111-january-27-2023","title":"0.1.11 January 27, 2023","text":"<ul> <li>Support for Triton models (through http/grpc)</li> <li>Implemented yolov5 backend for triton</li> <li>Implemented Autoshape wrapper for NMS &amp; scaling</li> <li>Added easy test case for reproducing.</li> <li>Updated schema for models, fix test cases for it.</li> </ul>"},{"location":"reference/changelog/#0110-january-25-2023","title":"0.1.10 January 25, 2023","text":"<ul> <li>Implemented download models for scenarios</li> <li>Added cv2, torch, numpy dependencies for inference</li> <li>Added support for <code>--version</code> &amp; <code>--verbose</code> options to cli</li> <li>CLI Test cases to use <code>python -m visionai</code> to replicate user behavior</li> </ul>"},{"location":"reference/changelog/#017-january-24-2023","title":"0.1.7 January 24, 2023","text":"<ul> <li>Implemented scenarios functionality</li> <li>Docker compose integration</li> <li>Makefile integration</li> </ul>"},{"location":"reference/changelog/#017-january-22-2023","title":"0.1.7 January 22, 2023","text":"<ul> <li>Implemented camera add/delete functionality</li> </ul>"},{"location":"reference/changelog/#016-january-20-2023","title":"0.1.6 January 20, 2023","text":"<ul> <li>Implemented initial set of commands in different files (dummy implementation)</li> <li>Testing commands individually or through the main application</li> </ul>"},{"location":"reference/changelog/#013-january-16-2023","title":"0.1.3 January 16, 2023","text":"<ul> <li>Basic overview and usage documentation is updated.</li> <li>Started using a termy JS script to show terminal animations nicely</li> </ul>"},{"location":"reference/changelog/#012-january-14-20123","title":"0.1.2 January 14, 20123","text":"<ul> <li>Made MkDocs documents based on Typer format</li> <li>Registered CNAME to point to https://docs.visionify.ai</li> </ul>"},{"location":"reference/changelog/#011-january-11-2023","title":"0.1.1 January 11, 2023","text":"<ul> <li>Updated Azure DevOps CI/CD to automatically publish package on each merge</li> <li>Initial set of commands for visionai application</li> <li>Made <code>visionai</code> as a callable CLI application through poetry</li> </ul>"},{"location":"reference/changelog/#010-january-10-2023","title":"0.1.0 January 10, 2023","text":"<ul> <li>Initial release: <code>pip install visionai</code></li> <li>Pushed package to <code>PyPI</code> repository</li> </ul>"},{"location":"reference/changelog/#contact-information","title":"Contact Information","text":"contact_phone Sales Inquiries <p>Get in touch with our sales team for demos and pricing information.</p> <ul> <li>Email: sales@visionify.ai</li> <li>Phone: +1 720-449-1124</li> </ul> support_agent Technical Support <p>Need help? Visit our support portal or contact our technical team.</p> <ul> <li>https://support.visionify.ai</li> <li>support@visionify.ai</li> </ul> calendar_month Schedule a Demo <p>See VisionAI in action with a personalized demo from our team.</p> event                 Book Your Demo"},{"location":"reference/customization/","title":"Customization and Private Models","text":"<p>Our out of box models are sufficient for most of the sceanrios. However, we understand that every industry has unique requirements. We offer customization services to help you address your specific challenges.</p> <p> </p> Enterprise-grade monitoring and analytics dashboard"},{"location":"reference/customization/#why-choose-visionai-for-enterprise","title":"Why Choose VisionAI for Enterprise?","text":"<p>Our enterprise solution offers:</p> <ul> <li>Industry-Specific Models: Pre-trained for manufacturing, construction, warehousing &amp; logistics</li> <li>Customizable Workflows: Adapt to your existing processes and compliance requirements</li> <li>Enterprise-Grade Security: SOC-2 compliant with end-to-end encryption</li> <li>Seamless Integration: Works with existing camera infrastructure and business systems</li> <li>Privacy First: Built-in privacy controls including face blurring and data protection</li> <li>24/7 Support: Dedicated enterprise support team and SLA guarantees</li> </ul>"},{"location":"reference/customization/#enterprise-features","title":"Enterprise Features","text":""},{"location":"reference/customization/#1-comprehensive-monitoring-analytics","title":"1. Comprehensive Monitoring &amp; Analytics","text":"Enterprise-grade architecture with Azure integration <ul> <li>Real-Time Dashboard: <ul> <li>Monitor all locations from a single console</li> </ul> </li> <li>Advanced Analytics: <ul> <li>Customizable reports and KPIs</li> <li>Trend analysis and predictive insights</li> <li>Compliance tracking and documentation</li> </ul> </li> <li>Intelligent Alerts: <ul> <li>Multi-channel notifications (Email, SMS, Teams)</li> <li>Role-based alert routing</li> <li>Customizable alert thresholds</li> </ul> </li> </ul>"},{"location":"reference/customization/#2-enterprise-grade-customization","title":"2. Enterprise-Grade Customization","text":"<p>Our enterprise customization services include:</p> <ol> <li> <p>Industry-Specific Model Training</p> <ul> <li>Custom data collection and labeling</li> <li>Model fine-tuning for your specific use cases</li> <li>Continuous model improvement</li> </ul> </li> <li> <p>Integration Services</p> <ul> <li>ERP/CMMS integration</li> <li>Azure IoT Hub connectivity</li> <li>Custom API development</li> </ul> </li> <li> <p>Workflow Automation</p> <ul> <li>Custom reporting workflows</li> <li>Automated compliance documentation</li> <li>Integration with existing safety processes</li> </ul> </li> </ol>"},{"location":"reference/customization/#3-enterprise-support-services","title":"3. Enterprise Support &amp; Services","text":"<ul> <li> <p>Dedicated Success Team:</p> <ul> <li>Implementation planning</li> <li>Training and onboarding</li> <li>Ongoing optimization support</li> </ul> </li> <li> <p>SLA Guarantees:</p> <ul> <li>99.9% uptime guarantee</li> <li>24/7 technical support</li> <li>Regular system health checks</li> </ul> </li> <li> <p>Security &amp; Compliance:</p> <ul> <li>SOC-2 Type 2 certified</li> <li>GDPR compliant</li> <li>Regular security audits</li> </ul> </li> </ul>"},{"location":"reference/customization/#enterprise-license-terms","title":"Enterprise License Terms","text":"<p>Our enterprise license includes:</p> <ul> <li>Unlimited users and locations</li> <li>Custom model training rights</li> <li>Source code access (optional)</li> <li>API access and integration rights</li> <li>Custom feature development</li> <li>Priority support and updates</li> </ul>"},{"location":"reference/customization/#success-stories","title":"Success Stories","text":"<p>\"VisionAI has transformed our safety operations. We've seen a 60% reduction in safety incidents and significant improvements in compliance tracking.\" - Safety Director, Fortune 500 Manufacturer</p> <p>\"The customization capabilities allowed us to address our specific industry challenges. The ROI was evident within the first quarter.\" - VP Operations, Global Logistics Company</p>"},{"location":"reference/customization/#getting-started-with-enterprise","title":"Getting Started with Enterprise","text":"<ol> <li>Discovery Call: Understand your specific needs and use cases</li> <li>Custom Demo: See VisionAI in action with your scenarios</li> <li>Pilot Program: Start with a controlled pilot in your facility</li> <li>Full Deployment: Scale across your organization</li> </ol>"},{"location":"reference/customization/#learn-more","title":"Learn More","text":"<ul> <li>Quick Start</li> <li>Camera Placement Guide</li> <li>Supported Scenarios</li> <li>Camera Management</li> <li>FAQs</li> </ul>"},{"location":"reference/customization/#contact-information","title":"Contact Information","text":"contact_phone Sales Inquiries <p>Get in touch with our sales team for demos and pricing information.</p> <ul> <li>Email: sales@visionify.ai</li> <li>Phone: +1 720-449-1124</li> </ul> support_agent Technical Support <p>Need help? Visit our support portal or contact our technical team.</p> <ul> <li>https://support.visionify.ai</li> <li>support@visionify.ai</li> </ul> calendar_month Schedule a Demo <p>See VisionAI in action with a personalized demo from our team.</p> event                 Book Your Demo              <p>VisionAI - Enterprise-grade computer vision for workplace safety and compliance</p>"},{"location":"reference/deployment/","title":"Deployment Options","text":"<p>VisionAI offers flexible deployment options to meet your organization's specific requirements for security, privacy, and infrastructure. Choose from our three deployment models based on your needs for data residency, connectivity, and system integration.</p> <p> </p> VisionAI Deployment Options including Solution in a Box, SaaS and Enterprise Application"},{"location":"reference/deployment/#available-deployment-models","title":"Available Deployment Models","text":"Solution in a Box Highest Security <p>Complete on-premise solution with maximum security and privacy.</p> Key Features: <ul> <li>Edge server contains entire solution</li> <li>Highest security and privacy</li> <li>Operates within intranet only</li> <li>Zero cloud costs</li> <li>Limited connectivity</li> <li>Limited notifications &amp; reporting</li> </ul> Visionify SaaS Most Flexible <p>Quick deployment with full features and cloud-based management.</p> Key Features: <ul> <li>Edge server for inference</li> <li>Cloud-based webapp &amp; database</li> <li>Quick &amp; flexible deployment</li> <li>Complete notifications &amp; reporting</li> <li>Managed video storage</li> <li>Data resides in Visionify Cloud</li> </ul> Enterprise App Full Control <p>Deploy in your cloud infrastructure with complete control.</p> Key Features: <ul> <li>Edge server for inference</li> <li>Your cloud infrastructure</li> <li>Single tenant deployment</li> <li>Complete notifications &amp; reporting</li> <li>Use existing cloud pricing</li> <li>Full data residency control</li> </ul>"},{"location":"reference/deployment/#deployment-comparison","title":"Deployment Comparison","text":"Feature Solution in a Box Visionify SaaS Enterprise Application Deployment Time 1-2 Week 1-2 Week 3-4 Weeks Data Residency On-premise only Visionify Cloud Customer Cloud Security Level Highest High High Connectivity Required Intranet only Internet Internet Notifications Basic Full Full Reporting Basic Advanced Advanced Infrastructure Costs Lowest Medium Custom"},{"location":"reference/deployment/#next-steps","title":"Next Steps","text":"<ul> <li>Quick Start</li> <li>Camera Placement Guide</li> <li>Supported Scenarios</li> <li>Camera Management</li> <li>FAQs</li> </ul>"},{"location":"reference/deployment/#contact-information","title":"Contact Information","text":"Sales Inquiries <p>Get in touch with our sales team for demos and pricing information.</p> <ul> <li>Email: sales@visionify.ai</li> <li>Phone: +1 720-449-1124</li> </ul> Technical Support <p>Need help? Visit our support portal or contact our technical team.</p> <ul> <li>https://support.visionify.ai</li> <li>support@visionify.ai</li> </ul> Schedule a Demo <p>See VisionAI in action with a personalized demo from our team.</p> Book Your Demo"},{"location":"reference/privacy/","title":"Visoinify's Comprehensive Privacy Measures","text":"<p>Protect sensitive information and ensure compliance with our suite of privacy solutions.</p>"},{"location":"reference/privacy/#business-impact","title":"Business Impact","text":"<p>In today's digital landscape, safeguarding sensitive information is paramount. Organizations face:</p> <ul> <li>Increasing privacy regulations (GDPR, CCPA, PIPEDA)</li> <li>Risks of confidential data exposure</li> <li>Compliance requirements for document and video privacy</li> <li>Growing concerns about corporate espionage</li> </ul> <p>Our Vision AI solutions help enterprises:</p> <ul> <li>Ensure Compliance: Meet privacy regulations across jurisdictions</li> <li>Reduce Risk: Minimize liability from unauthorized data exposure</li> <li>Protect IP: Safeguard confidential business information</li> <li>Build Trust: Demonstrate commitment to stakeholder privacy</li> </ul>"},{"location":"reference/privacy/#face-blurring","title":"Face Blurring","text":"<p>Ensure GDPR compliance and protect individual privacy with intelligent Vision AI</p> <p> </p> Face blur as part of preprocessing <p>Our automated face blurring solution helps enterprises:</p> <ul> <li>Maintain Security: Keep video monitoring capabilities while protecting privacy</li> <li>Real-Time Processing: Immediate face detection and blurring</li> <li>Multi-Camera Support: Scale across all your video feeds</li> </ul>"},{"location":"reference/privacy/#blur-signs-and-text","title":"Blur Signs and Text","text":"<p>Safeguard Sensitive Information with Intelligent Text Blurring Technology</p> <p> </p> Text blur as part of preprocessing <p>Visionify's Document Privacy Suite uses advanced Vision AI to automatically detect and blur sensitive text, documents, and signage in real-time:</p> <ul> <li>Intelligent Detection: Automatically identifies text and documents</li> <li>Real-Time Blurring: Immediate obscuring of sensitive information</li> <li>Multi-Format Support: Works with documents, signs, screens, and more</li> </ul>"},{"location":"reference/privacy/#blur-screens","title":"Blur Screens","text":"<p>Ensure the privacy of individuals by obscuring computer monitor and other gadget screens in camera feeds</p> <p>Blurring computer monitor screens is a common technique used to protect the privacy of individuals in images and videos:</p> <ul> <li>Vision AI-based Monitoring: Obscures alphanumeric characters on screens</li> <li>Protects PII and Trade Secrets: Ensures sensitive data is unreadable</li> </ul>"},{"location":"reference/privacy/#license-plate-blurring","title":"License Plate Blurring","text":"<p>Ensure the privacy of vehicle owners in images and videos by blurring license plates</p> <p> </p> Licence-plate blur as part of preprocessing <p>Our license plate blurring technology helps protect the privacy and security of individuals:</p> <ul> <li>Real-Time Detection: Obscures license plates in images and videos</li> <li>High Accuracy: Uses YOLOv5 algorithm for precise detection</li> </ul>"},{"location":"reference/privacy/#obstructed-camera-view-detection","title":"Obstructed Camera View Detection","text":"<p>Keep your camera view clear with our obstructed camera detection model.</p> <p> </p> Detection of obstructed camera event <p>The obstructed camera detection model ensures clear camera views by detecting obstructions:</p> <ul> <li>Real-Time Monitoring: Detects various types of obstructions</li> <li>High Accuracy: Utilizes deep learning techniques for precise detection</li> </ul>"},{"location":"reference/privacy/#getting-started","title":"Getting Started","text":"<ol> <li>Schedule a Demo</li> <li>Receive Custom Implementation Plan</li> <li>Deploy with Expert Support</li> </ol>"},{"location":"reference/privacy/#next-steps","title":"Next Steps","text":"<ul> <li>Quick Start</li> <li>Camera Placement Guide</li> <li>Supported Scenarios</li> <li>Camera Management</li> <li>FAQs</li> </ul>"},{"location":"reference/privacy/#contact-information","title":"Contact Information","text":"contact_phone Sales Inquiries <p>Get in touch with our sales team for demos and pricing information.</p> <ul> <li>Email: sales@visionify.ai</li> <li>Phone: +1 720-449-1124</li> </ul> support_agent Technical Support <p>Need help? Visit our support portal or contact our technical team.</p> <ul> <li>https://support.visionify.ai</li> <li>support@visionify.ai</li> </ul> calendar_month Schedule a Demo <p>See VisionAI in action with a personalized demo from our team.</p> event                 Book Your Demo"},{"location":"reference/reference/","title":"VisionAI API Reference","text":"<p>Below is a list of commands that are available in the toolkit. Right now, we are making this available to clients on a need basis. The same  would be available through APIs to all clients in the future.</p> <p>VisionAI tookit provides a large number of ready-to-deploy scenarios built using latest computer vision frameworks. Supports many of the common workplace health and safety use-cases.</p> <p>Running the toolkit does assume a NVIDIA GPU powered machine for efficient performance. Please see the system requirements on the documentation.</p> <p>You can instead opt to install it through Azure Managed VM, with preconfigured machines &amp; recommended hardware support. You can find information about this on our documentation website.</p> <p>Visit https://docs.visionify.ai for more details.</p> <p>Usage:</p> <pre><code>$ visionai [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--verbose</code>: [default: False]</li> <li><code>--version</code>: [default: False]</li> <li><code>--install-completion</code>: Install completion for the current shell.</li> <li><code>--show-completion</code>: Show completion for the current shell, to copy it or customize the installation.</li> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <pre><code>\u256d\u2500 Commands \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e\n\u2502 auth         Authentication commands                           \u2502\n\u2502 camera       Add/remove/manage cameras                         \u2502\n\u2502 device       Device commands                                   \u2502\n\u2502 init         Initialize VisionAI library                       \u2502\n\u2502 model        Manage models                                     \u2502\n\u2502 pipeline     Manage pipelines                                  \u2502\n\u2502 scenario     Add/remove scenarios to camera                    \u2502\n\u2502 status       Print status of all running containers.           \u2502\n\u2502 stop         Stop all running containers.                      \u2502\n\u2502 web          Start/stop web server                             \u2502\n\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\n</code></pre>"},{"location":"reference/reference/#visionai-auth","title":"<code>visionai auth</code>","text":"<p>Authorization (logging in/out)</p> <p>Login and get authorization token etc.</p> <p>You can login/logout check authorization token with this.</p> <p>Usage:</p> <pre><code>$ visionai auth [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>login</code>: Login with an application token.</li> <li><code>logout</code>: Logout from your session Get the auth token...</li> <li><code>status</code>: Check login status Check the current login...</li> </ul>"},{"location":"reference/reference/#visionai-auth-login","title":"<code>visionai auth login</code>","text":"<p>Login with an application token.</p> <p>Get the auth token from our website</p> <p>Usage:</p> <pre><code>$ visionai auth login [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--token TEXT</code>: Authenticate the app through token  [required]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-auth-logout","title":"<code>visionai auth logout</code>","text":"<p>Logout from your session</p> <p>Get the auth token from our website</p> <p>Usage:</p> <pre><code>$ visionai auth logout [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-auth-status","title":"<code>visionai auth status</code>","text":"<p>Check login status</p> <p>Check the current login system.</p> <p>Usage:</p> <pre><code>$ visionai auth status [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-camera","title":"<code>visionai camera</code>","text":"<p>Manage cameras</p> <p>An organization can have multiple cameras that are installed at different places. They may be from different vendors and/or maybe using different security surveillance software. Most cameras however do support RTSP, RTMP or HLS streams as an output. Please refer to your camera vendor documentation to find this out. This module will help you onboard those cameras on visionai systems by using a simple named instance for each camera.</p> <p>Usage:</p> <pre><code>$ visionai camera [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>add</code>: Add a named camera instance Add a camera as a...</li> <li><code>add-scenario</code>: Add a scenario for a camera Add an individual...</li> <li><code>list</code>: List available cameras Print cameras...</li> <li><code>list-scenario</code>: List scenarios configured for a camera</li> <li><code>list-scenarios</code>: List scenarios configured for a camera</li> <li><code>preview</code>: Preview the camera system View the camera...</li> <li><code>remove</code>: Remove a camera from the system Specify a...</li> <li><code>remove-scenario</code>: Remove a scenario from a camera Specify a...</li> <li><code>reset</code>: Reset all camera configuration.</li> </ul>"},{"location":"reference/reference/#visionai-camera-add","title":"<code>visionai camera add</code>","text":"<p>Add a named camera instance</p> <p>Add a camera as a named instance in the system. For adding a camera we support RTSP, HLS, HTTP(S) systems. To add a camera you need to provide a name for the camera, URI for the camera (including any username/password within the URI itself), description for camera (about its location, where its pointing, who is the vendor etc.).</p> <p>Before the camera is added - we need to test out if the camera instance is valid. We need to be able to read from the camera and calculate its FPS. Show this information on the screen.</p> <p>Usage:</p> <pre><code>$ visionai camera add [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--name TEXT</code>: Camera Name  [required]</li> <li><code>--uri TEXT</code>: URI for camera  [required]</li> <li><code>--description TEXT</code>: Description  [required]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-camera-add-scenario","title":"<code>visionai camera add-scenario</code>","text":"<p>Add a scenario for a camera</p> <p>Add an individual scenario to be run for a camera. Specify the names for scenario and camera.</p> <p>Usage:</p> <pre><code>$ visionai camera add-scenario [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--camera TEXT</code>: camera name  [required]</li> <li><code>--scenario TEXT</code>: scenario name  [required]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-camera-list","title":"<code>visionai camera list</code>","text":"<p>List available cameras</p> <p>Print cameras available in the system and the scenarios / routines that are set up for them.</p> <p>Usage:</p> <pre><code>$ visionai camera list [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-camera-list-scenario","title":"<code>visionai camera list-scenario</code>","text":"<p>List scenarios configured for a camera</p> <p>Usage:</p> <pre><code>$ visionai camera list-scenario [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--camera TEXT</code>: Camera name  [default: ]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-camera-list-scenarios","title":"<code>visionai camera list-scenarios</code>","text":"<p>List scenarios configured for a camera</p> <p>Usage:</p> <pre><code>$ visionai camera list-scenarios [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--camera TEXT</code>: Camera name  [default: ]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-camera-preview","title":"<code>visionai camera preview</code>","text":"<p>Preview the camera system</p> <p>View the camera feed, review FPS etc available for camera.</p> <p>Usage:</p> <pre><code>$ visionai camera preview [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--name TEXT</code>: camera name to preview  [required]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-camera-remove","title":"<code>visionai camera remove</code>","text":"<p>Remove a camera from the system</p> <p>Specify a named camera that needs to be removed from the system. Once removed, all the scenarios and pre-process routines associated with the camera will be removed.</p> <p>Usage:</p> <pre><code>$ visionai camera remove [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--name TEXT</code>: [default: Camera name]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-camera-remove-scenario","title":"<code>visionai camera remove-scenario</code>","text":"<p>Remove a scenario from a camera</p> <p>Specify a named scenario that needs to be removed from the system. Once removed, all the scenarios and pre-process routines associated with the scenario will be removed.</p> <p>Usage:</p> <pre><code>$ visionai camera remove-scenario [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--camera TEXT</code>: camera  [required]</li> <li><code>--scenario TEXT</code>: scenario name  [required]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-camera-reset","title":"<code>visionai camera reset</code>","text":"<p>Reset all camera configuration.</p> <p>All cameras and their scenarios would be removed from the system. Any earlier configuration is backed up as a timed json backup file.</p> <p>Usage:</p> <pre><code>$ visionai camera reset [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--confirm / --no-confirm</code>: Confirm delete  [default: False]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-cameras","title":"<code>visionai cameras</code>","text":"<p>... alias for camera</p> <p>Usage:</p> <pre><code>$ visionai cameras [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>add</code>: Add a named camera instance Add a camera as a...</li> <li><code>add-scenario</code>: Add a scenario for a camera Add an individual...</li> <li><code>list</code>: List available cameras Print cameras...</li> <li><code>list-scenario</code>: List scenarios configured for a camera</li> <li><code>list-scenarios</code>: List scenarios configured for a camera</li> <li><code>preview</code>: Preview the camera system View the camera...</li> <li><code>remove</code>: Remove a camera from the system Specify a...</li> <li><code>remove-scenario</code>: Remove a scenario from a camera Specify a...</li> <li><code>reset</code>: Reset all camera configuration.</li> </ul>"},{"location":"reference/reference/#visionai-cameras-add","title":"<code>visionai cameras add</code>","text":"<p>Add a named camera instance</p> <p>Add a camera as a named instance in the system. For adding a camera we support RTSP, HLS, HTTP(S) systems. To add a camera you need to provide a name for the camera, URI for the camera (including any username/password within the URI itself), description for camera (about its location, where its pointing, who is the vendor etc.).</p> <p>Before the camera is added - we need to test out if the camera instance is valid. We need to be able to read from the camera and calculate its FPS. Show this information on the screen.</p> <p>Usage:</p> <pre><code>$ visionai cameras add [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--name TEXT</code>: Camera Name  [required]</li> <li><code>--uri TEXT</code>: URI for camera  [required]</li> <li><code>--description TEXT</code>: Description  [required]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-cameras-add-scenario","title":"<code>visionai cameras add-scenario</code>","text":"<p>Add a scenario for a camera</p> <p>Add an individual scenario to be run for a camera. Specify the names for scenario and camera.</p> <p>Usage:</p> <pre><code>$ visionai cameras add-scenario [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--camera TEXT</code>: camera name  [required]</li> <li><code>--scenario TEXT</code>: scenario name  [required]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-cameras-list","title":"<code>visionai cameras list</code>","text":"<p>List available cameras</p> <p>Print cameras available in the system and the scenarios / routines that are set up for them.</p> <p>Usage:</p> <pre><code>$ visionai cameras list [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-cameras-list-scenario","title":"<code>visionai cameras list-scenario</code>","text":"<p>List scenarios configured for a camera</p> <p>Usage:</p> <pre><code>$ visionai cameras list-scenario [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--camera TEXT</code>: Camera name  [default: ]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-cameras-list-scenarios","title":"<code>visionai cameras list-scenarios</code>","text":"<p>List scenarios configured for a camera</p> <p>Usage:</p> <pre><code>$ visionai cameras list-scenarios [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--camera TEXT</code>: Camera name  [default: ]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-cameras-preview","title":"<code>visionai cameras preview</code>","text":"<p>Preview the camera system</p> <p>View the camera feed, review FPS etc available for camera.</p> <p>Usage:</p> <pre><code>$ visionai cameras preview [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--name TEXT</code>: camera name to preview  [required]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-cameras-remove","title":"<code>visionai cameras remove</code>","text":"<p>Remove a camera from the system</p> <p>Specify a named camera that needs to be removed from the system. Once removed, all the scenarios and pre-process routines associated with the camera will be removed.</p> <p>Usage:</p> <pre><code>$ visionai cameras remove [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--name TEXT</code>: [default: Camera name]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-cameras-remove-scenario","title":"<code>visionai cameras remove-scenario</code>","text":"<p>Remove a scenario from a camera</p> <p>Specify a named scenario that needs to be removed from the system. Once removed, all the scenarios and pre-process routines associated with the scenario will be removed.</p> <p>Usage:</p> <pre><code>$ visionai cameras remove-scenario [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--camera TEXT</code>: camera  [required]</li> <li><code>--scenario TEXT</code>: scenario name  [required]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-cameras-reset","title":"<code>visionai cameras reset</code>","text":"<p>Reset all camera configuration.</p> <p>All cameras and their scenarios would be removed from the system. Any earlier configuration is backed up as a timed json backup file.</p> <p>Usage:</p> <pre><code>$ visionai cameras reset [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--confirm / --no-confirm</code>: Confirm delete  [default: False]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-device","title":"<code>visionai device</code>","text":"<p>Manage device features</p> <p>Since scenarios run on individual edge-devices, and we don't have enough control over the CPU, Memory, GPU statistics - it is imperative that we have strong methods for validating if a scenario can run on a chosen platform. This module provides many utilities to check CPU, Memory and GPU statistics for the edge device. We also provide an Azure Managed service where these scenarios can be configured and run on your premise on pre-validated VM machines.</p> <p>Usage:</p> <pre><code>$ visionai device [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>list</code>: List available devices Get a list of all...</li> <li><code>modules</code>: List running modules on the device Again this...</li> <li><code>select</code>: Select a device Not sure why is this needed...</li> <li><code>stats</code>: Machine health (GPU/Mem stats) Show machine...</li> </ul>"},{"location":"reference/reference/#visionai-device-list","title":"<code>visionai device list</code>","text":"<p>List available devices</p> <p>Get a list of all available [processing] devices</p> <p>Usage:</p> <pre><code>$ visionai device list [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-device-modules","title":"<code>visionai device modules</code>","text":"<p>List running modules on the device</p> <p>Again this does not make much sense at this time. Let's revisit.</p> <p>Usage:</p> <pre><code>$ visionai device modules [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-device-select","title":"<code>visionai device select</code>","text":"<p>Select a device</p> <p>Not sure why is this needed at this time.</p> <p>Usage:</p> <pre><code>$ visionai device select [OPTIONS] DEVICE\n</code></pre> <p>Arguments:</p> <ul> <li><code>DEVICE</code>: [required]</li> </ul> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-device-stats","title":"<code>visionai device stats</code>","text":"<p>Machine health (GPU/Mem stats)</p> <p>Show machine health (GPU/memory stats). This can be used to determine if more scenarios can be run on the machine or not.</p> <p>Usage:</p> <pre><code>$ visionai device stats [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-devices","title":"<code>visionai devices</code>","text":"<p>... alias for device</p> <p>Usage:</p> <pre><code>$ visionai devices [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>list</code>: List available devices Get a list of all...</li> <li><code>modules</code>: List running modules on the device Again this...</li> <li><code>select</code>: Select a device Not sure why is this needed...</li> <li><code>stats</code>: Machine health (GPU/Mem stats) Show machine...</li> </ul>"},{"location":"reference/reference/#visionai-devices-list","title":"<code>visionai devices list</code>","text":"<p>List available devices</p> <p>Get a list of all available [processing] devices</p> <p>Usage:</p> <pre><code>$ visionai devices list [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-devices-modules","title":"<code>visionai devices modules</code>","text":"<p>List running modules on the device</p> <p>Again this does not make much sense at this time. Let's revisit.</p> <p>Usage:</p> <pre><code>$ visionai devices modules [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-devices-select","title":"<code>visionai devices select</code>","text":"<p>Select a device</p> <p>Not sure why is this needed at this time.</p> <p>Usage:</p> <pre><code>$ visionai devices select [OPTIONS] DEVICE\n</code></pre> <p>Arguments:</p> <ul> <li><code>DEVICE</code>: [required]</li> </ul> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-devices-stats","title":"<code>visionai devices stats</code>","text":"<p>Machine health (GPU/Mem stats)</p> <p>Show machine health (GPU/memory stats). This can be used to determine if more scenarios can be run on the machine or not.</p> <p>Usage:</p> <pre><code>$ visionai devices stats [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-model","title":"<code>visionai model</code>","text":"<p>Serve models</p> <p>Before we can run any scenarios - the models necessary for them must be ready. We use Triton inference server to make the best use of GPU/CPU resources available on the machine in order to serve our models. Any models that are available in models-repo folder would be served after this (TODO - only serve models configured in scenarios).</p> <p>Usage:</p> <pre><code>$ visionai model [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>check</code>: Check model-server status &amp; print helpful...</li> <li><code>serve</code>: Start serving all available models.</li> <li><code>start</code>: Start serving all available models.</li> <li><code>status</code>: Show the status of serving models Shows how...</li> <li><code>stop</code>: Stop serving all models.</li> </ul>"},{"location":"reference/reference/#visionai-model-check","title":"<code>visionai model check</code>","text":"<p>Check model-server status &amp; print helpful debug info.</p> <p>TODO: Goal of the check command is to identify any configuration/dependency issues that we can inform to user that he can fix on his end. This could be like missing dependency, missing software package, missing driver details etc.</p> <ul> <li>Check if model-server is running or not.</li> <li>Check if triton-client can access model-server</li> <li>Check what are the models served</li> <li>Print all of this in a pretty manner [checkbox based]</li> <li>Check container logs &amp; show them here.</li> <li>grep container logs for common errors &amp; highlight that in output</li> </ul> <p>Usage:</p> <pre><code>$ visionai model check [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-model-serve","title":"<code>visionai model serve</code>","text":"<p>Start serving all available models.</p> <p>All models present in the models-repo/ will be served. We use triton inference server to serve them. The triton server will be at http://localhost:8000, grpc://localhost:8001.</p> <p>Please make sure these two ports are not used by anyone else.</p> <p>Usage:</p> <pre><code>$ visionai model serve [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-model-start","title":"<code>visionai model start</code>","text":"<p>Start serving all available models.</p> <p>All models present in the models-repo/ will be served. We use triton inference server to serve them. The triton server will be at http://localhost:8000, grpc://localhost:8001.</p> <p>Please make sure these two ports are not used by anyone else.</p> <p>Usage:</p> <pre><code>$ visionai model start [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-model-status","title":"<code>visionai model status</code>","text":"<p>Show the status of serving models</p> <p>Shows how many models are being served, metrics for the models etc.</p> <p>Usage:</p> <pre><code>$ visionai model status [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-model-stop","title":"<code>visionai model stop</code>","text":"<p>Stop serving all models.</p> <p>This method will stop serving all models. Any inference running will all be stopped as well.</p> <p>Usage:</p> <pre><code>$ visionai model stop [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-models","title":"<code>visionai models</code>","text":"<p>... alias for model</p> <p>Usage:</p> <pre><code>$ visionai models [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>check</code>: Check model-server status &amp; print helpful...</li> <li><code>serve</code>: Start serving all available models.</li> <li><code>start</code>: Start serving all available models.</li> <li><code>status</code>: Show the status of serving models Shows how...</li> <li><code>stop</code>: Stop serving all models.</li> </ul>"},{"location":"reference/reference/#visionai-models-check","title":"<code>visionai models check</code>","text":"<p>Check model-server status &amp; print helpful debug info.</p> <p>TODO: Goal of the check command is to identify any configuration/dependency issues that we can inform to user that he can fix on his end. This could be like missing dependency, missing software package, missing driver details etc.</p> <ul> <li>Check if model-server is running or not.</li> <li>Check if triton-client can access model-server</li> <li>Check what are the models served</li> <li>Print all of this in a pretty manner [checkbox based]</li> <li>Check container logs &amp; show them here.</li> <li>grep container logs for common errors &amp; highlight that in output</li> </ul> <p>Usage:</p> <pre><code>$ visionai models check [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-models-serve","title":"<code>visionai models serve</code>","text":"<p>Start serving all available models.</p> <p>All models present in the models-repo/ will be served. We use triton inference server to serve them. The triton server will be at http://localhost:8000, grpc://localhost:8001.</p> <p>Please make sure these two ports are not used by anyone else.</p> <p>Usage:</p> <pre><code>$ visionai models serve [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-models-start","title":"<code>visionai models start</code>","text":"<p>Start serving all available models.</p> <p>All models present in the models-repo/ will be served. We use triton inference server to serve them. The triton server will be at http://localhost:8000, grpc://localhost:8001.</p> <p>Please make sure these two ports are not used by anyone else.</p> <p>Usage:</p> <pre><code>$ visionai models start [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-models-status","title":"<code>visionai models status</code>","text":"<p>Show the status of serving models</p> <p>Shows how many models are being served, metrics for the models etc.</p> <p>Usage:</p> <pre><code>$ visionai models status [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-models-stop","title":"<code>visionai models stop</code>","text":"<p>Stop serving all models.</p> <p>This method will stop serving all models. Any inference running will all be stopped as well.</p> <p>Usage:</p> <pre><code>$ visionai models stop [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-pipeline","title":"<code>visionai pipeline</code>","text":"<p>Manage pipelines</p> <p>Pipeline is a sequence of preprocess routines and scenarios to be run on a given set of cameras. Each pipeline can be configured to run specific scenarios - each scenario with their own customizations for event notifications. This module provides robust methods for managing pipelines, showing their details, adding/remove cameras from pipelines and running a pipeline.</p> <p>Usage:</p> <pre><code>$ visionai pipeline [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>add-camera</code>: Add a camera to a pipeline Each pipeline...</li> <li><code>add-preprocess</code>: Add a preprocess routine to a pipeline...</li> <li><code>add-scenario</code>: Add a scenario to a pipeline The order of the...</li> <li><code>create</code>: Create a named pipeline Create a named...</li> <li><code>remove-camera</code>: Remove a camera from a pipeline This method...</li> <li><code>reset</code>: Reset the pipeline to original state.</li> <li><code>run</code>: Run a pipeline of scenarios on given cameras...</li> <li><code>show</code>: Show details of a pipeline Show what is...</li> </ul>"},{"location":"reference/reference/#visionai-pipeline-add-camera","title":"<code>visionai pipeline add-camera</code>","text":"<p>Add a camera to a pipeline</p> <p>Each pipeline consists of a bunch of scenarios to run and which cameras they need to be run on. This method allows the user to add one or more named camera instance to a pipeline. Please note the camera instance has to be created prior to adding it here.</p>"},{"location":"reference/reference/#add-a-camera","title":"add a camera","text":"<p>$ visionai camera add --name OFFICE-01 --uri https://youtube.com</p>"},{"location":"reference/reference/#add-camera-to-pipeline","title":"add camera to pipeline","text":"<p>$ visionai pipeline --name test_pipe add-camera --name OFFICE-01</p> <p>@arg pipeline - specify a named pipeline @arg camera - specify name of the camera to add</p> <p>@return None</p> <p>Usage:</p> <pre><code>$ visionai pipeline add-camera [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--pipeline TEXT</code>: pipeline name  [required]</li> <li><code>--camera TEXT</code>: camera to add  [required]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-pipeline-add-preprocess","title":"<code>visionai pipeline add-preprocess</code>","text":"<p>Add a preprocess routine to a pipeline</p> <p>Preprocessing tasks are run prior to scenarios. The order in which multiple preprocess tasks are added does not matter. All added preprocess routines are executed in different threads.</p> <p>$ visionai pipeline --name test_pipe add-preprocess --name face-blur</p> <p>$ visionai pipeline --name test_pipe add-preprocess --name text-blur</p> <p>$ visionai pipeline --name test_pipe show</p> <p>$ visionai pipeline --name test_pipe run</p> <p>@arg pipeline - specify a named pipeline @arg preprocess - specify name of the preprocess task to run</p> <p>@return None</p> <p>Usage:</p> <pre><code>$ visionai pipeline add-preprocess [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--pipeline TEXT</code>: pipeline name  [required]</li> <li><code>--preprocess TEXT</code>: preprocess routine to add  [required]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-pipeline-add-scenario","title":"<code>visionai pipeline add-scenario</code>","text":"<p>Add a scenario to a pipeline</p> <p>The order of the scenarios does not matter. All added scenarios are run in different threads. All scenarios are run after pre-processing stage is done.</p> <p>$visionai pipeline --name test_pipe add-scenario --name smoke-and-fire</p> <p>$visionai pipeline --name test_pipe add-scenario --name ppe-detection</p> <p>$visionai pipeline --name test_pipe run</p> <p>@arg pipeline - specify a named pipeline @arg scenario - specify name of the scenario to run</p> <p>@return None</p> <p>Usage:</p> <pre><code>$ visionai pipeline add-scenario [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--pipeline TEXT</code>: pipeline name  [required]</li> <li><code>--scenario TEXT</code>: scenario to add  [required]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-pipeline-create","title":"<code>visionai pipeline create</code>","text":"<p>Create a named pipeline</p> <p>Create a named pipeline. Pipeline is a list of scenarios to be run for specific cameras. The flow is as follows. Create a pipeline using:</p> <p>visionai pipeline create --name test_pipe</p> <p>visionai pipeline add-scenario --pipeline test_pipe  --name smoke-and-fire</p> <p>visionai pipeline add-scenario --pipeline test_pipe  --name ppe-detection</p> <p>visionai pipeline add-preprocess --pipeline test_pipe  --name face-blur</p> <p>visionai pipeline add-preprocess --pipeline test_pipe  --name text-blur</p> <p>visionai pipeline add-scenario --pipeline test_pipe  --name max-occupancy</p> <p>visionai pipeline show --pipeline test_pipe</p> <p>visionai pipeline add-camera --pipeline test_pipe  --name CAMERA-01</p> <p>visionai pipeline add-camera --pipeline test_pipe  --name CAMERA-02</p> <p>visionai pipeline show --pipeline test_pipe</p> <p>visionai pipeline run --pipeline test_pipe</p> <p>@arg pipeline - specify a named pipeline</p> <p>@return None</p> <p>Usage:</p> <pre><code>$ visionai pipeline create [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--name TEXT</code>: pipeline name  [required]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-pipeline-remove-camera","title":"<code>visionai pipeline remove-camera</code>","text":"<p>Remove a camera from a pipeline</p> <p>This method can be used to remove a camera from a pipeline.</p> <p>$ visionai pipeline --name test_pipe remove-camera --name OFFICE-01</p> <p>@arg pipeline - specify a named pipeline @arg camera - specify name of the camera to remove</p> <p>@return None</p> <p>Usage:</p> <pre><code>$ visionai pipeline remove-camera [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--pipeline TEXT</code>: pipeline name  [required]</li> <li><code>--camera TEXT</code>: camera to remove  [required]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-pipeline-reset","title":"<code>visionai pipeline reset</code>","text":"<p>Reset the pipeline to original state.</p> <p>Deletes all cameras, scenarios and scenario configuration from the pipeline. Its as if the pipeline has been deleted and created from scratch again.</p> <p>$ visionai pipeline --name test_pipe reset</p> <p>@arg pipeline - pipeline to reset</p> <p>@return None</p> <p>Usage:</p> <pre><code>$ visionai pipeline reset [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--pipeline TEXT</code>: pipeline name  [required]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-pipeline-run","title":"<code>visionai pipeline run</code>","text":"<p>Run a pipeline of scenarios on given cameras</p> <p>Specify different scenarios to run on one or more cameras. This method can be directly used to specify scenarios and cameras directly. Else you can configure a named pipeline and then run it here.</p> <p>@arg pipeline - specify a named pipeline</p> <p>@return None</p> <p>Usage:</p> <pre><code>$ visionai pipeline run [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--pipeline TEXT</code>: Pipeline to run  [required]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-pipeline-show","title":"<code>visionai pipeline show</code>","text":"<p>Show details of a pipeline</p> <p>Show what is configured in the current pipeline.</p> <p>$ visionai pipeline --name test_pipe show</p> <p>@arg pipeline - specify a named pipeline</p> <p>@return None</p> <p>Usage:</p> <pre><code>$ visionai pipeline show [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--pipeline TEXT</code>: pipeline name  [required]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-pipelines","title":"<code>visionai pipelines</code>","text":"<p>... alias for pipeline</p> <p>Usage:</p> <pre><code>$ visionai pipelines [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>add-camera</code>: Add a camera to a pipeline Each pipeline...</li> <li><code>add-preprocess</code>: Add a preprocess routine to a pipeline...</li> <li><code>add-scenario</code>: Add a scenario to a pipeline The order of the...</li> <li><code>create</code>: Create a named pipeline Create a named...</li> <li><code>remove-camera</code>: Remove a camera from a pipeline This method...</li> <li><code>reset</code>: Reset the pipeline to original state.</li> <li><code>run</code>: Run a pipeline of scenarios on given cameras...</li> <li><code>show</code>: Show details of a pipeline Show what is...</li> </ul>"},{"location":"reference/reference/#visionai-pipelines-add-camera","title":"<code>visionai pipelines add-camera</code>","text":"<p>Add a camera to a pipeline</p> <p>Each pipeline consists of a bunch of scenarios to run and which cameras they need to be run on. This method allows the user to add one or more named camera instance to a pipeline. Please note the camera instance has to be created prior to adding it here.</p>"},{"location":"reference/reference/#add-a-camera_1","title":"add a camera","text":"<p>$ visionai camera add --name OFFICE-01 --uri https://youtube.com</p>"},{"location":"reference/reference/#add-camera-to-pipeline_1","title":"add camera to pipeline","text":"<p>$ visionai pipeline --name test_pipe add-camera --name OFFICE-01</p> <p>@arg pipeline - specify a named pipeline @arg camera - specify name of the camera to add</p> <p>@return None</p> <p>Usage:</p> <pre><code>$ visionai pipelines add-camera [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--pipeline TEXT</code>: pipeline name  [required]</li> <li><code>--camera TEXT</code>: camera to add  [required]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-pipelines-add-preprocess","title":"<code>visionai pipelines add-preprocess</code>","text":"<p>Add a preprocess routine to a pipeline</p> <p>Preprocessing tasks are run prior to scenarios. The order in which multiple preprocess tasks are added does not matter. All added preprocess routines are executed in different threads.</p> <p>$ visionai pipeline --name test_pipe add-preprocess --name face-blur</p> <p>$ visionai pipeline --name test_pipe add-preprocess --name text-blur</p> <p>$ visionai pipeline --name test_pipe show</p> <p>$ visionai pipeline --name test_pipe run</p> <p>@arg pipeline - specify a named pipeline @arg preprocess - specify name of the preprocess task to run</p> <p>@return None</p> <p>Usage:</p> <pre><code>$ visionai pipelines add-preprocess [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--pipeline TEXT</code>: pipeline name  [required]</li> <li><code>--preprocess TEXT</code>: preprocess routine to add  [required]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-pipelines-add-scenario","title":"<code>visionai pipelines add-scenario</code>","text":"<p>Add a scenario to a pipeline</p> <p>The order of the scenarios does not matter. All added scenarios are run in different threads. All scenarios are run after pre-processing stage is done.</p> <p>$visionai pipeline --name test_pipe add-scenario --name smoke-and-fire</p> <p>$visionai pipeline --name test_pipe add-scenario --name ppe-detection</p> <p>$visionai pipeline --name test_pipe run</p> <p>@arg pipeline - specify a named pipeline @arg scenario - specify name of the scenario to run</p> <p>@return None</p> <p>Usage:</p> <pre><code>$ visionai pipelines add-scenario [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--pipeline TEXT</code>: pipeline name  [required]</li> <li><code>--scenario TEXT</code>: scenario to add  [required]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-pipelines-create","title":"<code>visionai pipelines create</code>","text":"<p>Create a named pipeline</p> <p>Create a named pipeline. Pipeline is a list of scenarios to be run for specific cameras. The flow is as follows. Create a pipeline using:</p> <p>visionai pipeline create --name test_pipe</p> <p>visionai pipeline add-scenario --pipeline test_pipe  --name smoke-and-fire</p> <p>visionai pipeline add-scenario --pipeline test_pipe  --name ppe-detection</p> <p>visionai pipeline add-preprocess --pipeline test_pipe  --name face-blur</p> <p>visionai pipeline add-preprocess --pipeline test_pipe  --name text-blur</p> <p>visionai pipeline add-scenario --pipeline test_pipe  --name max-occupancy</p> <p>visionai pipeline show --pipeline test_pipe</p> <p>visionai pipeline add-camera --pipeline test_pipe  --name CAMERA-01</p> <p>visionai pipeline add-camera --pipeline test_pipe  --name CAMERA-02</p> <p>visionai pipeline show --pipeline test_pipe</p> <p>visionai pipeline run --pipeline test_pipe</p> <p>@arg pipeline - specify a named pipeline</p> <p>@return None</p> <p>Usage:</p> <pre><code>$ visionai pipelines create [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--name TEXT</code>: pipeline name  [required]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-pipelines-remove-camera","title":"<code>visionai pipelines remove-camera</code>","text":"<p>Remove a camera from a pipeline</p> <p>This method can be used to remove a camera from a pipeline.</p> <p>$ visionai pipeline --name test_pipe remove-camera --name OFFICE-01</p> <p>@arg pipeline - specify a named pipeline @arg camera - specify name of the camera to remove</p> <p>@return None</p> <p>Usage:</p> <pre><code>$ visionai pipelines remove-camera [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--pipeline TEXT</code>: pipeline name  [required]</li> <li><code>--camera TEXT</code>: camera to remove  [required]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-pipelines-reset","title":"<code>visionai pipelines reset</code>","text":"<p>Reset the pipeline to original state.</p> <p>Deletes all cameras, scenarios and scenario configuration from the pipeline. Its as if the pipeline has been deleted and created from scratch again.</p> <p>$ visionai pipeline --name test_pipe reset</p> <p>@arg pipeline - pipeline to reset</p> <p>@return None</p> <p>Usage:</p> <pre><code>$ visionai pipelines reset [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--pipeline TEXT</code>: pipeline name  [required]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-pipelines-run","title":"<code>visionai pipelines run</code>","text":"<p>Run a pipeline of scenarios on given cameras</p> <p>Specify different scenarios to run on one or more cameras. This method can be directly used to specify scenarios and cameras directly. Else you can configure a named pipeline and then run it here.</p> <p>@arg pipeline - specify a named pipeline</p> <p>@return None</p> <p>Usage:</p> <pre><code>$ visionai pipelines run [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--pipeline TEXT</code>: Pipeline to run  [required]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-pipelines-show","title":"<code>visionai pipelines show</code>","text":"<p>Show details of a pipeline</p> <p>Show what is configured in the current pipeline.</p> <p>$ visionai pipeline --name test_pipe show</p> <p>@arg pipeline - specify a named pipeline</p> <p>@return None</p> <p>Usage:</p> <pre><code>$ visionai pipelines show [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--pipeline TEXT</code>: pipeline name  [required]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-scenario","title":"<code>visionai scenario</code>","text":"<p>Manage scenarios</p> <p>An organization can have multiple scenarios that are installed at different places. They may be from different vendors and/or maybe using different security surveillance software. Most scenarios however do support RTSP, RTMP or HLS streams as an output. Please refer to your scenario vendor documentation to find this out. This module will help you onboard those scenarios on visionai systems by using a simple named instance for each scenario.</p> <p>Usage:</p> <pre><code>$ visionai scenario [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>download</code>: Download models for scenarios Ex: visionai...</li> <li><code>list</code>: List all scenarios available List all...</li> <li><code>test</code>: Run the scenario locally to test it out.</li> </ul>"},{"location":"reference/reference/#visionai-scenario-download","title":"<code>visionai scenario download</code>","text":"<p>Download models for scenarios</p> <p>Ex: visionai scenario download ppe-detection  # download ppe-detection scenario Ex: visionai scenario download all            # download all configured scenarios for the org Ex: visionai scenario download world          # download all available scenarios</p> <p>Download models for a given scenario, or download models for all scenarios that have been configured.</p> <p>Usage:</p> <pre><code>$ visionai scenario download [OPTIONS] NAME\n</code></pre> <p>Arguments:</p> <ul> <li><code>NAME</code>: [required]</li> </ul> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-scenario-list","title":"<code>visionai scenario list</code>","text":"<p>List all scenarios available</p> <p>List all scenarios available in the system. This includes scenarios that may or maynot be applied to any specific camera.</p> <p>Usage:</p> <pre><code>$ visionai scenario list [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-scenario-test","title":"<code>visionai scenario test</code>","text":"<p>Run the scenario locally to test it out.</p> <ul> <li>Download the model if not available.</li> <li>Pull the model server container image.</li> <li>Start the model server container with this model.</li> <li>Run inference with this model</li> </ul> <p>Usage:</p> <pre><code>$ visionai scenario test [OPTIONS] NAME\n</code></pre> <p>Arguments:</p> <ul> <li><code>NAME</code>: [required]</li> </ul> <p>Options:</p> <ul> <li><code>--camera TEXT</code>: Camera name (default is webcam)  [default: 0]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-scenarios","title":"<code>visionai scenarios</code>","text":"<p>... alias for scenario</p> <p>Usage:</p> <pre><code>$ visionai scenarios [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>download</code>: Download models for scenarios Ex: visionai...</li> <li><code>list</code>: List all scenarios available List all...</li> <li><code>test</code>: Run the scenario locally to test it out.</li> </ul>"},{"location":"reference/reference/#visionai-scenarios-download","title":"<code>visionai scenarios download</code>","text":"<p>Download models for scenarios</p> <p>Ex: visionai scenario download ppe-detection  # download ppe-detection scenario Ex: visionai scenario download all            # download all configured scenarios for the org Ex: visionai scenario download world          # download all available scenarios</p> <p>Download models for a given scenario, or download models for all scenarios that have been configured.</p> <p>Usage:</p> <pre><code>$ visionai scenarios download [OPTIONS] NAME\n</code></pre> <p>Arguments:</p> <ul> <li><code>NAME</code>: [required]</li> </ul> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-scenarios-list","title":"<code>visionai scenarios list</code>","text":"<p>List all scenarios available</p> <p>List all scenarios available in the system. This includes scenarios that may or maynot be applied to any specific camera.</p> <p>Usage:</p> <pre><code>$ visionai scenarios list [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-scenarios-test","title":"<code>visionai scenarios test</code>","text":"<p>Run the scenario locally to test it out.</p> <ul> <li>Download the model if not available.</li> <li>Pull the model server container image.</li> <li>Start the model server container with this model.</li> <li>Run inference with this model</li> </ul> <p>Usage:</p> <pre><code>$ visionai scenarios test [OPTIONS] NAME\n</code></pre> <p>Arguments:</p> <ul> <li><code>NAME</code>: [required]</li> </ul> <p>Options:</p> <ul> <li><code>--camera TEXT</code>: Camera name (default is webcam)  [default: 0]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-ui","title":"<code>visionai ui</code>","text":"<p>Start/stop web-app</p> <p>Start and stop the VisionAI web-app which can be a more intuitive way of managing cameras, pipelines and scenarios. Web-app also provides a live-stream view of the cameras.</p> <p>Usage:</p> <pre><code>$ visionai ui [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>start</code>: Start web server Use this function to start...</li> <li><code>status</code>: Web service status Use this function to get...</li> <li><code>stop</code>: Stop web server Use this function to stop...</li> </ul>"},{"location":"reference/reference/#visionai-ui-start","title":"<code>visionai ui start</code>","text":"<p>Start web server</p> <p>Use this function to start the web-service. Web service can be used for more intuitive configuration for the cameras and scenarios. Web-app is also the place to view event details, camera live-stream etc.</p> <p>Usage:</p> <pre><code>$ visionai ui start [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-ui-status","title":"<code>visionai ui status</code>","text":"<p>Web service status</p> <p>Use this function to get the status of the web-service. (if its running or not. This function also prints diagnostic information like last few log messages etc.)</p> <p>Usage:</p> <pre><code>$ visionai ui status [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--tail INTEGER</code>: tail number of lines  [default: 20]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-ui-stop","title":"<code>visionai ui stop</code>","text":"<p>Stop web server</p> <p>Use this function to stop already running web-service. There can be a single instance of the web-service supported currently. So there is no need for any arguments for this function.</p> <p>Usage:</p> <pre><code>$ visionai ui stop [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--web TEXT</code></li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-web","title":"<code>visionai web</code>","text":"<p>... alias for ui</p> <p>Usage:</p> <pre><code>$ visionai web [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul> <p>Commands:</p> <ul> <li><code>start</code>: Start web server Use this function to start...</li> <li><code>status</code>: Web service status Use this function to get...</li> <li><code>stop</code>: Stop web server Use this function to stop...</li> </ul>"},{"location":"reference/reference/#visionai-web-start","title":"<code>visionai web start</code>","text":"<p>Start web server</p> <p>Use this function to start the web-service. Web service can be used for more intuitive configuration for the cameras and scenarios. Web-app is also the place to view event details, camera live-stream etc.</p> <p>Usage:</p> <pre><code>$ visionai web start [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-web-status","title":"<code>visionai web status</code>","text":"<p>Web service status</p> <p>Use this function to get the status of the web-service. (if its running or not. This function also prints diagnostic information like last few log messages etc.)</p> <p>Usage:</p> <pre><code>$ visionai web status [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--tail INTEGER</code>: tail number of lines  [default: 20]</li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/reference/#visionai-web-stop","title":"<code>visionai web stop</code>","text":"<p>Stop web server</p> <p>Use this function to stop already running web-service. There can be a single instance of the web-service supported currently. So there is no need for any arguments for this function.</p> <p>Usage:</p> <pre><code>$ visionai web stop [OPTIONS]\n</code></pre> <p>Options:</p> <ul> <li><code>--web TEXT</code></li> <li><code>--help</code>: Show this message and exit.</li> </ul>"},{"location":"reference/security/","title":"Security","text":"<p>Visionify's commitment to security and privacy goes beyond compliance - it's built into our DNA. Our platform meets the highest enterprise security standards while protecting individual privacy.</p> SOC 2 Type II Certified GDPR Compliant"},{"location":"reference/security/#enterprise-grade-security","title":"Enterprise-Grade Security","text":""},{"location":"reference/security/#infrastructure-security","title":"Infrastructure Security","text":"<ul> <li>Azure Cloud Infrastructure: Leveraging Microsoft Azure's enterprise-grade security</li> <li>End-to-End Encryption: AES-256 encryption for data at rest and in transit</li> <li>Network Isolation: Private VNet support with dedicated instances</li> <li>Access Controls: Role-based access control (RBAC)</li> </ul>"},{"location":"reference/security/#data-protection","title":"Data Protection","text":"<ul> <li>Data Residency: Options for US, EU, and custom data centers</li> <li>Data Retention: Configurable retention policies</li> <li>Backup &amp; Recovery: Automated backups with point-in-time recovery</li> <li>Audit Trails: Comprehensive logging of all system access</li> </ul>"},{"location":"reference/security/#privacy-by-design","title":"Privacy by Design","text":""},{"location":"reference/security/#video-privacy","title":"Video Privacy","text":"<ul> <li>Automated Face Blurring: Real-time face anonymization</li> <li>License Plate Masking: Automatic vehicle identification masking</li> <li>Text Redaction: Intelligent text and signage blurring</li> <li>Minimal Data Storage: Only relevant event metadata stored</li> </ul>"},{"location":"reference/security/#compliance-features","title":"Compliance Features","text":"<ul> <li>Data Minimization: Only essential data collected and processed</li> <li>Right to be Forgotten: Built-in data deletion capabilities</li> <li>Privacy Controls: Granular privacy settings configuration</li> <li>Consent Management: Built-in consent tracking system</li> </ul>"},{"location":"reference/security/#security-certifications","title":"Security Certifications","text":""},{"location":"reference/security/#soc-2-type-ii-certified","title":"SOC 2 Type II Certified","text":"<p>Our SOC 2 Type II certification demonstrates our commitment to:</p> <ul> <li>Security</li> <li>Availability</li> <li>Processing Integrity</li> <li>Confidentiality</li> <li>Privacy</li> </ul>"},{"location":"reference/security/#gdpr-compliance","title":"GDPR Compliance","text":"<p>Full compliance with EU data protection regulations including:</p> <ul> <li>Data Protection Impact Assessments</li> <li>Privacy Impact Assessments</li> <li>Data Processing Agreements</li> <li>Subject Access Request Management</li> </ul>"},{"location":"reference/security/#enterprise-controls","title":"Enterprise Controls","text":""},{"location":"reference/security/#authentication-access","title":"Authentication &amp; Access","text":"<ul> <li>Multi-Factor Authentication: Required for all admin access</li> <li>IP Whitelisting: Restrict access to approved networks</li> <li>Session Management: Automatic timeout and session controls</li> </ul>"},{"location":"reference/security/#monitoring-alerts","title":"Monitoring &amp; Alerts","text":"<ul> <li>24/7 Security Monitoring: Real-time threat detection</li> <li>Automated Alerts: Immediate notification of security events</li> <li>Activity Logging: Comprehensive audit trails</li> <li>Performance Monitoring: Continuous system health checks</li> </ul>"},{"location":"reference/security/#data-governance","title":"Data Governance","text":"<ul> <li>Data Classification: Automated data categorization</li> <li>Access Controls: Granular permissions management</li> <li>Retention Policies: Configurable data lifecycle management</li> <li>Audit Capabilities: Complete data access tracking</li> </ul>"},{"location":"reference/security/#security-operations","title":"Security Operations","text":"<ul> <li>Incident Response: 24/7 security team</li> <li>Vulnerability Management: Regular security assessments</li> <li>Patch Management: Automated security updates</li> <li>Penetration Testing: Annual third-party testing</li> </ul>"},{"location":"reference/security/#next-steps","title":"Next Steps","text":"<ul> <li>Quick Start</li> <li>Camera Placement Guide</li> <li>Supported Scenarios</li> <li>Camera Management</li> <li>FAQs</li> </ul>"},{"location":"reference/security/#contact-information","title":"Contact Information","text":"contact_phone Sales Inquiries <p>Get in touch with our sales team for demos and pricing information.</p> <ul> <li>Email: sales@visionify.ai</li> <li>Phone: +1 720-449-1124</li> </ul> support_agent Technical Support <p>Need help? Visit our support portal or contact our technical team.</p> <ul> <li>https://support.visionify.ai</li> <li>support@visionify.ai</li> </ul> calendar_month Schedule a Demo <p>See VisionAI in action with a personalized demo from our team.</p> event                 Book Your Demo"},{"location":"reference/troubleshooting/","title":"Troubleshooting Guide","text":"<p>Common questions and solutions for VisionAI platform issues.</p>"},{"location":"reference/troubleshooting/#why-cant-i-see-my-camera-feed","title":"Why can't I see my camera feed?","text":"<p>Common causes:</p> <ul> <li>Incorrect RTSP URL format</li> <li>Network connectivity issues</li> <li>Camera firewall restrictions</li> <li>Invalid camera credentials</li> </ul> <p>Solutions:</p> <ul> <li>Verify RTSP URL using VLC Player</li> <li>Check camera network connectivity</li> <li>Confirm camera username/password</li> </ul>"},{"location":"reference/troubleshooting/#why-is-my-video-feed-delayed","title":"Why is my video feed delayed?","text":"<p>Possible reasons:</p> <ul> <li>Network bandwidth limitations</li> <li>High camera resolution settings</li> <li>Server processing load</li> <li>Network latency</li> </ul> <p>Solutions:</p> <ul> <li>Lower camera resolution</li> <li>Check network bandwidth</li> <li>Optimize frame rate settings</li> <li>Verify server resources</li> </ul>"},{"location":"reference/troubleshooting/#why-is-my-video-feed-blurry","title":"Why is my video feed blurry?","text":"<p>Possible reasons:</p> <ul> <li>Low camera resolution settings</li> <li>Poor lighting conditions</li> <li>Camera lens issues</li> </ul> <p>Solutions:</p> <ul> <li>Increase camera resolution</li> <li>Improve lighting conditions</li> <li>Check camera lens for clarity</li> </ul>"},{"location":"reference/troubleshooting/#learn-more","title":"Learn More","text":"<ul> <li>Quick Start</li> <li>Camera Placement Guide</li> <li>Supported Scenarios</li> <li>Camera Management</li> <li>FAQs</li> </ul>"},{"location":"reference/troubleshooting/#contact-information","title":"Contact Information","text":"contact_phone Sales Inquiries <p>Get in touch with our sales team for demos and pricing information.</p> <ul> <li>Email: sales@visionify.ai</li> <li>Phone: +1 720-449-1124</li> </ul> support_agent Technical Support <p>Need help? Visit our support portal or contact our technical team.</p> <ul> <li>https://support.visionify.ai</li> <li>support@visionify.ai</li> </ul> calendar_month Schedule a Demo <p>See VisionAI in action with a personalized demo from our team.</p> event                 Book Your Demo"},{"location":"scenarios/","title":"Scenarios","text":"<p>Scenarios (also referred to as <code>use cases</code>) form the building blocks of VisionAI platform. These scenarios are organized into <code>Suites</code>. Below we talk about different suites and the scenarios that are part of them.</p> <ul> <li>All scenarios are available as pick-n-choose scenarios. You can pick the scenarios you want based on your business needs. Each scenario is independently tested.</li> <li>Some scenarios require zones to be defined - you can define zones through the VisionAI web-application.</li> <li>Events provided by these scenarios are given below. Events are sent to Redis, MQTT &amp; WebSocket endpoints for custom integrations.</li> <li>Currently supported scenarios are highlighted by a \u2705. Roadmap scenarios are highlighted by a \ud83d\udcc5.</li> </ul> <p>Below image also provides a summary of all the scenarios that are supported by VisionAI.</p> <p> </p> Visionify Supported AI Scenarios <p>New scenario request</p> <p>This chapter lists down all the scenarios that are supported by the VisionAI platform. We are always looking to expand our suite - please send a request to us about any additional scenarios you need.</p>"},{"location":"scenarios/#ppe-compliance","title":"PPE Compliance","text":"<p>PPE Compliance is our core application. We support most of the common types of PPEs used in manufacturing &amp; construction industry. This suite is sometimes also referred to by <code>Worker Health and Safety</code>.</p> <p>PPE compliance is the first step towards a comprehensive safety program. Workers sometimes forget to wear PPEs like helmets, gloves, safety boots, high-vis vests, goggles, masks, coveralls etc., due to lack of awareness or complacency. PPE Compliance helps you ensure that workers are wearing the required PPEs.</p> <p>Ensuring PPE Compliance can yield significant benefits. It can help reduce the number of accidents and injuries in the workplace, improve productivity, and enhance the overall safety culture of the organization.</p> <p> </p> PPE Compliance Sample Event <p>Table: PPE Compliance Events and Detection Details</p> Status Scenario name Supported Events Event Details More Info \u2705 PPE Compliance <code>No Helmet</code> Person detected without helmet PPE Compliance <code>No Gloves</code> Person detected without gloves <code>No Safety Boots</code> Person detected without safety boots <code>No High-Vis Vest</code> Person detected without high-vis vest <code>No Goggles</code> Person detected without goggles <code>No Mask</code> Person detected without mask <code>No Cap</code> Person detected without cap <code>No Apron</code> Person detected without apron <code>No Hairnet</code> Person detected without hairnet <code>No Face Shield</code> Person detected without face shield (Welding) <code>No Coveralls</code> Person detected without coveralls <code>No Safety Harness</code> Personal Fall Arrest System (PFAS) <code>No Earmuffs</code> Person detected without earmuffs"},{"location":"scenarios/#area-controls","title":"Area Controls","text":"<p>Area controls is a core scenario of the VisionAI application. With this scenario - we can enable different area and time related use-cases. Area control scenarios require a zone to be configured for each of the different events.</p> <p>For example, if we want to setup a Pedestrian Pathway, or create a Man-Machine area that is restricted during certain hours - we can do that with area control scenarios.</p> <p>Deploying Area Control scenarios requires understanding of the camera area and the type of work performed there. We recommend that you look at the video clips from the camera, and tune the scenario accordingly.</p> <p> </p> Restricted Zone Violation Example Event <p>Table: Area Control Events and Detection Details</p> Scenario name Supported? Event Event Details More Info Area Controls \u2705 <code>Restricted Area</code> Person in Restricted Area More details \u2705 <code>Perimeter Control</code> Person in Secure Perimeter \u2705 <code>Time Limited Areas</code> Person in zone for more than X mins \u2705 <code>Confined Space Monitoring</code> Person in confined space for more than X mins \u2705 <code>Min Worker Zone</code> No Person in Mandatory Personnel Zone \u2705 <code>Max Worker Zone</code> Grouping/Crowding detected \ud83d\udcc5 <code>Person under Suspended Load</code> Person under suspended load \u2705 <code>Pedestrian Pathway</code> Person outside of pedestrian pathway \u2705 <code>Person in Vehicle Pathway</code> Person detected in vehicle pathway"},{"location":"scenarios/#forklift-safety","title":"Forklift Safety","text":"<p>Visionify's Forklift Safety suite detects near-misses between forklifts &amp; people, forklift-speed limit, and dedicated pathways for forklifts &amp; people. This scenario is useful for areas where forklifts are operated.</p> <p>Forklift Safety also implements other best practices like Wearning Seatbelts, Stop sign compliance etc.</p> <p>Our forklift safety suite can be considered as a passive safety system. It does not actively prevent any accidents, but it does help you identify areas that need attention. The goal of the Forklift Safety Suite is to make your team aware of the risks, so you can data driven changes to make your workplace safer.</p> <p> </p> Forklift Safety Violation Example Event <p>Table: Forklift Safety Events and Detection Details</p> Scenario name Supported? Event Event Details More Info Forklift Safety \u2705 <code>Forklift Person interaction</code> Forklift Person Near-Miss More details \u2705 <code>Forklift Forklift interaction</code> Forklift Forklift Near-Miss \u2705 <code>Forklift Speed Limit</code> Forklift Speed Limit Violation \u2705 <code>Forklift Stop Sign Compliance</code> Forklift Stop Sign Compliance Violation \u2705 <code>Dedicated Forklift Pathway</code> Forklift outside of dedicated pathway \u2705 <code>Person in Forklift Pathway</code> Person in Forklift Pathway \ud83d\udcc5 <code>Forklift Max-height Violation</code> Forklift Max-height Violation \ud83d\udcc5 <code>Forklift with Pins Up</code> Forklift with Pins Up \u2705 <code>Forklift and People Heatmap</code> Forklift and People Heatmap"},{"location":"scenarios/#emergency-events","title":"Emergency Events","text":"<p>Emergency events detection is critical for workplace safety. This suite focuses on detecting various emergency situations that require immediate attention, such as smoke, fire, slip, trip and falls, any person-down events resulting from exhaustion and heat-stroke. Early detection of these events can help prevent accidents and enable quick response times.</p> <p>Alert Notifications</p> <p>Visionify's system can be configured to send out an alert when any of these emergency events are detected. This alert can be sent as a Text Message, Email or a notification through Microsoft Teams.</p> <p> </p> Smoke and Fire Detection Example Event <p>Table: Emergency Events and Detection Details</p> Scenario name Supported? Event Event Details More Info Emergency Events \u2705 <code>Smoke Event Detected</code> Smoke Event Detected More details \u2705 <code>Fire Event Detected</code> Fire Event Detected More details \u2705 <code>Person Down</code> Slip, trip, fall, or other Person Down Events More details"},{"location":"scenarios/#heatmaps-and-occupancy-metrics","title":"Heatmaps and Occupancy Metrics","text":"<p>Occupancy metrics suite provides use-cases for person counting, heatmaps (density maps) of people &amp; forklifts, desk occupancy, station occupancy and mobile phone usage metrics. </p> <p>Visionify's occupancy metrics suite can be used with the rest of our suite to enable different compliance policies or collect general planning data for your organization.</p> <p> </p> People &amp; Forklift Heatmap Event <p>Table: Occupancy Metrics Events and Detection Details</p> Scenario name Supported? Event Event Details More Info Occupancy Metrics \u2705 <code>People Headcount</code> People Headcount More details \u2705 <code>People &amp; Forklift Heatmap</code> Periodic Heatmap Event \u2705 <code>Desk Occupancy</code> Desk Occupancy \u2705 <code>Station Occupancy</code> Station Occupancy \u2705 <code>Phone Usage Metrics</code> Station Occupancy"},{"location":"scenarios/#housekeeping","title":"Housekeeping","text":"<p>Visionify's Housekeeping Suite provides various hazard identifications on the work floor. These metrics include identifying spills and leaks on the floor, unattended objects, boxes or pallets on the floor, identifying door open/close events, blocked exits monitoring, missing fire-extinguishers etc. </p> <p>Housekeeping suite provides organization a second set of eyes for their regular audits. By identifying hazards early, this suite tends to avoid accidents and injuries.</p> <p> </p> Spills and Leaks Detection Example Event <p>Table: Housekeeping Events and Detection Details</p> Scenario name Supported? Event Event Details More Info Housekeeping \u2705 <code>Spills &amp; Leaks</code> Spills and Leaks More details \u2705 <code>Unattended Objects</code> Unattended Objects \u2705 <code>Unattended Pallet/Box</code> Unattended Pallet/Box \u2705 <code>Clean Pathway</code> Clean Pathway \u2705 <code>Blocked Exits</code> Blocked Exits \u2705 <code>Missing Fire Extinguisher</code> Missing Fire Extinguisher Event \u2705 <code>Door Open/Close</code> Door Open/Close Event"},{"location":"scenarios/#behavioral-safety-suite","title":"Behavioral Safety Suite","text":"<p>Visionify's Behavioral Safety Suite focuses on identifying and correcting unsafe behaviors before they lead to accidents. This suite monitors various behavioral patterns including running in work areas, climbing on equipment or railings, smoking/vaping in prohibited areas, consuming food/drinks in restricted zones, and mobile phone usage in unsafe conditions. </p> <p>By detecting these unsafe behaviors early, organizations can provide timely interventions and training to promote safer work practices. The Behavioral Safety suite serves as a proactive tool for safety managers to reinforce safety protocols and maintain workplace discipline.</p> <p> </p> Mobile Phone Usage Detection Example Event <p>Table: Behavioral Safety Events and Detection Details</p> Scenario name Supported? Event Event Details More Info Behavioral Safety \u2705 <code>Running Detection</code> Person running in work area More details \u2705 <code>Climbing Detection</code> Person climbing on equipment/railings \u2705 <code>Smoking/Vaping Detection</code> Person smoking or vaping in prohibited area \u2705 <code>Food/Drinks Detection</code> Person with food/drinks in restricted area \u2705 <code>Mobile Phone Usage</code> Person using phone in unsafe conditions"},{"location":"scenarios/#staircase-safety","title":"Staircase Safety","text":"<p>Visionify's Staircase Safety Suite focuses on preventing accidents and injuries in one of the most common yet hazardous areas of any facility - staircases. This suite monitors various unsafe behaviors including failure to use handrails, running on stairs, using mobile phones while climbing/descending, and skipping steps. These behaviors are leading causes of workplace accidents, often resulting in serious injuries.</p> <p>By identifying these risky behaviors in real-time, organizations can take proactive measures to prevent staircase-related incidents. The suite helps safety managers enforce proper staircase usage protocols and create awareness about safe staircase practices among employees.</p> <p>Table: Staircase Safety Events and Detection Details</p> Scenario name Supported? Event Event Details More Info Staircase Safety \u2705 <code>No Bannister Usage</code> Person not holding handrail while using stairs More details \u2705 <code>Running on Stairs</code> Person running on staircase \u2705 <code>Phone Usage on Stairs</code> Person using mobile phone while on stairs \u2705 <code>Skipping Steps</code> Person skipping steps while using stairs"},{"location":"scenarios/#employee-privacy-face-blurring","title":"Employee Privacy (Face Blurring)","text":"<p>For a majority of organizations - employee privacy is a top concern. Along with employee privacy, the organization needs to make sure that any data does not leave the premises. Any faces detected through Vision AI system need to be blurred, along with text, signage, computer screens and other sensitive information.</p> <p>Before any other scenarios are run, or before we store or process the images - the images are pre-processed through this privacy suite. As such, privacy suite is treated differently from other scenarios. Below examples provide a high-level overview of the privacy suite.</p> <p>Table: Privacy Suite Events and Detection Details</p> Status Scenario name Details Details \u2705 <code>face-blurring</code> Blur any faces detected More details \u2705 <code>text-blurring</code> Blue any text detected (paper, computer screens etc) \u2705 <code>license-plate-blurring</code> Blur any license plates detected \ud83d\udcc5 <code>signs-blurring</code> Blur any signs detected \ud83d\udcc5 <code>obstructed-camera</code> If camera feed is obstructed, send an alert"},{"location":"scenarios/#company-policies","title":"Company Policies","text":"<p>Company policies include specific scenarios that are relevant to your company. These could include scenarios like no-smoking/no-vaping zones, no food or drinks in certain areas, or no cell phones/pictures in certain areas. Some of these scenarios overlap with occupancy metrics, but they are still useful to have here as separate scenarios.</p> <p>Table: Company Policies Events and Detection Details</p> Status Scenario name Supported Events Details \ud83d\udcc5 <code>no-food-or-drinks-allowed</code> <code>Person with food detected</code> <code>Person with drinks detected</code> <code>Spill event detected</code> More details \ud83d\udcc5 <code>no-phone-text-pictures</code> <code>Cellphone usage detected</code> <code>Person detected taking pictures</code> More details \u2705 <code>no-smoking-or-vaping</code> <code>Smoking event detected</code> <code>Vaping event detected</code> More details \ud83d\udcc5 <code>no-children-pets-visitors</code> <code>Children detected</code> <code>Pets detected</code> <code>Visitors detected</code> More details"},{"location":"scenarios/#suspicious-activity-detection","title":"Suspicious Activity detection","text":"<p>Suspicious activity detection suite includes knives &amp; firearms detection, graffitti &amp; vandalism detection etc.</p> <p>Table: Suspicious Activity Events and Detection Details</p> Status Scenario name Supported Events Details \ud83d\udcc5 <code>vandalism-graffiti</code> Vandalism or Graffiti detected More details \u2705 <code>firearms-knives</code> Firearm or Knife detected` More details"},{"location":"scenarios/#next-steps","title":"Next Steps","text":"<ul> <li>Quick Start</li> <li>Camera Placement Guide</li> <li>Supported Scenarios</li> <li>Camera Management</li> <li>FAQs</li> </ul>"},{"location":"scenarios/#contact-information","title":"Contact Information","text":"contact_phone Sales Inquiries <p>Get in touch with our sales team for demos and pricing information.</p> <ul> <li>Email: sales@visionify.ai</li> <li>Phone: +1 720-449-1124</li> </ul> support_agent Technical Support <p>Need help? Visit our support portal or contact our technical team.</p> <ul> <li>https://support.visionify.ai</li> <li>support@visionify.ai</li> </ul> calendar_month Schedule a Demo <p>See VisionAI in action with a personalized demo from our team.</p> event                 Book Your Demo"},{"location":"scenarios/aggressive-behavior/","title":"Aggressive Behavior","text":"<p>Create a safer and more productive work environment with our real-time Aggressive behaviour detection system.</p> <p> </p> Detection of Aggressive Behavior"},{"location":"scenarios/aggressive-behavior/#overview","title":"Overview","text":"<p>A workplace that is free from bullying, fighting, and aggressive behavior can help to improve employee well-being and overall job satisfaction. This can result in higher levels of productivity, better employee retention rates, and a more positive work environment. Aggressive behavior is a serious problem at workplaces. It can lead to serious injuries and even death. It is important to detect these behaviors early on, and preventive measures can be taken to address the issue before it escalates.</p> <p>These models are an important tool for promoting a safe and respectful environment at workplaces and other settings, and they have the potential to make a real difference in the lives of those who may be vulnerable to bullying or aggression.</p>"},{"location":"scenarios/aggressive-behavior/#vision-ai-based-monitoring","title":"Vision AI based monitoring","text":"<p>VisionAI's agressive behaviour detection model is designed to promote a safe, healthy, and productive workplace environment for all employees. The model is able to provide real-time alerts when it detects aggressive behavior. This will enable management to intervene and prevent escalation of the situation.</p>"},{"location":"scenarios/aggressive-behavior/#model-details","title":"Model Details","text":""},{"location":"scenarios/aggressive-behavior/#dataset","title":"Dataset","text":"<p>The dataset for this scenario is based on real-world data from different workplaces. The dataset consists of images and videos collected from various sources.</p>"},{"location":"scenarios/aggressive-behavior/#model","title":"Model","text":""},{"location":"scenarios/aggressive-behavior/#model-card","title":"Model card","text":"Dataset size Version Camera support Precision Recall  mAP   32,20 v1 Ceiling 95%  93%  85%"},{"location":"scenarios/aggressive-behavior/#scenario-details","title":"Scenario details","text":"<p>The business logic for this scenario is as follows: </p> <ul> <li> <p>We use existing camera feeds from the premises to monitor the presence of people and analyse their behaviour.</p> </li> <li> <p>VisionAI system is able to run on edge devices. It uses camera feeds for processing. </p> </li> <li> <p>An alarming system is in place as part of an aggressive behavior detection solution.</p> </li> </ul> Test now with online Web-CamWith RTSP Camera - PipelinesWith Azure Setup <p>To test this model &amp; scenario, you can use the following steps:</p> <ul> <li> <p>Install the visionai package from PyPI</p> <pre><code>$ pip install visionai\n</code></pre> </li> <li> <p>Test the scenario from your local web-cam</p> <pre><code>$ visionai scenario test aggressive-behavior-detection\n\nDownloading models for scenario: aggressive-behavior-detection\nModel: aggressive-behavior-detection: https://workplaceos.blob.core.windows.net/models/yolov5s-aggressive-behavior-detection/yolov5s-aggressive-behavior-detection-0.0.1.zip\n\n\nStarting scenario: aggressive-behavior-detection..\n</code></pre> </li> <li> <p>You should be able to see the events generated on your console window with the detections of aggressive behavior within the camera field of view.</p> </li> </ul> <p>[TODO]</p> <p>VisionAI app is available at a Azure Market place, one can download and use it by following steps mentioned here</p>"},{"location":"scenarios/aggressive-behavior/#features","title":"Features","text":"<ul> <li> <p>Easy to use: The model is easy to use and can be deployed in a variety of settings, including workplaces and other public spaces.</p> </li> <li> <p>Alert system: The model is able to generate alerts when it detects signs of bullying, fighting, or aggressive behavior, allowing management to take appropriate action to address the issue.</p> </li> <li> <p>Real-time monitoring: The detection model is be able to monitor and analyze interactions among employees in real-time to identify any signs of bullying, fighting, or aggressive behavior.</p> </li> </ul>"},{"location":"scenarios/aggressive-behavior/#training-with-custom-data","title":"Training with custom data","text":"<p>The scenario is provided as part of our GPL-v3 package for VisionAI. If you wish to train this with custom datasets, please contact us and we can provide you with the training code. You can do custom training with your own datasets for free, as long as it complies with GPLv3 license (you give back the code to the community). If you are interested in a custom license, please contact us.</p>"},{"location":"scenarios/aggressive-behavior/#contact-us","title":"Contact Us","text":"<ul> <li>For technical issues, you can open a Github issue here.</li> <li>For business inquiries, you can contact us through our website.</li> </ul>"},{"location":"scenarios/area-controls/","title":"Area Control","text":"<p>Transform your workplace safety program with AI-powered area monitoring that helps prevent accidents, maintains occupancy compliance, and ensures worker safety in restricted zones.</p> <p> </p> Real-time detection of safety zone violations <p>Our enterprise solution helps you:</p> <ul> <li>Prevent unauthorized access to dangerous areas</li> <li>Ensure worker safety in high-risk zones</li> <li>Monitor pedestrian and vehicle pathways</li> <li>Track occupancy limits in restricted areas</li> <li>Generate compliance documentation automatically</li> </ul>"},{"location":"scenarios/area-controls/#why-area-control-matters-for-workplace-safety","title":"Why Area Control Matters for Workplace Safety","text":"<p>In today's complex industrial environments, maintaining worker safety in different areas of your facility is a critical challenge for EHS managers. Whether it's:</p> <ul> <li>Protecting workers from dangerous equipment zones</li> <li>Managing occupancy in high-risk areas</li> <li>Ensuring compliance with safety regulations</li> <li>Preventing unauthorized access to restricted areas</li> <li>Maintaining clear emergency exit paths</li> </ul> <p>Traditional safety methods like physical barriers, warning signs, or periodic safety walks have significant gaps:</p> <ul> <li>No real-time monitoring capability</li> <li>Heavy reliance on worker compliance</li> <li>Limited coverage of large facilities</li> <li>Difficulty in proving compliance</li> <li>No data for safety improvements</li> <li>High cost of dedicated safety personnel</li> </ul>"},{"location":"scenarios/area-controls/#real-world-applications","title":"Real-World Applications","text":"Real-time detection of restricted zone violations Automated monitoring of pedestrian pathway compliance"},{"location":"scenarios/area-controls/#the-smart-solution-ai-powered-safety-monitoring","title":"The Smart Solution: AI-Powered Safety Monitoring","text":"<p>Visionify's Area Control solution transforms how you manage workplace safety zones:</p> <ol> <li>24/7 Automated Monitoring: Continuous protection of all safety zones</li> <li>Instant Safety Alerts: Real-time notifications when violations occur</li> <li>Easy Zone Management: Define and adjust safety zones through simple interface</li> <li>Compliance Documentation: Automated reporting for safety audits</li> <li>Data-Driven Safety: Analytics to improve safety programs</li> </ol>"},{"location":"scenarios/area-controls/#key-safety-scenarios-covered","title":"Key Safety Scenarios Covered","text":"<p>Our system helps you manage these critical workplace safety scenarios:</p> Safety Scenario How It Helps Restricted Areas Prevents unauthorized entry into dangerous zones Maximum Occupancy Maintains safe occupancy limits in work areas Time-Limited Access Controls access during specific shift times Confined Spaces Monitors worker safety in confined spaces Minimum Personnel Ensures required staff presence in critical areas Crowd Management Prevents unsafe crowding in work areas Suspended Load Areas Keeps workers safe from overhead operations Safe Pathways Maintains separation of pedestrian and vehicle traffic"},{"location":"scenarios/area-controls/#benefits-for-ehs-managers","title":"Benefits for EHS Managers","text":"<ul> <li>Improved Safety Performance: Prevent accidents before they happen</li> <li>Enhanced Compliance: Automated monitoring and documentation</li> <li>Reduced Costs: Lower insurance premiums and fewer incidents</li> <li>Better Resource Allocation: Data-driven safety improvements</li> <li>Simplified Audits: Complete safety violation records</li> <li>Scalable Solution: Works with existing security cameras</li> </ul>"},{"location":"scenarios/area-controls/#easy-implementation","title":"Easy Implementation","text":"<ol> <li>Quick Setup: Uses your existing camera infrastructure</li> <li>Flexible Configuration: Define safety zones based on your needs</li> <li>Multiple Alert Options: Email, SMS, or integration with existing systems</li> <li>Privacy Focused: Built-in face blurring for worker privacy</li> <li>Enterprise Ready: Secure, scalable, and reliable</li> </ol>"},{"location":"scenarios/area-controls/#success-stories","title":"Success Stories","text":"<p>\"Visionify's area control system has transformed how we manage safety zones in our facility. We've seen a 60% reduction in safety violations and significantly improved our audit compliance.\" - Safety Manager, Fortune 500 Manufacturing Company</p>"},{"location":"scenarios/area-controls/#learn-more","title":"Learn More","text":"<ul> <li>Quick Start</li> <li>Camera Placement Guide</li> <li>Supported Scenarios</li> <li>Camera Management</li> <li>FAQs</li> </ul>"},{"location":"scenarios/area-controls/#contact-information","title":"Contact Information","text":"contact_phone Sales Inquiries <p>Get in touch with our sales team for demos and pricing information.</p> <ul> <li>Email: sales@visionify.ai</li> <li>Phone: +1 720-449-1124</li> </ul> support_agent Technical Support <p>Need help? Visit our support portal or contact our technical team.</p> <ul> <li>https://support.visionify.ai</li> <li>support@visionify.ai</li> </ul> calendar_month Schedule a Demo <p>See VisionAI in action with a personalized demo from our team.</p> event                 Book Your Demo"},{"location":"scenarios/authorized-personnel-occupancy/","title":"Authorized Personnel","text":"<p>An intelligent way to enhance security and prevent unauthorized access to restricted areas.</p>"},{"location":"scenarios/authorized-personnel-occupancy/#overview","title":"Overview","text":"<p>Unauthorized entry or access refers to any member of the public other than employees entering areas of the restricted business premises or a warehouse. This could be done by an individual, a group of people, visitors or children/pets wrongly entering a restricted area. There can be different ways in which a security breach can happen and an unauthorized access can pose various risks;</p> <ul> <li>Safety risk</li> <li>Security risk</li> <li>Risk of non-compliance</li> <li>Risk of injury</li> </ul> <p>It is important for organizations to maintain security and controlled access at the workplace. However, conventional surveillance methods are often complex, human-oriented, expensive and challenging to automate. In addition, the existing solutions cannot detect intrusion after an unauthorized entry has taken place.</p>"},{"location":"scenarios/authorized-personnel-occupancy/#vision-ai-based-monitoring","title":"Vision AI based monitoring","text":"<p>Make your workplace safer and smarter with our VisionAI monitoring, a complete solution that helps you enforce security policy adherence and deter intruders effectively. Now, you can easily detect any attempts to gain unauthorized access with our fully automated system that guards your facility 24/7 and sends instant alerts to help you prevent a security breach before it occurs. </p> <p>Our system offers reliable detection and is easy to integrate with your existing camera infrastructure, allowing you to scale your system with a few simple clicks.</p>"},{"location":"scenarios/authorized-personnel-occupancy/#events","title":"Events","text":"<p>VisionAI model's generated events would be:</p> <ul> <li>Children detected in area</li> <li>Visitors detected in area</li> <li>Person without uniform detected</li> <li>Person without badge detected</li> </ul> <p>It is recommended that any instance of above detected events be reported to the appropriate authority. An event data for this scenario has information such as:</p> <ul> <li>Date and time of the event</li> <li>Location of the event</li> <li>Type of personnel identified</li> </ul>"},{"location":"scenarios/authorized-personnel-occupancy/#model-details","title":"Model Details","text":""},{"location":"scenarios/authorized-personnel-occupancy/#dataset","title":"Dataset","text":"<p>The dataset comprises relevant, high-quality, labeled videos and images from diverse sources. The dataset is evenly distributed and balanced with an equal number of examples for each category to avoid bias toward one class. It contains variations with different real-world scenarios to render effective and efficient results.</p>"},{"location":"scenarios/authorized-personnel-occupancy/#model-card","title":"Model card","text":"Dataset size Version Camera support Precision Recall  mAP   22,20 v1 Both(Ceiling and Straight) 95%  93%  85%"},{"location":"scenarios/authorized-personnel-occupancy/#scenario-details","title":"Scenario details","text":"<p>Our VisionAI solution for access control protects against unauthorized access and physical security incidents before they occur. Different scenarios of unauthorized access have been taken into account for real-time detection and alerts which include;</p> <ul> <li>Visitors detected in the area</li> <li>Employees without uniform trying to gain access </li> <li>Employees without badges trying to enter the premise </li> <li>Children/pets wrongly entering restricted areas</li> </ul> Test now with online Web-CamWith RTSP Camera - PipelinesWith Azure Setup <p>To test this model &amp; scenario, you can use the following steps:</p> <ul> <li> <p>Install the visionai package from PyPI</p> <pre><code>$ pip install visionai\n</code></pre> </li> <li> <p>Test the scenario from your local web-cam</p> <pre><code>$ visionai scenario test auth-personnel-detection\n\nDownloading models for scenario: auth-personnel-detection\nModel: miss-fire-exting-detection: https://workplaceos.blob.core.windows.net/models/yolov5s-people/yolov5s-people-0.0.4.zip\n\n\nStarting scenario: auth-personnel-detection..\n</code></pre> </li> <li> <p>You should be able to see the events generated on your console window with authorized personnel identified within the camera field of view.</p> </li> </ul> <p>[TODO]</p> <p>VisionAI app is available at a Azure Market place, one can download and use it by following steps mentioned here</p>"},{"location":"scenarios/authorized-personnel-occupancy/#features","title":"Features","text":"<p>Some potential features of VisionAI for identifying authorized personnel could include: - Improved safety and security - Enhanced visual monitoring of each entry and exit point across all locations - Remotely monitor and instantly investigate any security concerns taking place even after working hours - Immediately get notified of potential physical security breaches, address them quickly and operate effectively.</p>"},{"location":"scenarios/authorized-personnel-occupancy/#training-with-custom-data","title":"Training with custom data","text":"<p>The scenario is provided as part of our GPL-v3 package for VisionAI. If you wish to train this with custom datasets, please contact us and we can provide you with the training code. You can do custom training with your own datasets for free, as long as it complies with GPLv3 license (you give back the code to the community). If you are interested in a custom license, please contact us.</p>"},{"location":"scenarios/authorized-personnel-occupancy/#contact-us","title":"Contact Us","text":"<ul> <li>For technical issues, you can open a Github issue here.</li> <li>For business inquiries, you can contact us through our website.</li> </ul>"},{"location":"scenarios/authorized-personnel/","title":"Authorized Personnel","text":"<p>An intelligent way to enhance security and prevent unauthorized access to restricted areas.</p>"},{"location":"scenarios/authorized-personnel/#overview","title":"Overview","text":"<p>Unauthorized entry or access refers to any member of the public other than employees entering areas of the restricted business premises or a warehouse. This could be done by an individual, a group of people, visitors or children/pets wrongly entering a restricted area. There can be different ways in which a security breach can happen and an unauthorized access can pose various risks;</p> <ul> <li>Safety risk</li> <li>Security risk</li> <li>Risk of non-compliance</li> <li>Risk of injury</li> </ul> <p>It is important for organizations to maintain security and controlled access at the workplace. However, conventional surveillance methods are often complex, human-oriented, expensive and challenging to automate. In addition, the existing solutions cannot detect intrusion after an unauthorized entry has taken place.</p>"},{"location":"scenarios/authorized-personnel/#vision-ai-based-monitoring","title":"Vision AI based monitoring","text":"<p>Make your workplace safer and smarter with our VisionAI monitoring, a complete solution that helps you enforce security policy adherence and deter intruders effectively. Now, you can easily detect any attempts to gain unauthorized access with our fully automated system that guards your facility 24/7 and sends instant alerts to help you prevent a security breach before it occurs. </p> <p>Our system offers reliable detection and is easy to integrate with your existing camera infrastructure, allowing you to scale your system with a few simple clicks.</p>"},{"location":"scenarios/authorized-personnel/#events","title":"Events","text":"<p>VisionAI model's generated events would be:</p> <ul> <li>Children detected in area</li> <li>Visitors detected in area</li> <li>Person without uniform detected</li> <li>Person without badge detected</li> </ul> <p>It is recommended that any instance of above detected events be reported to the appropriate authority. An event data for this scenario has information such as:</p> <ul> <li>Date and time of the event</li> <li>Location of the event</li> <li>Type of personnel identified</li> </ul>"},{"location":"scenarios/authorized-personnel/#model-details","title":"Model Details","text":""},{"location":"scenarios/authorized-personnel/#dataset","title":"Dataset","text":"<p>The dataset comprises relevant, high-quality, labeled videos and images from diverse sources. The dataset is evenly distributed and balanced with an equal number of examples for each category to avoid bias toward one class. It contains variations with different real-world scenarios to render effective and efficient results.</p>"},{"location":"scenarios/authorized-personnel/#model-card","title":"Model card","text":"Dataset size Version Camera support Precision Recall  mAP   22,20 v1 Both(ceiling and Straight) 95%  93%  85%"},{"location":"scenarios/authorized-personnel/#scenario-details","title":"Scenario details","text":"<p>Our VisionAI solution for access control protects against unauthorized access and physical security incidents before they occur. Different scenarios of unauthorized access have been taken into account for real-time detection and alerts which include;</p> <ul> <li>Visitors detected in the area</li> <li>Employees without uniform trying to gain access </li> <li>Employees without badges trying to enter the premise </li> <li>Children/pets wrongly entering restricted areas</li> </ul> Test now with online Web-CamWith RTSP Camera - PipelinesWith Azure Setup <p>To test this model &amp; scenario, you can use the following steps:</p> <ul> <li> <p>Install the visionai package from PyPI</p> <pre><code>$ pip install visionai\n</code></pre> </li> <li> <p>Test the scenario from your local web-cam</p> <pre><code>$ visionai scenario test auth-personnel-detection\n\nDownloading models for scenario: auth-personnel-detection\nModel: miss-fire-exting-detection: https://workplaceos.blob.core.windows.net/models/yolov5s-people/yolov5s-people-0.0.4.zip\n\n\nStarting scenario: auth-personnel-detection..\n</code></pre> </li> <li> <p>You should be able to see the events generated on your console window with authorized personnel identified within the camera field of view.</p> </li> </ul> <p>[TODO]</p> <p>VisionAI app is available at a Azure Market place, one can download and use it by following steps mentioned here</p>"},{"location":"scenarios/authorized-personnel/#features","title":"Features","text":"<p>Some potential features of VisionAI for identifying authorized personnel could include: - Improved safety and security - Enhanced visual monitoring of each entry and exit point across all locations - Remotely monitor and instantly investigate any security concerns taking place even after working hours - Immediately get notified of potential physical security breaches, address them quickly and operate effectively.</p>"},{"location":"scenarios/authorized-personnel/#training-with-custom-data","title":"Training with custom data","text":"<p>The scenario is provided as part of our GPL-v3 package for VisionAI. If you wish to train this with custom datasets, please contact us and we can provide you with the training code. You can do custom training with your own datasets for free, as long as it complies with GPLv3 license (you give back the code to the community). If you are interested in a custom license, please contact us.</p>"},{"location":"scenarios/authorized-personnel/#contact-us","title":"Contact Us","text":"<ul> <li>For technical issues, you can open a Github issue here.</li> <li>For business inquiries, you can contact us through our website.</li> </ul>"},{"location":"scenarios/blocked-exit/","title":"Blocked Exit monitoring","text":"<p>Ensure that your organziation is safe &amp; compliant for any emergency evacuations. If any of your exits are blocked - get an event notifications so it can be quickly resolved.</p> <p>Detection of blocked exit</p>"},{"location":"scenarios/blocked-exit/#overview","title":"Overview","text":"<p>Every second counts in emergency situations such as fires, earthquakes, or other disasters, and people need to evacuate the premises as quickly as possible to avoid being trapped or injured. Therefore, the presence of functional emergency exits and a well-designed escape route plan is of paramount importance. </p> <p>Any blockages or obstructions in the exits could prove fatal as they hinder people's ability to evacuate safely and quickly. However, the accumulation of debris, fire flames, and toxic gasses can block exits. Time is of the essence, and wrong escape plans can impede people from escaping quickly and safely. </p> <p>Moreover, People may try to force their way through blocked exits, leading to injuries or even fatalities. In addition, blocked exits can hinder the efforts of rescue teams trying to enter the building to help those in need. This makes it critical to preempt operational exits and detect blocked ones before the situation worsens.</p>"},{"location":"scenarios/blocked-exit/#vision-ai-based-monitoring","title":"Vision AI based monitoring","text":"<p>VisionAI based emergency rescue solution leverages cutting-edge AI-powered, real-time detection and monitoring of emergency exits with alerts and warnings for safe and secure evacuation in times of crisis. </p> <p>With our Blocked Exit Monitoring solution, you can rest assured that your premises are being monitored continuously, providing early warnings in case of any blockages in emergency exits. Our models can be deployed instantly and can augment your existing camera infrastructure with just a few clicks.</p>"},{"location":"scenarios/blocked-exit/#events","title":"Events","text":"<p>VisionAI model's generated events would be:</p> <ul> <li>Blocked exit detected</li> </ul>"},{"location":"scenarios/blocked-exit/#model-details","title":"Model Details","text":""},{"location":"scenarios/blocked-exit/#dataset","title":"Dataset","text":"<p>The dataset consists of images and videos collected from diverse sources and is designed to reflect real-world scenarios. It is evenly distributed with:</p> <ul> <li>Images of blocked exits: These images would provide visual examples of what a typical blocked exit looks like.</li> </ul> <p>Images of different types of blockages which includes: </p> <ul> <li> <p>Images of debris: Images of different types of debris, such as fallen objects or construction materials, would help the model to recognize obstructions in the path to the exit.</p> </li> <li> <p>Images of fire: Providing images of fire, smoke, and flames would help the model to recognize the different visual parameters that indicate a fire hazard.</p> </li> <li> <p>Images of toxic gasses: Images of different types of toxic gasses, such as carbon monoxide, would help the model to recognize the signs of gas leaks and other potential hazards.</p> </li> <li> <p>Images of overcrowding: Providing images of overcrowded spaces would help the model to recognize the risk of blockages in case of an emergency.</p> </li> <li> <p>Images of unobstructed exits: Providing images of exits that are not blocked would help the model to distinguish between blocked and unblocked exits.</p> </li> </ul>"},{"location":"scenarios/blocked-exit/#model-card","title":"Model card","text":"Dataset size Version Camera support Precision Recall  mAP   22,20 v1 Both(ceiling and Straight) 95%  93%  85%"},{"location":"scenarios/blocked-exit/#scenario-details","title":"Scenario details","text":"<p>The business logic for this scenario is as follows: - We use existing camera feeds from the premises to monitor blocked exits - VisionAI system is run at the edge. It uses the camera feeds for processing.</p> Test now with online Web-CamWith RTSP Camera - PipelinesWith Azure Setup <p>To test this model &amp; scenario, you can use the following steps:</p> <ul> <li> <p>Install the visionai package from PyPI</p> <pre><code>$ pip install visionai\n</code></pre> </li> <li> <p>Test the scenario from your local web-cam</p> <pre><code>$ visionai scenario test blocked-exit\n</code></pre> <p>Downloading models for scenario: blocked-exit Model: blocked-exit: https://workplaceos.blob.core.windows.net/models/yolov5s-people/yolov5s-people-0.0.4.zip</p> <p>Starting scenario: blocked-exit..</p> <p>```</p> </li> <li> <p>You should be able to see the events generated on your console window with the detections of maximum occupancy event within the camera field of view.</p> </li> </ul> <p>[TODO]</p> <p>VisionAI app is available at a Azure Market place, one can download and use it by following steps mentioned here</p>"},{"location":"scenarios/blocked-exit/#features","title":"Features","text":"<p>Some potential features of VisionAI for monitoring maximum occupancy include:</p> <ul> <li> <p>Real-time monitoring of maximum occupancy: VisionAI can monitor blocked exits in real-time, providing an automated and seamless approach to crowd management.</p> </li> <li> <p>Instant alerts and warnings: VisionAI can send instant alerts and warnings for detected blocked exits</p> </li> <li> <p>Easy to deploy: VisionAI can be easily deployed with minimal effort, allowing businesses to leverage our AI-based technology with minimal effort.</p> </li> </ul>"},{"location":"scenarios/blocked-exit/#training-with-custom-data","title":"Training with custom data","text":"<p>The scenario is provided as part of our GPL-v3 package for VisionAI. If you wish to train this with custom datasets, please contact us and we can provide you with the training code. You can do custom training with your own datasets for free, as long as it complies with GPLv3 license (you give back the code to the community). If you are interested in a custom license, please contact us.</p>"},{"location":"scenarios/blocked-exit/#learn-more","title":"Learn More","text":"<ul> <li>Quick Start</li> <li>Camera Placement Guide</li> <li>Supported Scenarios</li> <li>Camera Management</li> <li>FAQs</li> </ul>"},{"location":"scenarios/blocked-exit/#contact-information","title":"Contact Information","text":"contact_phone Sales Inquiries <p>Get in touch with our sales team for demos and pricing information.</p> <ul> <li>Email: sales@visionify.ai</li> <li>Phone: +1 720-449-1124</li> </ul> support_agent Technical Support <p>Need help? Visit our support portal or contact our technical team.</p> <ul> <li>https://support.visionify.ai</li> <li>support@visionify.ai</li> </ul> calendar_month Schedule a Demo <p>See VisionAI in action with a personalized demo from our team.</p> event                 Book Your Demo"},{"location":"scenarios/compliance-policies/","title":"Compliance policies","text":"<p>Compliance policies are put in place by companies to ensure the safety of employees, customers, and the general public. To send real-time alerts to employees, managers, and other stakeholders if there is a potential violation or deviation from established policies and procedures.</p> <p>These are a set of rules and regulations that a company creates and enforces to ensure that it operates in accordance with applicable laws, regulations, and ethical standards. The purpose of compliance policies is to help companies prevent legal and ethical violations, promote responsible conduct, and maintain their reputation and public trust. Some of these are  No pictures and no mobile phones in certain areas etc. There are many events that could trigger an alert for non-adherence to a compliance policy. Here are a few use cases:</p> <ul> <li>No food or drinks</li> <li>No phone, text, pictures</li> <li>No Smoking zones</li> <li>No children/visitors</li> </ul>"},{"location":"scenarios/confined-spaces-monitoring/","title":"Confined Spaces Monitoring","text":"<p>Ensure safety of employees in confined spaces. Get real-time alerts when workers are present in the space for too long.</p>"},{"location":"scenarios/confined-spaces-monitoring/#overview","title":"Overview","text":"<p>Confined spaces refer to areas that are partially or fully enclosed and are not designed for continuous human occupancy. Examples include tanks, silos, storage bins, manholes, and underground vaults. These spaces can be hazardous due to limited ventilation, lack of natural light, and potential for hazardous atmospheric conditions.</p> <p>Workers entering confined spaces are at risk of being overcome by toxic gases, asphyxiation, or other hazards. In addition, workers may be trapped in the confined space if an emergency occurs. Therefore, it is important to monitor confined spaces to ensure that they remain safe for workers.</p> <p>To monitor confined spaces, cameras can be used - with an oversight manager observing these spaces. Along with cameras other IoT devices can be used to measure atmospheric conditions such as air quality, temperature, humidity, and toxic gas levels.</p>"},{"location":"scenarios/confined-spaces-monitoring/#vision-ai-based-monitoring","title":"Vision AI based monitoring","text":"<p>Vision AI based monitors can be used to monitor confined spaces by providing real-time video feeds of the area. These cameras can be used to monitor the presence of workers in the confined space, as well as the duration of how long they are present within the space. Companies can put compliance policies in place to ensure that workers are not present in the confined space for an extended period of time. Camera based monitors can track workers entering the premises, and monitor their total duration of stay; and if that exceeds the compliance policy, an alert can be raised.</p> <p>It is important to note that these camera based monitoring provides should be supplanted by strong compliance processes to ensure their accuracy and reliability. In addition, workers entering confined spaces should always be trained on proper use of the monitoring equipment and be familiar with the hazards associated with confined spaces.</p>"},{"location":"scenarios/confined-spaces-monitoring/#model-details","title":"Model Details","text":""},{"location":"scenarios/confined-spaces-monitoring/#dataset","title":"Dataset","text":"<p>The datasets for this scenario is based off of people detection and tracking algorithms that are used in the industry. The dataset is a combination of images and videos from various sources. The dataset is curated to ensure that it is representative of the real world. It has equal distributions for:</p> <ul> <li>Indoor vs Outdoor environments</li> <li>Male vs Female</li> <li>Day vs Night</li> <li>Different types of clothing</li> <li>Different distances from the camera</li> <li>Various lighting conditions</li> <li>Various camera angles and resolutions</li> <li>Using seurity camera feeds</li> </ul> <p>Total number of images used was 387,644</p>"},{"location":"scenarios/confined-spaces-monitoring/#model","title":"Model","text":"<p>The model is based off of the YOLOv5 algorithm. The model is trained on a custom dataset of images and videos. The model is trained based on the above dataset curated by our team.</p>"},{"location":"scenarios/confined-spaces-monitoring/#model-card","title":"Model card","text":"Dataset size Version Camera support Precision Recall  mAP   2678 v2 Ceiling 94% 96% 94% <p>The model is light-weight enough to be run on any edge devices.</p>"},{"location":"scenarios/confined-spaces-monitoring/#scenario-details","title":"Scenario details","text":"<p>The business logic for this scenario is as follows: - We use existing camera feeds from the premises to monitor the presence of workers in the confined space. - VisionAI system is run at the edge. It uses the camera feeds for processing. - We detect and track people identified in this camera feed. - We monitor the total duration of stay of these people in the confined space. - If the duration of stay exceeds the compliance policy, an alert is raised.</p> Test now with online Web-CamWith RTSP Camera - PipelinesWith Azure Setup <p>To test this model &amp; scenario, you can use the following steps:</p> <ul> <li> <p>Install the visionai package from PyPI</p> <pre><code>$ pip install visionai\n</code></pre> </li> <li> <p>Test the scenario from your local web-cam</p> <pre><code>$ visionai scenario test obstructed-camera-detection\n\nDownloading models for scenario: obstructed-camera-detection\nModel: obstructed-camera-detection: https://workplaceos.blob.core.windows.net/models/yolov5s-obstructed-camera-detection/yolov5s-obstructed-camera-detection-0.0.1.zip\n\n\nStarting scenario: obstructed-camera-detection..\n</code></pre> </li> <li> <p>You should be able to see the events generated on your console window with the detections of people exceeding the duration limit within the camera field of view.</p> </li> </ul> <p>[TODO]</p> <p>VisionAI app is available at a Azure Market place, one can download and use it by following steps mentioned here</p>"},{"location":"scenarios/confined-spaces-monitoring/#events-supported","title":"Events Supported","text":"<p>This scenario supports the following events:</p> <ul> <li>Person detected: This event is generated when a person is detected in the camera feed.</li> <li>Person left: This event is generated when a person is no longer detected in the camera feed.</li> <li>Person duration exceeded: This event is generated when a person is detected for more than the specified duration in the camera feed. The duration amount is configurable through the web-app.</li> </ul>"},{"location":"scenarios/confined-spaces-monitoring/#training-with-custom-data","title":"Training with custom data","text":"<p>The scenario is provided as part of our GPL-v3 package for VisionAI. If you wish to train this with custom datasets, please contact us and we can provide you with the training code. You can do custom training with your own datasets for free, as long as it complies with GPLv3 license (you give back the code to the community). If you are interested in a custom license, please contact us.</p>"},{"location":"scenarios/confined-spaces-monitoring/#contact-us","title":"Contact Us","text":"<ul> <li>For technical issues, you can open a Github issue here.</li> <li>For business inquiries, you can contact us through our website.</li> </ul>"},{"location":"scenarios/custom-scenarios/","title":"Custom scenarios","text":"<p>Coming soon</p>"},{"location":"scenarios/employee-privacy/","title":"Employee Privacy","text":"<p>Employee privacy is a concern for many companies. The use of cameras in the workplace can be a sensitive issue. Employees may feel that their privacy is being violated. They may also feel that their personal space is being invaded. This can lead to a loss of trust and confidence in the company.</p> <p>Privacy policies are put in place to protect employees from unwarranted surveillance. They also help to ensure that employees are not subjected to any form of discrimination or harassment.</p> <p>To send real-time alerts to employees, managers, and other stakeholders if there is a potential violation or deviation from established policies and procedures.</p> <p>These are a set of rules and regulations that a company creates and enforces to ensure that it operates in accordance with applicable laws, regulations, and ethical standards. The purpose of compliance policies is to help companies prevent legal and ethical violations, promote responsible conduct, and maintain their reputation and public trust. Some of these are  No pictures and no mobile phones in certain areas etc. There are many events that could trigger an alert for non-adherence to privacy policies. Here are a few use cases:</p> <ul> <li>Blur faces</li> <li>Blur signs/text</li> <li>Blur screens</li> <li>Blur license plates</li> <li>Obstructed camera view</li> </ul>"},{"location":"scenarios/ergonomics/","title":"Ergonomics Monitoring","text":"<p>Ensure safety and comfort of employees by monitoring ergonomics. </p>"},{"location":"scenarios/ergonomics/#overview","title":"Overview","text":"<p>Ergonomics is the study of designing and arranging products, systems, and environments to fit the capabilities and limitations of people, with the goal of improving efficiency, safety, and comfort. The primary focus of ergonomics is to create environments that optimize human performance and well-being.</p>"},{"location":"scenarios/ergonomics/#vision-ai-based-monitoring","title":"Vision AI based monitoring","text":"<p>Vision AI based monitors can be used to monitor productivity and workers health by providing real-time video feeds of different areas. These cameras can be used to monitor and track number of objects moved by persons from one place to the other, as well as the bending information of workers while performing this work. </p> <p>Companies can put compliance policies in place to ensure that workers are made aware of work-related injuries and illnesses\u202fdue to unnecessary bending.  </p> <p>It is important to note that these camera-based monitoring provides should be supplanted by strong compliance processes to ensure their accuracy and reliability. In addition, workers working in companies should always be trained on ergonomics and its significance for safety and its impact on human health.</p>"},{"location":"scenarios/ergonomics/#events","title":"Events","text":"<p>VisionAI model's generated events would be:</p> <ul> <li>Bend count event per individual</li> </ul>"},{"location":"scenarios/ergonomics/#model-details","title":"Model Details","text":""},{"location":"scenarios/ergonomics/#dataset","title":"Dataset","text":"<p>Model training is carried out with Microsoft COCO: Common Objects in Context dataset. Person and Book classes are considered for model building. Person class is considered here because the problem of ergonomics is related to pose estimation and the object used to show movement is the book. It is the object carried by a person from one location to the other. Other objects can be considered as per the requirement.  </p> <p>The dataset is made up of a large number of images and it is curated to ensure a true  representation of the real world for: </p> <ul> <li> <p>Indoor vs Outdoor environments </p> </li> <li> <p>Variations in time  </p> </li> <li> <p>Different types of clothing for persons </p> </li> <li> <p>Different distances from the camera </p> </li> <li> <p>Various lighting conditions </p> </li> <li> <p>Various camera angles, resolutions and calibrations </p> </li> <li> <p>Using security camera feeds </p> </li> </ul>"},{"location":"scenarios/ergonomics/#model","title":"Model","text":"<p>The Yolov5 pre-trained model for detecting person and book (an example of an item) classes are used to build the model. DenseNet is employed to estimate each person's landmarks. These landmarks are used to estimate poses. This is mostly used to track a person's bending motion. To guarantee the counting of boxes, object tracking using a strong sort algorithm is also built. </p> <p>This provides ergonomics data that may be utilised for a variety of tasks, such as alarm generation when the number of bends exceeds predetermined levels and productivity counting to determine how many objects were transported from one location to another. </p>"},{"location":"scenarios/ergonomics/#model-card","title":"Model card","text":"<p>The DenseNet Model for Landmark detection</p> Dataset size Version Camera support Precision Recall  mAP   10894 v2 Straight 84% 72% 84% <p>The model is lightweight enough to be run on any edge device. </p>"},{"location":"scenarios/ergonomics/#scenario-details","title":"Scenario details","text":"<p>The business logic for this scenario is as follows: </p> <ul> <li> <p>We use existing camera feeds from the premises to monitor the presence of workers. </p> </li> <li> <p>VisionAI system is able to run on edge devices. It uses camera feeds for processing. </p> </li> <li> <p>We detect and track the number of objects transported and we monitor the total number of bending motions of a person while working.</p> </li> </ul> <p>=== \"Test now with online Web-Cam\"      To test this model &amp; scenario, you can use the following steps:</p> <pre><code> - Install the visionai package from PyPI\n\n    ```console\n    $ pip install visionai\n\n    ```\n\n - Test the scenario from your local web-cam\n\n\n    ```console\n    $ visionai scenario test ergonomics\n\n    ```\n\n    Downloading models for scenario: ergonomics\n\n\n\n    Starting scenario: ergonomics..\n\n    ```\n- You should be able to see the events generated on your console window with the detections of firearms and knives event within the camera field of view.\n</code></pre> With RTSP Camera - PipelinesWith Azure Setup <p>[TODO]</p> <p>VisionAI app is available at a Azure Market place, one can download and use it by following steps mentioned here</p>"},{"location":"scenarios/ergonomics/#training-with-custom-data","title":"Training with custom data","text":"<p>The scenario is provided as part of our GPL-v3 package for VisionAI. If you wish to train this with custom datasets, please contact us and we can provide you with the training code. You can do custom training with your own datasets for free, as long as it complies with GPLv3 license (you give back the code to the community). If you are interested in a custom license, please [contact us] (../company/contact.md).</p>"},{"location":"scenarios/ergonomics/#contact-us","title":"Contact Us","text":"<ul> <li>For technical issues, you can open a Github issue here.</li> <li>For business inquiries, you can contact us through our website.</li> </ul>"},{"location":"scenarios/exclusion-zones/","title":"Restricted areas/times","text":"<p>Secure restricted areas with our powerful AI-based monitoring system that detects and prevents unauthorized access in real-time</p> <p> </p> Detection of unauthorized entry event"},{"location":"scenarios/exclusion-zones/#overview","title":"Overview","text":"<p>Unauthorized access to restricted zones at the workplace can lead to theft, accidents, and other security breaches. Be it valuable assets, sensitive information or providing employee safety, maintaining high-security and controlled access for restricted zones at the workplace is essential for all organizations. However, monitoring and controlling access to these areas is often an expensive and error-prone process, requiring continuous manual surveillance by security personnel.</p> <p>Another major problem with existing systems cannot detect intrusion after an unauthorized access has been made.This renders biometric, sensors and security personnels ineffective after an unauthorized access has been already made.</p>"},{"location":"scenarios/exclusion-zones/#vision-ai-based-monitoring","title":"Vision AI based monitoring","text":"<p>With our Vision AI monitoring you can authorize access as well as continuous monitor live feeds inside a restricted area for real-time detection of unauthorized personnel. Our fully automated detection models are not only more powerful and accurate than existing systems but also more affordable and easy to integrate into existing infrastructure allowing users to scale the power of i-based real-time detection with a few simple clicks.</p>"},{"location":"scenarios/exclusion-zones/#events","title":"Events","text":"<p>VisionAI model's generated events would be:</p> <ul> <li>Person detected in restricted area</li> <li>Movement detected in restricted area</li> <li>Person detected after hours</li> <li>Movement detected after hours\"</li> </ul> <p>It is recommended that any instance of unauthorized entry be reported to the appropriate authority. An event data for a unauthozrized entry in exclusion zones may include information such as:</p> <ul> <li>Date and time of the event</li> <li>Location of the event</li> <li>Image of the event</li> </ul>"},{"location":"scenarios/exclusion-zones/#model-details","title":"Model Details","text":""},{"location":"scenarios/exclusion-zones/#dataset","title":"Dataset","text":"<p>The dataset consists of images and videos collected from diverse sources and is designed to reflect real-world scenarios. It is evenly distributed with:</p> <ul> <li> <p>Different environments: Both indoor and outdoor with varying/contrasting surrounding and infrastructure details</p> </li> <li> <p>Different angles and perspectives: The dataset includes images captured from different angles and perspectives, such as from above, below, or from the side of subjects</p> </li> <li> <p>Different modes of unauthorized access: The dataset includes images of individuals attempting to gain unauthorized access in different ways, such as climbing over fences, breaking locks, using counterfeit credentials, or attempting to sneak past security personnel.</p> </li> <li> <p>Diversity of individuals: The dataset includes images of individuals from different genders, ages, and ethnicities, to ensure that the AI model is able to accurately detect unauthorized access attempts regardless of the individual's appearance.</p> </li> </ul>"},{"location":"scenarios/exclusion-zones/#model","title":"Model","text":"<p>The model is based off of the YOLOv5 algorithm. The model is trained on a custom dataset of images and videos. The model is trained based on the above dataset compiled by our team.</p>"},{"location":"scenarios/exclusion-zones/#model-card","title":"Model card","text":"Dataset size Version Camera support Precision Recall  mAP   10k v2 Ceiling 98% 95% 95%"},{"location":"scenarios/exclusion-zones/#scenario-details","title":"Scenario details","text":"<p>Real-time detection and alerts for different kinds unauthorized access which includes but are not limited to:</p> <ul> <li>When an unauthorized person follows an authorized person through a secure area without proper authorization</li> <li>When an individual lingering around restricted areas without proper authorization</li> <li>Forceful entry </li> <li>Use of counterfeit access credentials</li> <li>Unauthorized access attempts during off-hours</li> </ul> Test now with online Web-CamWith RTSP Camera - PipelinesWith Azure Setup <p>To test this model &amp; scenario, you can use the following steps:</p> <ul> <li> <p>Install the visionai package from PyPI</p> <pre><code>$ pip install visionai\n</code></pre> </li> <li> <p>Test the scenario from your local web-cam</p> <pre><code>$ visionai scenario test exclusion-detection\n\nDownloading models for scenario: exclusion-detection\nModel: miss-fire-exting-detection: https://workplaceos.blob.core.windows.net/models/yolov5s-people/yolov5s-people-0.0.4.zip\n\n\nStarting scenario: exclusion-detection..\n</code></pre> </li> <li> <p>You should be able to see the events generated on your console window with the detections of unauthorized access or forceful entry within the camera field of view.</p> </li> </ul> <p>[TODO]</p> <p>VisionAI app is available at a Azure Market place, one can download and use it by following steps mentioned here</p>"},{"location":"scenarios/exclusion-zones/#features","title":"Features","text":"<p>Some potential features of VisionAI for detecting missing fire extinguishers could include:</p> <ul> <li> <p>Lightning Fast and Response Time: Ultra-fast Processing for real-time inference results and feedback (~30 frames per second processing) with customizable telemetry and inference results for your requirements.</p> </li> <li> <p>Scalability and Instant Deployment: Our pre-trained/custom models can be deployed instantly and are camera independent which means they can be pre-installed with existing cameras on site. </p> </li> <li> <p>Custom Integrations: Our custom smart dashboards and real-time alert/notification systems can be tailored to fit your specific needs be it simple dashboards or complex ERP integrations.</p> </li> <li> <p>Multiple channels for notifications: Employee Role-based notifications and alerts through different omni channels like emails, messages, custom alert systems, etc.</p> </li> <li> <p>Pre-Processing and Privacy by design: Our Pre-processing enhances Image quality before further analysis  While  maintaining data privacy by blurring out faces and other sensitive information present in a frame.</p> </li> </ul>"},{"location":"scenarios/exclusion-zones/#training-with-custom-data","title":"Training with custom data","text":"<p>The scenario is provided as part of our GPL-v3 package for VisionAI. If you wish to train this with custom datasets, please contact us and we can provide you with the training code. You can do custom training with your own datasets for free, as long as it complies with GPLv3 license (you give back the code to the community). If you are interested in a custom license, please contact us.</p>"},{"location":"scenarios/exclusion-zones/#contact-us","title":"Contact Us","text":"<ul> <li>For technical issues, you can open a Github issue here.</li> <li>For business inquiries, you can contact us through our website.</li> </ul>"},{"location":"scenarios/fall-and-accident-detection/","title":"Fall &amp; Accident detection","text":"<p>Detect potential collision/accident and wet floor, inspect slip and fall instances with VisionAI.</p>"},{"location":"scenarios/fall-and-accident-detection/#overview","title":"Overview","text":"<p>Fall &amp; Accident computer vision based detection system is designed to detect potential safety hazards in a given environment. The system uses video data from cameras placed in the area to identify a range of potential hazards, including person slip &amp; fall, potential collision/accident, wet floor, debris on the floor, and wet/slippery signs.</p> <p>To detect these hazards, the system uses deep learning-based algorithms to analyze the video data and identify specific patterns and features that correspond to each type of hazard. For example, to detect a person slip &amp; fall, the system may look for sudden changes in movement, unusual body positions, or signs of distress.</p> <p>Similarly, to detect potential collisions or accidents, the system may analyze the movement of people or objects in the environment and identify situations where there is a high likelihood of a collision or other accident occurring.</p>"},{"location":"scenarios/fall-and-accident-detection/#vision-ai-based-monitoring","title":"Vision AI based monitoring","text":"<p>Vision AI-based system can be used to detect slip and fall with high accuracy. Additionally, our model trained on real-world images minimizes false-positives or false-negatives.  </p> <p>The cameras scan every frame to ensure there are no accidents related to slip and fall cases. </p> <p>To detect a wet floor, the system may look for areas where there is a significant change in reflectance or texture, which could indicate the presence of moisture.</p> <p>To detect debris on the floor, the system may analyze the texture and shape of objects in the environment and identify items that are out of place or could potentially cause a tripping hazard.</p> <p>Finally, to detect wet/slippery signs, the system may analyze the shape and color of signs in the environment and identify those that indicate a wet or slippery floor.</p> <p>Overall, the system is designed to help improve safety in a range of environments, from factories and warehouses to retail stores and public spaces. By detecting potential hazards in real-time, the system can alert workers or visitors to potential dangers and help prevent accidents and injuries.</p>"},{"location":"scenarios/fall-and-accident-detection/#model-details","title":"Model Details","text":""},{"location":"scenarios/fall-and-accident-detection/#dataset","title":"Dataset","text":"<p>The dataset for this scenario is based on real-world data from different workplaces. The dataset consists of images and videos collected from various sources. </p>"},{"location":"scenarios/fall-and-accident-detection/#model-card","title":"Model card","text":"Dataset size Version Camera support Precision Recall  mAP   72,20 v1 Both(Ceiling and Straight) 95%  93%  85%"},{"location":"scenarios/fall-and-accident-detection/#scenario-details","title":"Scenario details","text":"<p>The business logic for this scenario is as follows:</p> <ul> <li> <p>We use existing camera feeds from the premises to detect potential collision/accident and wet floor, monitor and detect occurrences of slip and fall incidents.  </p> </li> <li> <p>VisionAI system is able to run on edge devices. It uses camera feeds for processing.</p> </li> <li> <p>An alert will be raised, when a potential collision/accident and wet floor is detected and/or occurrence slip and fall instance.</p> </li> </ul> Test now with online Web-CamWith RTSP Camera - PipelinesWith Azure Setup <p>To test this model &amp; scenario, you can use the following steps:</p> <ul> <li> <p>Install the visionai package from PyPI</p> <pre><code>$ pip install visionai\n</code></pre> </li> <li> <p>Test the scenario from your local web-cam</p> <pre><code>$ visionai scenario test fall-and-accident-detection\n\nDownloading models for scenario: fall-and-accident-detection\nModel: fall-and-accident-detection: https://workplaceos.blob.core.windows.net/models/yolov5s-fall-and-accident-detection/yolov5s-fall-and-accident-detection-0.0.1.zip\n\n\nStarting scenario: fall-and-accident-detection..\n</code></pre> </li> <li> <p>You should be able to see the events generated on your console window with the detections of potential collision/accident and wet floor, slip and fall instances within the camera field of view.</p> </li> </ul> <p>[TODO]</p> <p>VisionAI app is available at a Azure Market place, one can download and use it by following steps mentioned here</p>"},{"location":"scenarios/fall-and-accident-detection/#features","title":"Features","text":"<ul> <li> <p>Continuous monitoring: The model continuously monitors the user movements to ensure that they are safe and alert the user or emergency services if necessary. This includes monitoring the user's heart rate, breathing, and other vital signs to detect any signs of distress or injury.</p> </li> <li> <p>Alerting system: The model is able to alert supervisors or managers and/or emergency services when it identifies a range of potential hazards, including person slip &amp; fall, potential collision/accident, wet floor, debris on the floor, and wet/slippery signs.</p> </li> <li> <p>Customization: The model must be customizable to fit the needs of different users. This includes settings for sensitivity, activity recognition, and user-specific parameters such as age, weight, and height.</p> </li> </ul>"},{"location":"scenarios/fall-and-accident-detection/#training-with-custom-data","title":"Training with custom data","text":"<p>The scenario is provided as part of our GPL-v3 package for VisionAI. If you wish to train this with custom datasets, please contact us and we can provide you with the training code. You can do custom training with your own datasets for free, as long as it complies with GPLv3 license (you give back the code to the community). If you are interested in a custom license, please contact us.</p>"},{"location":"scenarios/fall-and-accident-detection/#contact-us","title":"Contact Us","text":"<ul> <li>For technical issues, you can open a Github issue here.</li> <li>For business inquiries, you can contact us through our website.</li> </ul>"},{"location":"scenarios/firearms-and-knives/","title":"Firearms And Knives Detection","text":"<p>New Technology aims to improve Firearm Detection and Save Lives with VisionAI.</p> <p> </p> Detection of firearms and knives event"},{"location":"scenarios/firearms-and-knives/#overview","title":"Overview","text":"<p>Firearms detection refers to the use of technology and methods to identify the presence of firearms in a particular location or setting. The goal of firearms detection is to prevent violence and ensure public safety by detecting and responding to the presence of firearms including knives, guns and other weapons.</p> <p>There are various methods and technologies used for firearms detection, including metal detectors, X-ray machines, and millimeter-wave scanners. All these solutions are invasive. </p> <p>With the advent in technology, our VisionAI solution for fire-arms detection is non-invasive in nature and it works by analyzing video footage to detect the presence of firearms or other weapons.</p>"},{"location":"scenarios/firearms-and-knives/#vision-ai-based-monitoring","title":"Vision AI based monitoring","text":"<p>Vision AI based monitors can be used to detect Firearms and knives events by providing real-time video feeds of the factory area. The cameras scan every frame to ensure there is no sign of firearms and knives.</p>"},{"location":"scenarios/firearms-and-knives/#events","title":"Events","text":"<p>VisionAI model's generated events would be:</p> <ul> <li>Person brandishing firearm</li> <li>Person brandishing knives</li> </ul>"},{"location":"scenarios/firearms-and-knives/#model-details","title":"Model Details","text":""},{"location":"scenarios/firearms-and-knives/#dataset","title":"Dataset","text":"<p>The dataset for this scenario is based on real-world firearms and knives events. The dataset consists of images and videos collected from various sources including UC Berkeley Anomaly Detection Dataset, UCF Crime Dataset etc.</p>"},{"location":"scenarios/firearms-and-knives/#model","title":"Model","text":"<p>The model is based off of the YOLOv5 algorithm. The model is trained on a custom dataset of images and videos. The model is trained based on the above dataset compiled by our team.</p>"},{"location":"scenarios/firearms-and-knives/#model-card","title":"Model card","text":"Dataset size Version Camera support Accuracy Recall F1 score 4230 v7 Ceiling 98.2 95.2 95 <p>The model is adaptable enough to run on any edge computing device.</p>"},{"location":"scenarios/firearms-and-knives/#scenario-details","title":"Scenario details","text":"<p>The business logic for this scenario is as follows:</p> <ul> <li>We use existing camera feeds from the premises to detect firearms and knives events.</li> <li>VisionAI system is able to run on edge devices. It uses camera feeds for processing.</li> <li>We detect people in the camera feed and we monitor whether the person is carrying any firearms and knives.</li> <li>If the person is detected with this event, an alert is raised.</li> </ul> Test now with online Web-CamWith RTSP Camera - PipelinesWith Azure Setup <p>To test this model &amp; scenario, you can use the following steps:</p> <ul> <li> <p>Install the visionai package from PyPI</p> <pre><code>$ pip install visionai\n</code></pre> </li> <li> <p>Test the scenario from your local web-cam</p> <pre><code>$ visionai scenario test firearms-knives-detection\n\nDownloading models for scenario: firearms-knives-detection\n\n\n\nStarting scenario: firearms-knives-detection..\n</code></pre> </li> <li> <p>You should be able to see the events generated on your console window with the detections of firearms and knives within the camera field of view.</p> </li> </ul> <p>[TODO]</p> <p>VisionAI app is available at a Azure Market place, one can download and use it by following steps mentioned here</p>"},{"location":"scenarios/firearms-and-knives/#features","title":"Features","text":"<p>The VisionAI solution is the most efficient way of implementing this scenario, as evidenced by the following features:</p> <ul> <li> <p>Unmatched accuracy</p> <p>Trained and Tested to give the best results. Our systems are trained to detect firearms and knives at the earliest detection with an accuracy of 99%</p> </li> <li> <p>Lightning Fast and Response Time</p> <p>Our Ultra-fast Processing provides real-time inference results and feedback (~30 frames per second processing). </p> </li> <li> <p>Minimizing false-positives/negatives</p> <p>Our systems create a fail-proof system by ensuring there are no false-positives or false-negatives. </p> </li> <li> <p>Scalability and Deployment </p> <p>Our pre-trained/custom models can be deployed instantly and are camera independent which means they can be pre-installed with existing cameras on site. We also offer cameras, IoT sensors and edge devices with strategic placement that helps scale a large workplace area with minimum installations. </p> </li> <li> <p>Custom Integrations</p> <p>Our detection system can be integrated with other safety systems, such as building management systems or alarm systems, allowing for a coordinated response to emergencies.</p> </li> </ul>"},{"location":"scenarios/firearms-and-knives/#training-with-custom-data","title":"Training with custom data","text":"<p>The scenario is provided as part of our GPL-v3 package for VisionAI. If you wish to train this with custom datasets, please contact us and we can provide you with the training code. You can do custom training with your own datasets for free, as long as it complies with GPLv3 license (you give back the code to the community). If you are interested in a custom license, please (contact us)[contact.md].</p>"},{"location":"scenarios/firearms-and-knives/#contact-us","title":"Contact Us","text":"<ul> <li>For technical issues, you can open a Github issue here.</li> <li>For business inquiries, you can contact us through our website.</li> </ul>"},{"location":"scenarios/forklift-safety/","title":"Forklift Safety &amp; Accident Prevention","text":"<p>Transform your forklift safety program with AI-powered monitoring that helps prevent accidents, ensures compliance, and provides data-driven insights for workplace safety improvements.</p> <p> </p> Real-time detection of forklift near-miss incidents"},{"location":"scenarios/forklift-safety/#the-cost-of-forklift-accidents","title":"The Cost of Forklift Accidents","text":"<p>Forklift incidents create significant impact on businesses:</p> <ul> <li>70 fatalities and 34,900 serious injuries annually from forklift accidents</li> <li>$135,000 average cost per forklift accident</li> <li>$38,000 in indirect costs per lost workday injury</li> <li>30% of forklift accidents involve pedestrians</li> </ul>"},{"location":"scenarios/forklift-safety/#important-safety-notice","title":"Important Safety Notice","text":"<p>VisionAI's forklift safety system is a passive monitoring solution designed to complement your existing safety protocols. While our system helps identify risks and prevent accidents, it should be used alongside traditional safety measures, training, and established protocols.</p>"},{"location":"scenarios/forklift-safety/#comprehensive-forklift-safety-monitoring","title":"Comprehensive Forklift Safety Monitoring","text":"<p>Our AI-powered system monitors:</p>"},{"location":"scenarios/forklift-safety/#1-near-miss-detection","title":"1. Near-Miss Detection","text":"<ul> <li>Forklift-pedestrian interactions</li> <li>Forklift-forklift interactions</li> <li>Real-time alert system</li> <li>Incident documentation</li> </ul>"},{"location":"scenarios/forklift-safety/#2-speed-compliance","title":"2. Speed &amp; Compliance","text":"<ul> <li>Speed limit monitoring</li> <li>Stop sign compliance</li> <li>Pathway adherence</li> <li>Seatbelt usage verification</li> </ul>"},{"location":"scenarios/forklift-safety/#3-traffic-management","title":"3. Traffic Management","text":"<ul> <li>Dedicated pathway monitoring</li> <li>Pedestrian zone violations</li> <li>High-traffic area analysis</li> <li>Intersection monitoring</li> </ul>"},{"location":"scenarios/forklift-safety/#4-data-analytics","title":"4. Data Analytics","text":"<ul> <li>Heat mapping of traffic patterns</li> <li>Risk zone identification</li> <li>Behavioral analysis</li> <li>Trend reporting</li> </ul>"},{"location":"scenarios/forklift-safety/#key-features-benefits","title":"Key Features &amp; Benefits","text":"<p>\u2713 Accident Prevention - Early warning system - Near-miss detection - Behavioral monitoring - Risk area identification</p> <p>\u2713 Compliance Support - OSHA compliance documentation - Automated incident reporting - Training verification - Safety audit support</p> <p>\u2713 Operational Efficiency - Traffic flow optimization - Resource utilization insights - Maintenance scheduling - Performance metrics</p> <p>\u2713 Cost Reduction - Reduced accident rates - Lower insurance premiums - Decreased downtime - Minimized damage costs</p>"},{"location":"scenarios/forklift-safety/#industry-applications","title":"Industry Applications","text":""},{"location":"scenarios/forklift-safety/#manufacturing","title":"Manufacturing","text":"<ul> <li>Production floor monitoring</li> <li>Loading dock safety</li> <li>Material handling areas</li> <li>Storage zones</li> </ul>"},{"location":"scenarios/forklift-safety/#warehousing-distribution","title":"Warehousing &amp; Distribution","text":"<ul> <li>High-traffic aisles</li> <li>Loading/unloading zones</li> <li>Cross-dock operations</li> <li>Storage areas</li> </ul>"},{"location":"scenarios/forklift-safety/#logistics-centers","title":"Logistics Centers","text":"<ul> <li>Shipping/receiving areas</li> <li>Cross-traffic zones</li> <li>Staging areas</li> <li>Pedestrian walkways</li> </ul>"},{"location":"scenarios/forklift-safety/#success-story","title":"Success Story","text":"<p>\"After implementing VisionAI's forklift safety system, we've seen a 65% reduction in near-miss incidents and completely eliminated serious forklift accidents. The data insights have helped us optimize our facility layout and improve overall safety culture.\" </p> <p>- Safety Director, Major Distribution Center</p>"},{"location":"scenarios/forklift-safety/#implementation-process","title":"Implementation Process","text":"<ol> <li>Assessment</li> <li>Facility layout review</li> <li>Traffic pattern analysis</li> <li>Risk zone identification</li> <li> <p>Custom alert configuration</p> </li> <li> <p>Deployment</p> </li> <li>Camera placement optimization</li> <li>System integration</li> <li>Alert system setup</li> <li> <p>Team training</p> </li> <li> <p>Ongoing Support</p> </li> <li>24/7 monitoring capability</li> <li>Regular performance reviews</li> <li>System optimization</li> <li>Compliance documentation</li> </ol>"},{"location":"scenarios/forklift-safety/#supported-safety-events","title":"Supported Safety Events","text":"<p>Visionify's Forklift Safety suite detects near-misses between forklifts &amp; people, forklift-speed limit, and dedicated pathways for forklifts &amp; people. This scenario is useful for areas where forklifts are operated.</p> <p>Forklift Safety also implements other best practices like Wearning Seatbelts, Stop sign compliance etc.</p> <p>Our forklift safety suite can be considered as a passive safety system. It does not actively prevent any accidents, but it does help you identify areas that need attention. The goal of the Forklift Safety Suite is to make your team aware of the risks, so you can data driven changes to make your workplace safer.</p> <p> </p> Forklift Safety Violation Example Event <p>Table: Forklift Safety Events and Detection Details</p> Scenario name Supported? Event Event Details Forklift Safety \u2705 <code>Forklift Person interaction</code> Forklift Person Near-Miss \u2705 <code>Forklift Forklift interaction</code> Forklift Forklift Near-Miss \u2705 <code>Forklift Speed Limit</code> Forklift Speed Limit Violation \u2705 <code>Forklift Stop Sign Compliance</code> Forklift Stop Sign Compliance Violation \u2705 <code>Dedicated Forklift Pathway</code> Forklift outside of dedicated pathway \u2705 <code>Person in Forklift Pathway</code> Person in Forklift Pathway \ud83d\udcc5 <code>Forklift Max-height Violation</code> Forklift Max-height Violation \ud83d\udcc5 <code>Forklift with Pins Up</code> Forklift with Pins Up \u2705 <code>Forklift and People Heatmap</code> Forklift and People Heatmap"},{"location":"scenarios/forklift-safety/#learn-more","title":"Learn More","text":"<ul> <li>Quick Start</li> <li>Camera Placement Guide</li> <li>Supported Scenarios</li> <li>Camera Management</li> <li>FAQs</li> </ul>"},{"location":"scenarios/forklift-safety/#contact-information","title":"Contact Information","text":"contact_phone Sales Inquiries <p>Get in touch with our sales team for demos and pricing information.</p> <ul> <li>Email: sales@visionify.ai</li> <li>Phone: +1 720-449-1124</li> </ul> support_agent Technical Support <p>Need help? Visit our support portal or contact our technical team.</p> <ul> <li>https://support.visionify.ai</li> <li>support@visionify.ai</li> </ul> calendar_month Schedule a Demo <p>See VisionAI in action with a personalized demo from our team.</p> event                 Book Your Demo"},{"location":"scenarios/hand-wash/","title":"Hand Wash","text":"<p>Enhance hygiene compliance with our cutting-edge hand wash detection model, designed to accurately monitor and promote effective hand washing practices.</p> <p> </p> Detection of hand-wash"},{"location":"scenarios/hand-wash/#overview","title":"Overview","text":"<p>Hand hygiene is critical to preventing the spread of infectious diseases. However, ensuring that individuals properly wash their hands at appropriate times can be challenging, particularly in high-traffic areas. </p> <p>A hand wash detection model can help address this challenge by automatically detecting and monitoring hand washing behaviors, providing real-time feedback and alerts to individuals who may need to improve their hygiene practices. This can enhance overall hygiene compliance, reduce the spread of germs and diseases, and promote a safer and healthier environment for all.</p>"},{"location":"scenarios/hand-wash/#vision-ai-based-monitoring","title":"Vision AI based monitoring","text":"<p>Vision AI-based hand-wash system is designed to detect and ensure no one misses hand wash. The system uses image processing and machine learning algorithms to analyze the hand region in images or videos and detect hand wash based on specific features.</p> <p>Overall, the hand wash detection model is an important tool for promoting hygiene and preventing the spread of disease in a range of environments, from hospitals and schools to offices and public spaces. By detecting whether people have used hand wash, the system can help encourage good hygiene practices and reduce the risk of infection.</p>"},{"location":"scenarios/hand-wash/#model-details","title":"Model Details","text":""},{"location":"scenarios/hand-wash/#dataset","title":"Dataset","text":"<p>The dataset consists of images and videos collected from various sources. </p>"},{"location":"scenarios/hand-wash/#model-card","title":"Model card","text":"Dataset size Version Camera support Precision Recall  mAP   7326 v5 Straight 79% 84% 76%"},{"location":"scenarios/hand-wash/#scenario-details","title":"Scenario details","text":"<p>The business logic for this scenario is as follows: </p> <ul> <li> <p>We use existing camera feeds from the premises to monitor and detect the instances of missing hand wash.</p> </li> <li> <p>VisionAI system is able to run on edge devices. It uses camera feeds for processing. </p> </li> <li> <p>An alarming system is in place as part of an hand wash detection solution. </p> </li> </ul> Test now with online Web-CamWith RTSP Camera - PipelinesWith Azure Setup <p>To test this model &amp; scenario, you can use the following steps:</p> <ul> <li> <p>Install the visionai package from PyPI</p> <pre><code>$ pip install visionai\n</code></pre> </li> <li> <p>Test the scenario from your local web-cam</p> <pre><code>$ visionai scenario test hand-wash-detection\n\nDownloading models for scenario: hand-wash-detection\nModel: hand-wash-detection: https://workplaceos.blob.core.windows.net/models/yolov5s-hand-wash-detection/yolov5s-hand-wash-detection-0.0.4.zip\n\n\nStarting scenario: hand-wash-detection..\n</code></pre> </li> <li> <p>You should be able to see the information generated on your console window with the detections of missing hand-wash event within the camera field of view.</p> </li> </ul> <p>[TODO]</p> <p>VisionAI app is available at a Azure Market place, one can download and use it by following steps mentioned here</p>"},{"location":"scenarios/hand-wash/#features","title":"Features","text":"<ul> <li> <p>Hand region detection: The system should be able to accurately detect the hand region in an image or video, which can be done using skin color segmentation or hand detection algorithms.</p> </li> <li> <p>Real-time performance: The system should be able to operate in real-time, analyzing images or videos quickly and accurately to detect whether a person has missed hand wash or not.</p> </li> <li> <p>Robustness: The system should be able to perform well under varying conditions, such as different lighting conditions, hand positions, or hand appearances due to age, skin color, or skin conditions.</p> </li> </ul>"},{"location":"scenarios/hand-wash/#training-with-custom-data","title":"Training with custom data","text":"<p>The scenario is provided as part of our GPL-v3 package for VisionAI. If you wish to train this with custom datasets, please contact us and we can provide you with the training code. You can do custom training with your own datasets for free, as long as it complies with GPLv3 license (you give back the code to the community). If you are interested in a custom license, please contact us.</p>"},{"location":"scenarios/hand-wash/#contact-us","title":"Contact Us","text":"<ul> <li>For technical issues, you can open a Github issue here.</li> <li>For business inquiries, you can contact us through our website.</li> </ul>"},{"location":"scenarios/hazard-warning-housekeeping/","title":"Workplace Hazard Detection &amp; Housekeeping Analytics","text":"<p>Transform your facility safety program with AI-powered hazard detection that helps prevent accidents, maintains workplace standards, and ensures OSHA compliance through automated monitoring.</p> <p> </p> Real-time detection of workplace hazards and spills"},{"location":"scenarios/hazard-warning-housekeeping/#the-cost-of-poor-housekeeping","title":"The Cost of Poor Housekeeping","text":"<p>Workplace hazards and poor housekeeping lead to:</p> <ul> <li>95,000 workplace injuries annually due to poor housekeeping</li> <li>$450M yearly costs from slip and fall accidents</li> <li>30% of workplace accidents linked to poor housekeeping</li> <li>40% increase in insurance premiums due to poor safety records</li> </ul>"},{"location":"scenarios/hazard-warning-housekeeping/#comprehensive-hazard-monitoring","title":"Comprehensive Hazard Monitoring","text":"![Oil Leak](https://visionai.azureedge.net/docs-images/docs-visionify-version1.0-23March23/oil-leakage.png){ width=\"300\" }       Oil leak detection        ![Water Leak](https://visionai.azureedge.net/docs-images/docs-visionify-version1.0-23March23/Water-Leak.png){ width=\"300\" }       Water leak monitoring"},{"location":"scenarios/hazard-warning-housekeeping/#1-spills-leaks-detection","title":"1. Spills &amp; Leaks Detection","text":"<ul> <li>Immediate spill identification</li> <li>Liquid leak monitoring</li> <li>Slippery surface detection</li> <li>Quick response activation</li> </ul>"},{"location":"scenarios/hazard-warning-housekeeping/#2-pathway-monitoring","title":"2. Pathway Monitoring","text":"<ul> <li>Exit blockage detection</li> <li>Clean pathway verification</li> <li>Unattended object detection</li> <li>Traffic flow optimization</li> </ul>"},{"location":"scenarios/hazard-warning-housekeeping/#3-safety-equipment-monitoring","title":"3. Safety Equipment Monitoring","text":"<ul> <li>Fire extinguisher presence</li> <li>Emergency exit accessibility</li> <li>Safety signage verification</li> <li>Door status monitoring</li> </ul>"},{"location":"scenarios/hazard-warning-housekeeping/#4-workplace-organization","title":"4. Workplace Organization","text":"<ul> <li>Pallet placement monitoring</li> <li>Box and container tracking</li> <li>Equipment positioning</li> <li>Storage area compliance</li> </ul>"},{"location":"scenarios/hazard-warning-housekeeping/#business-benefits","title":"Business Benefits","text":"<p>\u2713 Accident Prevention - Early hazard detection - Proactive maintenance alerts - Slip and fall prevention - Emergency exit compliance</p> <p>\u2713 Cost Reduction - Lower insurance premiums - Reduced cleanup costs - Minimized downtime - Decreased liability exposure</p> <p>\u2713 Compliance Management - OSHA standard adherence - Automated documentation - Audit trail maintenance - Regular compliance reports</p> <p>\u2713 Operational Efficiency - Streamlined inspections - Automated monitoring - Quick incident response - Resource optimization</p>"},{"location":"scenarios/hazard-warning-housekeeping/#success-story","title":"Success Story","text":"<p>\"VisionAI's hazard detection system helped us reduce workplace incidents by 45% and improve our safety audit scores by 60%. The automated monitoring has transformed our housekeeping program.\" </p> <p>- EHS Director, Global Manufacturing Facility</p>"},{"location":"scenarios/hazard-warning-housekeeping/#key-features","title":"Key Features","text":"Feature Detection Capability Business Impact Spills &amp; Leaks Real-time liquid detection Prevent slip and fall accidents Blocked Exits Exit pathway monitoring Ensure emergency preparedness Unattended Objects Object detection in pathways Maintain workplace organization Missing Safety Equipment Fire extinguisher monitoring Ensure safety compliance Door Monitoring Open/close status tracking Improve security and climate control Clean Pathway Obstruction detection Maintain efficient operations"},{"location":"scenarios/hazard-warning-housekeeping/#implementation-process","title":"Implementation Process","text":"<ol> <li>Facility Assessment</li> <li>Risk area identification</li> <li>Camera placement planning</li> <li>Custom alert configuration</li> <li> <p>Integration planning</p> </li> <li> <p>Quick Deployment</p> </li> <li>Non-disruptive installation</li> <li>System configuration</li> <li>Team training</li> <li> <p>Alert setup</p> </li> <li> <p>Ongoing Support</p> </li> <li>24/7 monitoring capability</li> <li>Regular performance reviews</li> <li>System optimization</li> <li>Compliance reporting</li> </ol>"},{"location":"scenarios/hazard-warning-housekeeping/#learn-more","title":"Learn More","text":"<ul> <li>Quick Start</li> <li>Camera Placement Guide</li> <li>Supported Scenarios</li> <li>Camera Management</li> <li>FAQs</li> </ul>"},{"location":"scenarios/hazard-warning-housekeeping/#contact-information","title":"Contact Information","text":"contact_phone Sales Inquiries <p>Get in touch with our sales team for demos and pricing information.</p> <ul> <li>Email: sales@visionify.ai</li> <li>Phone: +1 720-449-1124</li> </ul> support_agent Technical Support <p>Need help? Visit our support portal or contact our technical team.</p> <ul> <li>https://support.visionify.ai</li> <li>support@visionify.ai</li> </ul> calendar_month Schedule a Demo <p>See VisionAI in action with a personalized demo from our team.</p> event                 Book Your Demo"},{"location":"scenarios/hazard-warning-suite/","title":"Hazard warning Suite","text":"<p>A \"hazard warning suite\" could refer to a set of scenarios that are designed to monitor, detect, and alert individuals or systems of potential hazards in a given environment. The suite could include various types of sensors and technologies, such as cameras, microphones, and environmental sensors, that can detect hazards like fires, toxic gas leaks, chemical spills, and other potential threats.</p> <p>The suite also include artificial intelligence techniques that can analyze sensor data and detect patterns or anomalies that could indicate the presence of a hazard. Once a hazard is detected, the suite could automatically trigger alarms, notifications, or alerts to relevant personnel, emergency services, or other systems to take appropriate action.</p> <p>In addition to real-time hazard detection and alerts, a hazard warning suite also include provisions for post-event analysis and reporting. This could help organizations identify patterns of hazards and develop strategies to prevent or mitigate future incidents.</p> <p>Overall, a hazard warning suite can be an important tool for ensuring the safety of workers, visitors, and the environment in a variety of settings, such as factories, warehouses, research facilities, and other high-risk environments.</p> <ul> <li>Smoke and Fire Detection</li> <li>No smoking/no vaping</li> <li>Spills &amp; leaks detection</li> <li>Missing fire extinguisher</li> <li>Blocked exit monitoring</li> <li>Equipment rust and corrosion</li> </ul>"},{"location":"scenarios/hazard-warning-suite/#learn-more","title":"Learn More","text":"<ul> <li>Quick Start</li> <li>Camera Placement Guide</li> <li>Supported Scenarios</li> <li>Camera Management</li> <li>FAQs</li> </ul>"},{"location":"scenarios/hazard-warning-suite/#contact-information","title":"Contact Information","text":"contact_phone Sales Inquiries <p>Get in touch with our sales team for demos and pricing information.</p> <ul> <li>Email: sales@visionify.ai</li> <li>Phone: +1 720-449-1124</li> </ul> support_agent Technical Support <p>Need help? Visit our support portal or contact our technical team.</p> <ul> <li>https://support.visionify.ai</li> <li>support@visionify.ai</li> </ul> calendar_month Schedule a Demo <p>See VisionAI in action with a personalized demo from our team.</p> event                 Book Your Demo"},{"location":"scenarios/housekeeping/","title":"Housekeeping","text":""},{"location":"scenarios/housekeeping/#housekeeping","title":"Housekeeping","text":"<p>Visionify's Housekeeping Suite provides various hazard identifications on the work floor. These metrics include identifying spills and leaks on the floor, unattended objects, boxes or pallets on the floor, identifying door open/close events, blocked exits monitoring, missing fire-extinguishers etc. </p> <p>Housekeeping suite provides organization a second set of eyes for their regular audits. By identifying hazards early, this suite tends to avoid accidents and injuries.</p> <p> </p> Spills and Leaks Detection Sample Event <p>Table: Housekeeping Events and Detection Details</p> Scenario name Supported? Event Event Details More Info Housekeeping \u2705 <code>Spills &amp; Leaks</code> Spills and Leaks More details \u2705 <code>Unattended Objects</code> Unattended Objects \u2705 <code>Unattended Pallet/Box</code> Unattended Pallet/Box \u2705 <code>Clean Pathway</code> Clean Pathway \u2705 <code>Blocked Exits</code> Blocked Exits \u2705 <code>Missing Fire Extinguisher</code> Missing Fire Extinguisher Event \u2705 <code>Door Open/Close</code> Door Open/Close Event"},{"location":"scenarios/housekeeping/#learn-more","title":"Learn More","text":"<ul> <li>Quick Start</li> <li>Camera Placement Guide</li> <li>Supported Scenarios</li> <li>Camera Management</li> <li>FAQs</li> </ul>"},{"location":"scenarios/housekeeping/#contact-information","title":"Contact Information","text":"contact_phone Sales Inquiries <p>Get in touch with our sales team for demos and pricing information.</p> <ul> <li>Email: sales@visionify.ai</li> <li>Phone: +1 720-449-1124</li> </ul> support_agent Technical Support <p>Need help? Visit our support portal or contact our technical team.</p> <ul> <li>https://support.visionify.ai</li> <li>support@visionify.ai</li> </ul> calendar_month Schedule a Demo <p>See VisionAI in action with a personalized demo from our team.</p> event                 Book Your Demo"},{"location":"scenarios/intrusion-detection/","title":"Intrusion Detection","text":"<p>An advanced physical intrusion detection system powered with Computer Vision and AI.</p>"},{"location":"scenarios/intrusion-detection/#overview","title":"Overview","text":"<p>Intrusion detection is a system to monitor suspicious activities indicating an intrusion. Intrusion detection is important to detect and prevent unauthorized access to the facility, production area and other restricted areas within a building or manufacturing setup. An intrusion detection system helps prevent theft and vandalism, protecting the facility from malicious activities that can disrupt production, damage equipment, and compromise sensitive information. In addition, an effective intrusion detection system helps to ensure compliance with regulations and standards related to security and safety in the industry.</p> <p>The current physical intrusion detection systems have a limited detection range and a number of other problems.  Existing solutions: - Do not provide comprehensive coverage across a large sprawling area. - Can be affected by environmental factors in the outdoors and raise false alarms. - Are vulnerable to tampering. - Do not offer much flexibility in terms of getting integrated well with other security measures like video surveillance not cost-effective. </p>"},{"location":"scenarios/intrusion-detection/#vision-ai-based-monitoring","title":"Vision AI based monitoring","text":"<p>Expand your security capabilities with VisionAI, a modern AI and ML solution to detect intrusions and protect your premises against all potential physical intrusion threats. Our model can accurately identify suspicious behaviors that may indicate a physical intrusion and instantly alerts the security personnel, allowing them to take appropriate and timely action against it to avoid associated dangers.</p> <p>Our smart solution seamlessly integrates with the existing camera infrastructure and analyzes the real-time video feed. It can help in different ways, offers a comprehensive solution to detect all forms of physical intrusion, and ensures compliance with all security and safety regulations.</p>"},{"location":"scenarios/intrusion-detection/#model-details","title":"Model Details","text":""},{"location":"scenarios/intrusion-detection/#dataset","title":"Dataset","text":"<p>The dataset consists of high-quality images and videos collected from diverse sources and is designed to reflect real-world scenarios. The dataset is representative of all types of environments that should be taken care of while detecting physical intrusion.  </p> <ul> <li> <p>Different locations/environments \u2013 The dataset includes images/videos from a variety of indoor and outdoor environments, locations, weather conditions and building layouts.</p> </li> <li> <p>Diversity of intruders \u2013 The dataset considers images and videos of intruders from different backgrounds trying to intrude in various poses such as standing, walking, running, crawling etc. </p> </li> <li> <p>Balanced - The dataset is evenly distributed and balanced between intrusion and non-intrusion examples to prevent bias towards one class of data.</p> </li> <li> <p>Different angles and perspectives - The dataset includes images and videos captured from different angles and lighting conditions to ensure the model can detect intrusion in various real-world scenarios.</p> </li> </ul>"},{"location":"scenarios/intrusion-detection/#model-card","title":"Model card","text":"Dataset size Version Camera support Precision Recall  mAP   2326 v5 Ceiling 65%  71%  71%"},{"location":"scenarios/intrusion-detection/#scenario-details","title":"Scenario details","text":"<p>Our VisionAI solution for intrusion detection can be deployed to a physical perimeter integrated with the existing camera infrastructure and works in different scenarios to detect physical intrusion. The model is equipped to detect the following;</p> <ul> <li>Any person with suspicious behavior</li> <li>Anybody trying to intrude in a building or perimeter</li> <li>Anybody trying to trespass a restricted area without permission</li> <li>Anybody loitering around a restricted area for an extended period </li> </ul> Test now with online Web-CamWith RTSP Camera - PipelinesWith Azure Setup <p>To test this model &amp; scenario, you can use the following steps:</p> <ul> <li> <p>Install the visionai package from PyPI</p> <pre><code>$ pip install visionai\n</code></pre> </li> <li> <p>Test the scenario from your local web-cam</p> <pre><code>$ visionai scenario test intrusion-detection\n\nDownloading models for scenario: intrusion-detection\nModel: intrusion-detection: https://workplaceos.blob.core.windows.net/models/yolov5s-intrusion-detection/yolov5s-intrusion-detection-0.0.1.zip\n\n\nStarting scenario: intrusion-detection..\n</code></pre> </li> <li> <p>You should be able to see the events generated on your console window with detection of intrusions within the camera field of view.</p> </li> </ul> <p>[TODO]</p> <p>VisionAI app is available at a Azure Market place, one can download and use it by following steps mentioned here</p>"},{"location":"scenarios/intrusion-detection/#features","title":"Features","text":"<ul> <li> <p>Real-time monitoring: The model can be deployed to a physical perimeter integrated with the existing camera infrastructure and works in real-time to detect physical intrusion.</p> </li> <li> <p>Comprehensive coverage: The model can detect intrusion in a variety of environments, locations, weather conditions and building layouts.</p> </li> <li> <p>Customizable: The model can be customized to detect intrusion in a specific area or location based on user requirements.</p> </li> </ul> <p>-Integration: The model can be integrated with other security measures like video surveillance to provide a comprehensive solution to detect all forms of physical intrusion.</p> <ul> <li>Alert system: The solution has an alert system to notify the security personnel in case of an intrusion.</li> </ul>"},{"location":"scenarios/intrusion-detection/#training-with-custom-data","title":"Training with custom data","text":"<p>The scenario is provided as part of our GPL-v3 package for VisionAI. If you wish to train this with custom datasets, please contact us and we can provide you with the training code. You can do custom training with your own datasets for free, as long as it complies with GPLv3 license (you give back the code to the community). If you are interested in a custom license, please contact us.</p>"},{"location":"scenarios/intrusion-detection/#learn-more","title":"Learn More","text":"<ul> <li>Quick Start</li> <li>Camera Placement Guide</li> <li>Supported Scenarios</li> <li>Camera Management</li> <li>FAQs</li> </ul>"},{"location":"scenarios/intrusion-detection/#contact-information","title":"Contact Information","text":"contact_phone Sales Inquiries <p>Get in touch with our sales team for demos and pricing information.</p> <ul> <li>Email: sales@visionify.ai</li> <li>Phone: +1 720-449-1124</li> </ul> support_agent Technical Support <p>Need help? Visit our support portal or contact our technical team.</p> <ul> <li>https://support.visionify.ai</li> <li>support@visionify.ai</li> </ul> calendar_month Schedule a Demo <p>See VisionAI in action with a personalized demo from our team.</p> event                 Book Your Demo"},{"location":"scenarios/loitering/","title":"Loitering Detection","text":"<p>Keeping Public Spaces Safe: Innovations in Loitering Detection and Prevention with Vision AI.</p> <p> </p> Loitering detection event"},{"location":"scenarios/loitering/#overview","title":"Overview","text":"<p>Loitering detection refers to the use of technology to identify and monitor individuals who are loitering in public spaces, with the aim of preventing crime, reducing security risks, and maintaining public safety. Loitering is typically defined as lingering or remaining in a particular location for an extended period of time, without a legitimate reason to be there.</p> <p>Loitering detection technologies may include sensors, cameras, and other monitoring systems that can detect and track individuals in public spaces. Some of these technologies can be integrated with machine learning and artificial intelligence (AI) algorithms to analyze data and identify patterns of behavior that may be indicative of loitering.</p> <p>Loitering detection technologies can be used in a variety of settings, including transportation hubs, shopping centers, and other public areas where large groups of people may congregate. These technologies can help identify potential security threats, such as individuals who may be carrying weapons or engaging in suspicious activities.</p> <p>However, there are also concerns about privacy and civil liberties when it comes to the use of loitering detection technologies. Critics argue that these technologies can be used to target marginalized communities, and may contribute to a climate of suspicion and discrimination.</p> <p>Overall, the use of loitering detection technologies is a complex issue that requires careful consideration of both security and privacy concerns. While these technologies can play an important role in maintaining public safety, it is important to ensure that their use is balanced with respect for individual rights and freedoms.</p>"},{"location":"scenarios/loitering/#vision-ai-based-monitoring","title":"Vision AI based monitoring","text":"<p>Vision AI based monitors can be used to for the detection of loitering events by providing real-time video feeds of the factory area. The cameras scan every frame and raise an event when a person enters from an usually closed location, person detected during off-hours, person detected for extended duration of time.</p>"},{"location":"scenarios/loitering/#model-details","title":"Model Details","text":""},{"location":"scenarios/loitering/#dataset","title":"Dataset","text":"<p>The dataset for this scenario is based on real-world loitering detection events. The dataset consists of images and videos collected from various sources. </p>"},{"location":"scenarios/loitering/#model-card","title":"Model card","text":"Dataset size Version Camera support Precision Recall  mAP   8280 v1 Both(Ceiling and Straight) 85.0%  81.7%  79.0%"},{"location":"scenarios/loitering/#scenario-details","title":"Scenario details","text":"<p>The business logic for this scenario is as follows:</p> <ul> <li>We use existing camera feeds from the premises for raising loitering events.</li> <li>VisionAI system is able to run on edge devices. It uses camera feeds for processing.</li> <li>From the camera feed we monitor if a person enters from an usually closed location, person detected during off-hours, person detected for extended duration of time.</li> <li>If loitering event is detected, an alert is raised.</li> </ul> Test now with online Web-CamWith RTSP Camera - PipelinesWith Azure Setup <p>To test this model &amp; scenario, you can use the following steps:</p> <ul> <li> <p>Install the visionai package from PyPI</p> <pre><code>$ pip install visionai\n</code></pre> </li> <li> <p>Test the scenario from your local web-cam</p> <pre><code>$ visionai scenario test loitering-detection\n\nDownloading models for scenario: loitering-detection\n\n\nStarting scenario: loitering-detection..\n</code></pre> </li> <li> <p>You should be able to see the events generated on your console window with the detections of loitering within the camera field of view.</p> </li> </ul> <p>[TODO]</p> <p>VisionAI app is available at a Azure Market place, one can download and use it by following steps mentioned here</p>"},{"location":"scenarios/loitering/#features","title":"Features","text":"<p>The VisionAI solution is the most efficient way of implementing this scenario, as evidenced by the following features:</p> <ul> <li> <p>Customization: Our systems are customizable to fit your needs. We can train our models with your own data and provide you with a custom solution. We also provide a custom license for our software if you wish to use it in a closed environment.</p> </li> <li> <p>Unmatched accuracy: Trained and Tested to give the best results. Our systems are trained to detect loitering events with an accuracy of 99%</p> </li> <li> <p>Lightning Fast and Response Time: Our Ultra-fast Processing provides real-time inference results and feedback (~30 frames per second processing). </p> </li> <li> <p>Scalability and Deployment: Our pre-trained/custom models can be deployed instantly and are camera independent which means they can be pre-installed with existing cameras on site. We also offer cameras, IoT sensors and edge devices with strategic placement that helps scale a large workplace area with minimum installations. </p> </li> </ul>"},{"location":"scenarios/loitering/#training-with-custom-data","title":"Training with custom data","text":"<p>The scenario is provided as part of our GPL-v3 package for VisionAI. If you wish to train this with custom datasets, please contact us and we can provide you with the training code. You can do custom training with your own datasets for free, as long as it complies with GPLv3 license (you give back the code to the community). If you are interested in a custom license, please contact us.</p>"},{"location":"scenarios/loitering/#contact-us","title":"Contact Us","text":"<ul> <li>For technical issues, you can open a Github issue here.</li> <li>For business inquiries, you can contact us through our website.</li> </ul>"},{"location":"scenarios/max-occupancy-count/","title":"Maximum Occupancy","text":"<p>Transform the way you manage occupancy in real-time with our cutting-edge Computer Vision Occupancy Monitoring Solution.</p> <p> </p> Maximum Occupancy monitoring event"},{"location":"scenarios/max-occupancy-count/#overview","title":"Overview","text":"<p>Effective crowd management is critical for many workplaces like airports, hospitals, factories, and retail shops, among others. One key aspect is maintaining compliance with maximum occupancy limits which is  crucial for maintaining safety, mitigating potential injuries, and legal issues. </p> <p>Existing solutions for tracking maximum occupancy typically rely on manual monitoring, which can be labor-intensive, prone to errors, and time-consuming while other systems such as sensors and RFID (Radio-Frequency Identification) tags produce a lot of false readings, have limited range and incur significant expenses.</p> <p>As such, there is a need for more efficient and reliable methods for monitoring and managing maximum occupancy. A promising solution lies in the use of computer vision technology, which can accurately detect and track individuals in real-time, providing an automated and seamless approach to crowd management.</p>"},{"location":"scenarios/max-occupancy-count/#vision-ai-based-monitoring","title":"Vision AI based monitoring","text":"<p>Maintain workplace occupancy limits flawlessly by leveraging computer vision-powered occupancy monitoring. Monitor Occupancy levels in Real-Time, get instant alerts and warnings whenever count exceeds threshold limit. With our ready-to-deploy models, businesses can effortlessly adhere to regulations and maintain a safe environment without the need for manual monitoring or complex sensor installations. </p> <p>A single camera can cover a wide area, allowing businesses to leverage our AI-based technology with minimal effort. You can easily augment your existing infrastructure and get started with our models with just a few clicks.</p> <p> </p> monitoring maximum occupancy"},{"location":"scenarios/max-occupancy-count/#events","title":"Events","text":"<p>VisionAI model's generated events would be:</p> <ul> <li>Person count exceeds limit (Max occupancy exceeded)</li> <li>Person count is below limit (Max occupancy not exceeded)</li> </ul>"},{"location":"scenarios/max-occupancy-count/#event-data","title":"Event Data","text":"<p>An event data for maximum occupancy scenario may include information such as:</p> <ul> <li>Date and time of the event</li> <li>Location of the event</li> <li>type of event (Max occupancy exceeded, etc.)</li> <li>Image of the event</li> </ul>"},{"location":"scenarios/max-occupancy-count/#model-details","title":"Model Details","text":""},{"location":"scenarios/max-occupancy-count/#dataset","title":"Dataset","text":"<p>The dataset consists of images and videos of people in different scenarios.    </p>"},{"location":"scenarios/max-occupancy-count/#model-card","title":"Model card","text":"Dataset size Version Camera support Precision Recall  mAP   2470 v1 Both(Ceiling and Straight) 85.0%  78.6%  71.0%"},{"location":"scenarios/max-occupancy-count/#scenario-details","title":"Scenario details","text":"<p>Real-time detection and alerts for different scenarios includes but are not limited to:</p> <ul> <li>When person count exceeds the predefined limit</li> <li>When the threshold is about to be reached as a safety warning</li> <li>Warnings based on population flow</li> </ul> Test now with online Web-CamWith RTSP Camera - PipelinesWith Azure Setup <p>To test this model &amp; scenario, you can use the following steps:</p> <ul> <li> <p>Install the visionai package from PyPI</p> <pre><code>$ pip install visionai\n</code></pre> </li> <li> <p>Test the scenario from your local web-cam</p> <pre><code>$ visionai scenario test max-occupancy\n</code></pre> <p>Downloading models for scenario: max-occupancy Model: max-occupancy: https://workplaceos.blob.core.windows.net/models/yolov5s-people/yolov5s-people-0.0.4.zip</p> <p>Starting scenario: max-occupancy..</p> <p>```</p> </li> <li> <p>You should be able to see the events generated on your console window with the detections of maximum occupancy event within the camera field of view.</p> </li> </ul> <p>[TODO]</p> <p>VisionAI app is available at a Azure Market place, one can download and use it by following steps mentioned here</p>"},{"location":"scenarios/max-occupancy-count/#features","title":"Features","text":"<p>Some potential features of VisionAI for monitoring maximum occupancy include:</p> <ul> <li> <p>Real-time monitoring of maximum occupancy: VisionAI can monitor maximum occupancy in real-time, providing an automated and seamless approach to crowd management.</p> </li> <li> <p>Instant alerts and warnings: VisionAI can send instant alerts and warnings whenever count exceeds threshold limit.</p> </li> <li> <p>Easy to deploy: VisionAI can be easily deployed with minimal effort, allowing businesses to leverage our AI-based technology with minimal effort.</p> </li> </ul>"},{"location":"scenarios/max-occupancy-count/#training-with-custom-data","title":"Training with custom data","text":"<p>The scenario is provided as part of our GPL-v3 package for VisionAI. If you wish to train this with custom datasets, please contact us and we can provide you with the training code. You can do custom training with your own datasets for free, as long as it complies with GPLv3 license (you give back the code to the community). If you are interested in a custom license, please contact us.</p>"},{"location":"scenarios/max-occupancy-count/#contact-us","title":"Contact Us","text":"<ul> <li>For technical issues, you can open a Github issue here.</li> <li>For business inquiries, you can contact us through our website.</li> </ul>"},{"location":"scenarios/missing-fire-extinguisher/","title":"Missing Fire Extinguisher","text":"<p>Strengthen your smoke &amp; fire detection compliance - through adding custom logic for checking for missing fire extinguisher from required places.</p> <p> </p> MMissing Fire extinguisher"},{"location":"scenarios/missing-fire-extinguisher/#overview","title":"Overview","text":"<p>Fire Extinguishers prove to be a crucial preventive measure against unexpected fires. These are essential components of safety features that can help contain early fires before they escalate into large ones. Adequately installed fire extinguishers in the building offer round-the-clock protection against unexpected fires, and a majority of fires can be put out using handy fire extinguishers.</p> <p>However, if a fire breaks out, missing fire extinguishers can increase the risk of injury and damage and can also have legal and regulatory obligations. Failure to comply with regulations can incur fines or legal issues. It also raises a question about the business\u2019s reputation and leads to a loss of trust from customers. The existing fire warning and safety systems also cannot identify early fire signs, and none of them offer detection of missing fire extinguishers.</p>"},{"location":"scenarios/missing-fire-extinguisher/#vision-ai-based-monitoring","title":"Vision AI based monitoring","text":"<p>Make your workplace safer with our VisionAI monitoring, a computer vision and deep learning-based solution that helps you detect missing fire extinguishers by analyzing visual data, making it easier for businesses to ensure that they have the necessary safety equipment in place.</p> <p>Our fully automated system guards your facility 24/7. It sends instant alerts whenever a missing fire extinguisher is detected, allowing businesses to achieve improved fire safety, compliance with regulations, cost savings, and peace of mind. </p>"},{"location":"scenarios/missing-fire-extinguisher/#events","title":"Events","text":"<p>VisionAI model's generated events would be:</p> <ul> <li>Missing fire extinguisher</li> </ul> <p>It is recommended that any instance of a missing fire extinguisher be reported to the appropriate authority. An event data for a missing fire extinguisher may include information such as:</p> <ul> <li>Date and time the missing fire extinguisher was discovered</li> <li>Location of the missing fire extinguisher, including the building, floor, and room number</li> <li>Type of fire extinguisher that is missing</li> </ul>"},{"location":"scenarios/missing-fire-extinguisher/#model-details","title":"Model Details","text":""},{"location":"scenarios/missing-fire-extinguisher/#dataset","title":"Dataset","text":"<p>The dataset consists of images and videos collected from diverse sources and is designed to reflect real-world scenarios. It is evenly distributed with;</p> <ul> <li> <p>Different locations: Different locations within an industrial setting where fire extinguishers are usually installed, like emergency exits, heavy machinery, near combustible material etc., all have been considered within the dataset.</p> </li> <li> <p>Different angles and perspectives: The dataset includes images captured from different angles and perspectives, such as from above, below, or from the side, in a crowded space or fire extinguishers obscured behind other objects in different locations.</p> </li> <li> <p>Different lighting conditions: The dataset includes images in different lighting conditions, like where the fire extinguisher is clearly visible, partially visible or obstructed.</p> </li> <li> <p>Different classes: The dataset is balanced between the two classes, present and missing fire extinguishers, to avoid bias in the model.  </p> </li> </ul>"},{"location":"scenarios/missing-fire-extinguisher/#model-card","title":"Model card","text":"Dataset size Version Camera support Precision Recall  mAP   4726 v1 Ceiling 91.0%  89.6%  84.0%"},{"location":"scenarios/missing-fire-extinguisher/#scenario-details","title":"Scenario details","text":"<p>Our VisionAI solution detects missing fire extinguishers in different scenarios within an industrial setting where the presence of fire extinguishers is expected. These scenarios can be;</p> <ul> <li> <p>Fire extinguishers are generally wall or pillar mounted. Our model is trained to detect the missing fire extinguishers in these locations.</p> </li> <li> <p>Our state-of-the-art models can detect missing fire extinguishers near hazardous/combustible material inside a manufacturing plant.</p> </li> <li> <p>There are specific equipment or machinery that require the availability of fire extinguishers in close proximity for safety reasons. Our model can identify any such space if a fire extinguisher is missing.</p> </li> <li> <p>Also, the model can detect missing fire extinguishers near emergency exits, where they are installed for quick access in case of fire.  </p> </li> </ul> Test now with online Web-CamWith RTSP Camera - PipelinesWith Azure Setup <p>To test this model &amp; scenario, you can use the following steps:</p> <ul> <li> <p>Install the visionai package from PyPI</p> <pre><code>$ pip install visionai\n</code></pre> </li> <li> <p>Test the scenario from your local web-cam</p> <pre><code>$ visionai scenario test miss-fire-exting-detection\n\nDownloading models for scenario: miss-fire-exting-detection\nModel: miss-fire-exting-detection: https://workplaceos.blob.core.windows.net/models/yolov5s-people/yolov5s-people-0.0.4.zip\n\n\nStarting scenario: miss-fire-exting-detection..\n</code></pre> </li> <li> <p>You should be able to see the events generated on your console window with the detections of smoking/vaping event within the camera field of view.</p> </li> </ul> <p>[TODO]</p> <p>VisionAI app is available at a Azure Market place, one can download and use it by following steps mentioned here</p>"},{"location":"scenarios/missing-fire-extinguisher/#features","title":"Features","text":"<p>Some potential features of VisionAI for detecting missing fire extinguishers could include:</p> <ul> <li> <p>Continuous monitoring: An system could continuously monitor fire extinguisher locations and track any changes in real-time, enabling prompt detection of missing fire extinguishers.</p> </li> <li> <p>Location tracking: The system could use sensors or other location tracking devices to monitor the precise location of fire extinguishers and track any movements or changes in their location.</p> </li> <li> <p>Alerts and notifications: When a missing fire extinguisher is detected, the system could automatically generate an alert or notification to the appropriate personnel or authorities, enabling prompt corrective action.</p> </li> <li> <p>Historical data analysis: Over time, the system could collect and analyze historical data on fire extinguisher locations, enabling identification of trends or patterns that may indicate underlying fire safety issues.</p> </li> </ul> <p>Note</p> <p>Overall, an AI-based system for detecting missing fire extinguishers could enable more proactive and efficient fire safety monitoring and management, helping to prevent fires and ensure the safety of occupants and property.</p>"},{"location":"scenarios/missing-fire-extinguisher/#training-with-custom-data","title":"Training with custom data","text":"<p>The scenario is provided as part of our GPL-v3 package for VisionAI. If you wish to train this with custom datasets, please contact us and we can provide you with the training code. You can do custom training with your own datasets for free, as long as it complies with GPLv3 license (you give back the code to the community). If you are interested in a custom license, please contact us.</p>"},{"location":"scenarios/missing-fire-extinguisher/#contact-us","title":"Contact Us","text":"<ul> <li>For technical issues, you can open a Github issue here.</li> <li>For business inquiries, you can contact us through our website.</li> </ul>"},{"location":"scenarios/mobile-phone-compliance/","title":"Mobile Phone Compliance","text":"<p>Enabling businesses to overcome digital distractions and misuse of mobile phones at workplaces.</p> <p> </p> Visionify Mobile Phone Usage Detection"},{"location":"scenarios/mobile-phone-compliance/#business-challenge","title":"Business Challenge","text":"<p>In today's digital workplace, unauthorized mobile phone usage presents significant risks to enterprise security and productivity. From industrial espionage to data breaches, organizations need robust solutions to enforce mobile phone policies and protect sensitive areas.</p>"},{"location":"scenarios/mobile-phone-compliance/#the-visionify-solution","title":"The Visionify Solution","text":"<p>Visionify's enterprise-grade computer vision platform delivers automated, real-time detection of unauthorized mobile phone usage across your facilities. By leveraging advanced AI and deep learning technologies, our solution provides:</p> <ul> <li>Superior Detection Accuracy: Up to 92% accurate detection of mobile phone usage, significantly outperforming traditional surveillance methods</li> <li>Immediate ROI: Seamless integration with existing security camera infrastructure, eliminating the need for additional hardware investment</li> <li>Enterprise-Scale Deployment: Proven deployment across multiple facilities and thousands of cameras</li> <li>Real-Time Alerts: Instant notification system for security teams when violations occur</li> <li>Compliance Support: Comprehensive audit trails and reporting to support regulatory requirements</li> </ul>"},{"location":"scenarios/mobile-phone-compliance/#enterprise-benefits","title":"Enterprise Benefits","text":"Enhanced Security <ul> <li>Prevent unauthorized documentation of sensitive information</li> <li>Protect intellectual property and trade secrets</li> <li>Reduce risks of industrial espionage</li> </ul> Operational Excellence <ul> <li>Automate compliance monitoring across facilities</li> <li>Reduce manual security oversight costs</li> <li>Improve workplace productivity</li> </ul> Risk Management <ul> <li>Support regulatory compliance requirements</li> <li>Maintain audit trails for investigations</li> <li>Reduce liability exposure</li> </ul> Enterprise-Ready Architecture <ul> <li>Edge-based processing for minimal network impact</li> <li>Flexible deployment options (cloud, on-premise, hybrid)</li> <li>Enterprise-grade security and encryption</li> <li>High availability and failover support</li> </ul>"},{"location":"scenarios/mobile-phone-compliance/#implementation-process","title":"Implementation Process","text":"<ol> <li>Assessment: Review of existing camera infrastructure and compliance requirements</li> <li>Deployment: Rapid integration with existing security systems</li> <li>Configuration: Customization of detection parameters and alert protocols</li> <li>Training: Security team orientation and system management training</li> <li>Support: Ongoing technical support and system optimization</li> </ol>"},{"location":"scenarios/mobile-phone-compliance/#privacy-and-compliance","title":"Privacy and Compliance","text":"<p>Our solution is designed with enterprise privacy requirements in mind: - Data processing compliant with GDPR and other privacy regulations - No personal data storage - Configurable privacy zones - Role-based access control</p>"},{"location":"scenarios/mobile-phone-compliance/#enterprise-support","title":"Enterprise Support","text":"<ul> <li>24/7 technical support</li> <li>Dedicated account management</li> <li>Regular system updates and improvements</li> <li>Custom integration services available</li> </ul>"},{"location":"scenarios/mobile-phone-compliance/#custom-enterprise-solutions","title":"Custom Enterprise Solutions","text":"<p>For organizations requiring customized solutions, Visionify offers:</p> <ul> <li>Custom model training for specific use cases</li> <li>Integration with existing enterprise systems</li> <li>Custom reporting and analytics</li> <li>Extended support packages</li> </ul>"},{"location":"scenarios/mobile-phone-compliance/#next-steps","title":"Next Steps","text":"<ul> <li>Quick Start</li> <li>Camera Placement Guide</li> <li>Supported Scenarios</li> <li>Camera Management</li> <li>FAQs</li> </ul>"},{"location":"scenarios/mobile-phone-compliance/#contact-information","title":"Contact Information","text":"contact_phone Sales Inquiries <p>Get in touch with our sales team for demos and pricing information.</p> <ul> <li>Email: sales@visionify.ai</li> <li>Phone: +1 720-449-1124</li> </ul> support_agent Technical Support <p>Need help? Visit our support portal or contact our technical team.</p> <ul> <li>https://support.visionify.ai</li> <li>support@visionify.ai</li> </ul> calendar_month Schedule a Demo <p>See VisionAI in action with a personalized demo from our team.</p> event                 Book Your Demo"},{"location":"scenarios/no-food-or-drinks/","title":"No Food, No Drinks","text":"<p>An easier, smarter way to enforce policies with VisionAI</p> <p> </p> Event: No food, No drinks"},{"location":"scenarios/no-food-or-drinks/#overview","title":"Overview","text":"<p>Implementing a \u2018No Food, No Drinks\u2019 policy can be challenging. However, for some industries like healthcare, manufacturing, textiles, laboratories and pharmaceuticals, it is imperative to have an effective \u2018no food, no drinks\u2019 policy to maintain strict hygiene and safety standards essential to prevent product contamination. Unfortunately, the current mechanisms rely on manual inspections, are highly human-oriented, and are difficult to automate, depending on enforcement by supervisors and security personnel.</p> <p>Manual inspections can be inconsistent and subjective. Also, humans are prone to errors; they may miss food or drink items that are not easily visible. Furthermore, manual inspections may not be able to cover all areas of the workplace, and they can create privacy concerns for employees. All these factors can compromise the effectiveness of the policy and may lead to non-compliance.</p>"},{"location":"scenarios/no-food-or-drinks/#vision-ai-based-monitoring","title":"Vision AI based monitoring","text":"<p>Implement VisionAI solution to address these problems by providing consistent, objective, and cost-effective enforcement while minimizing privacy concerns. Our smart solution seamlessly integrates with your existing camera infrastructure to capture all areas where food and drinks may be present. The model works by detecting and identifying individuals carrying or consuming foods or beverages. In addition, the model is trained to recognize different types of foods and drinks and the actions associated with consuming them, such as holding a cup or bottle and lifting it to the mouth, chewing, swallowing etc.</p> <p>The model analyzes the video feed in real-time and works with the greatest accuracy. It instantly alerts the appropriate personnel to take action and proves to be an effective tool for enforcing a \u2018no food and drinks\u2019 policy in an organizational setting, improving hygiene and safety measures, and ensuring compliance with regulations.</p>"},{"location":"scenarios/no-food-or-drinks/#model-details","title":"Model Details","text":""},{"location":"scenarios/no-food-or-drinks/#dataset","title":"Dataset","text":"<p>The dataset consists of images and videos collected from diverse sources and is designed to reflect real-world scenarios. The dataset is representative of the types of people, settings, and situations where the policy will be enforced. It is evenly distributed with:</p> <ul> <li> <p>Different locations: Different locations within an industrial setting where food and drinks are not allowed, like production areas, offices or workstations, and storage areas, have been considered within the dataset.</p> </li> <li> <p>Different angles and perspectives: The dataset includes images captured from different angles and perspectives, such as a front-facing view to have a clear view of the person for any food item they may be carrying, a top-down view for when the person is seated or when food or drinks are on a table, side view, low/high angle view and oblique view to detect from a diagonal or slanted perspective. An oblique view is useful when carrying food or drinks in a bag or container.</p> </li> <li> <p>Different lighting conditions: The dataset includes images of lighting conditions, like where the food items are partially visible or obstructed.</p> </li> <li> <p>Different versions: The images in the dataset have variations in the appearance of people, food, and drinks, so the model can learn to recognize them in different contexts.</p> </li> </ul>"},{"location":"scenarios/no-food-or-drinks/#model-card","title":"Model card","text":"Dataset size Version Camera support Precision Recall  mAP   3220 v1 Both(Ceiling and Straight) 75.0%  81.6%  84.0%"},{"location":"scenarios/no-food-or-drinks/#scenario-details","title":"Scenario details","text":"<p>Our VisionAI solution for detecting food items and drinks works in different scenarios within an industrial setting. Our model can be deployed at the entrance/exit points or inside to monitor and see whether employees or visitors carry food items or beverages. The model is equipped to detect the following: - Person carrying a food item - Person carrying any beverage - Any spill event taking place within the specified area</p> Test now with online Web-CamWith RTSP Camera - PipelinesWith Azure Setup <p>To test this model &amp; scenario, you can use the following steps:</p> <ul> <li> <p>Install the visionai package from PyPI</p> <pre><code>$ pip install visionai\n</code></pre> </li> <li> <p>Test the scenario from your local web-cam</p> <pre><code>$ visionai scenario test no-food-or-drinks\n\nDownloading models for scenario: no-food-or-drinks\nModel: no-food-or-drinks: https://workplaceos.blob.core.windows.net/models/yolov5s-no-food-or-drinks/yolov5s-no-food-or-drinks-0.0.1.zip\n\n\nStarting scenario: no-food-or-drinks..\n</code></pre> </li> <li> <p>You should be able to see the events generated on your console window with detection of food items and drinks within the camera field of view.</p> </li> </ul> <p>[TODO]</p> <p>VisionAI app is available at a Azure Market place, one can download and use it by following steps mentioned here</p>"},{"location":"scenarios/no-food-or-drinks/#features","title":"Features","text":"<ul> <li> <p>Real-time monitoring: The model analyzes the video feed in real-time and works with the greatest accuracy. It is an effective tool for enforcing a \u2018no food and drinks\u2019 policy in an organizational setting, improving hygiene and safety measures, and ensuring compliance with regulations.</p> </li> <li> <p>Cost-effective: The model is cost-effective and does not require any additional hardware or software. It can be deployed with existing camera infrastructure.</p> </li> <li> <p>Privacy: The model is designed to protect the privacy of employees and visitors. It does not capture or store any personal information, and it does not require any personal information to be provided by the user.</p> </li> <li> <p>Customizable: The model can be customized to suit the needs of the user. It can be trained with custom data to detect and recognize different types of food items and drinks.</p> </li> </ul>"},{"location":"scenarios/no-food-or-drinks/#training-with-custom-data","title":"Training with custom data","text":"<p>The scenario is provided as part of our GPL-v3 package for VisionAI. If you wish to train this with custom datasets, please contact us and we can provide you with the training code. You can do custom training with your own datasets for free, as long as it complies with GPLv3 license (you give back the code to the community). If you are interested in a custom license, please contact us.</p>"},{"location":"scenarios/no-food-or-drinks/#contact-us","title":"Contact Us","text":"<ul> <li>For technical issues, you can open a Github issue here.</li> <li>For business inquiries, you can contact us through our website.</li> </ul>"},{"location":"scenarios/no-smoking-hazard/","title":"No Smoking/No Vaping","text":"<p>No smoking &amp; No vaping zone enforcements with Vision AI.</p> <p> </p> Detection of Smoking event"},{"location":"scenarios/no-smoking-hazard/#overview","title":"Overview","text":"<p>Smoking and vaping are typically banned in workplaces like manufacturing plants, construction sites, warehouses, chemical plants, etc., an ideal 100% compliance rate can be challenging to achieve. However, it is imperative for employers to ensure that their workplaces are absolutely smoke-free.</p> <p>VisionAI makes it possible to avert workplace hazards and help employers maintain 100% compliance through smart AI solutions. Our next-gen real-time detection systems make sure a fire/smoke or any sign of vaping is detected instantly. These systems are also trained to generate alerts and notifications accordingly.</p>"},{"location":"scenarios/no-smoking-hazard/#vision-ai-based-monitoring","title":"Vision AI based monitoring","text":"<p>Vision AI based monitors can be used to detect smoking/vaping events by providing real-time video feeds of the factory area. The cameras scan every frame to ensure there is no sign of smoking/vaping.</p>"},{"location":"scenarios/no-smoking-hazard/#model-details","title":"Model Details","text":""},{"location":"scenarios/no-smoking-hazard/#dataset","title":"Dataset","text":"<p>The dataset for this scenario is based on real-world smoking/vaping events. The dataset consists of images and videos collected from various sources. </p>"},{"location":"scenarios/no-smoking-hazard/#model-card","title":"Model card","text":"Dataset size Version Camera support Precision Recall  mAP   1785 v2 Both(Ceiling and Straight) 98% 95% 95%"},{"location":"scenarios/no-smoking-hazard/#scenario-details","title":"Scenario details","text":"<p>The business logic for this scenario is as follows:</p> <ul> <li>We use existing camera feeds from the premises to detect smoking/vaping events.</li> <li>VisionAI system is able to run on edge devices. It uses camera feeds for processing.</li> <li>We detect people in the camera feed and we monitor whether the person is involved in any smoking/vaping activity.</li> <li>If the person is detected with this event, an alert is raised.</li> </ul> Test now with online Web-CamWith RTSP Camera - PipelinesWith Azure Setup <p>To test this model &amp; scenario, you can use the following steps:</p> <ul> <li> <p>Install the visionai package from PyPI</p> <pre><code>$ pip install visionai\n</code></pre> </li> <li> <p>Test the scenario from your local web-cam</p> <pre><code>$ visionai scenario test no-smoking-detection\n\nDownloading models for scenario: no-smoking-detection\nModel: no-smoking-detection: https://workplaceos.blob.core.windows.net/models/yolov5s-people/yolov5s-people-0.0.4.zip\n\n\nStarting scenario: no-smoking-detection..\n</code></pre> </li> <li> <p>You should be able to see the events generated on your console window with the detections of smoking/vaping within the camera field of view.</p> </li> </ul> <p>[TODO]</p> <p>VisionAI app is available at a Azure Market place, one can download and use it by following steps mentioned here</p>"},{"location":"scenarios/no-smoking-hazard/#features","title":"Features","text":"<p>The VisionAI solution is the most efficient way of implementing this scenario, as evidenced by the following features:</p> <ul> <li> <p>Unmatched accuracy</p> <p>Trained and Tested to give the best results. Our systems are trained to detect Fire and Smoke at the earliest detection with an accuracy of 99%</p> </li> <li> <p>Lightning Fast and Response Time</p> <p>Our Ultra-fast Processing provides real-time inference results and feedback (~30 frames per second processing). </p> </li> <li> <p>Minimizing false-positives/negatives</p> <p>Our systems create a fail-proof system by ensuring there are no false-positives or false-negatives. </p> </li> <li> <p>Scalability and Deployment </p> <p>Our models can be deployed instantly and are camera independent which means they can be pre-installed with existing cameras on site. We also offer cameras, IoT sensors and edge devices with strategic placement that helps scale a large workplace area with minimum installations. </p> </li> <li> <p>Custom Integrations</p> <p>Our detection system can be integrated with other safety systems, such as building management systems or alarm systems, allowing for a coordinated response to emergencies.</p> </li> </ul>"},{"location":"scenarios/no-smoking-hazard/#training-with-custom-data","title":"Training with custom data","text":"<p>The scenario is provided as part of our GPL-v3 package for VisionAI. If you wish to train this with custom datasets, please contact us and we can provide you with the training code. You can do custom training with your own datasets for free, as long as it complies with GPLv3 license (you give back the code to the community). If you are interested in a custom license, please (contact us)[contact.md].</p>"},{"location":"scenarios/no-smoking-hazard/#contact-us","title":"Contact Us","text":"<ul> <li>For technical issues, you can open a Github issue here.</li> <li>For business inquiries, you can contact us through our website.</li> </ul>"},{"location":"scenarios/no-smoking/","title":"No Smoking/No Vaping","text":"<p>No smoking &amp; No vaping zone enforcements with Vision AI.</p> <p> </p> Detection of Smoking event"},{"location":"scenarios/no-smoking/#overview","title":"Overview","text":"<p>Smoking and vaping are typically banned in workplaces like manufacturing plants, construction sites, warehouses, chemical plants, etc., an ideal 100% compliance rate can be challenging to achieve. However, it is imperative for employers to ensure that their workplaces are absolutely smoke-free.</p> <p>VisionAI makes it possible to avert workplace hazards and help employers maintain 100% compliance through smart AI solutions. Our next-gen real-time detection systems make sure a fire/smoke or any sign of vaping is detected instantly. These systems are also trained to generate alerts and notifications accordingly.</p>"},{"location":"scenarios/no-smoking/#vision-ai-based-monitoring","title":"Vision AI based monitoring","text":"<p>Vision AI based monitors can be used to detect smoking/vaping events by providing real-time video feeds of the factory area. The cameras scan every frame to ensure there is no sign of smoking/vaping.</p>"},{"location":"scenarios/no-smoking/#model-details","title":"Model Details","text":""},{"location":"scenarios/no-smoking/#dataset","title":"Dataset","text":"<p>The dataset for this scenario is based on real-world smoking/vaping events. The dataset consists of images and videos collected from various sources. </p>"},{"location":"scenarios/no-smoking/#model","title":"Model","text":"<p>The model is based off of the YOLOv5 algorithm. The model is trained on a custom dataset of images and videos. The model is trained based on the above dataset compiled by our team.</p>"},{"location":"scenarios/no-smoking/#model-card","title":"Model card","text":"Dataset size Version Camera support Precision Recall  mAP   1785 v2 Both(Ceiling and Straight) 98% 95% 95%"},{"location":"scenarios/no-smoking/#scenario-details","title":"Scenario details","text":"<p>The business logic for this scenario is as follows:</p> <ul> <li>We use existing camera feeds from the premises to detect smoking/vaping events.</li> <li>VisionAI system is able to run on edge devices. It uses camera feeds for processing.</li> <li>We detect people in the camera feed and we monitor whether the person is involved in any smoking/vaping activity.</li> <li>If the person is detected with this event, an alert is raised.</li> </ul> Test now with online Web-CamWith RTSP Camera - PipelinesWith Azure Setup <p>To test this model &amp; scenario, you can use the following steps:</p> <ul> <li> <p>Install the visionai package from PyPI</p> <pre><code>$ pip install visionai\n</code></pre> </li> <li> <p>Test the scenario from your local web-cam</p> <pre><code>$ visionai scenario test no-smoking-detection\n\nDownloading models for scenario: no-smoking-detection\nModel: no-smoking-detection: https://workplaceos.blob.core.windows.net/models/yolov5s-people/yolov5s-people-0.0.4.zip\n\n\nStarting scenario: no-smoking-detection..\n</code></pre> </li> <li> <p>You should be able to see the events generated on your console window with the detections of smoking/vaping within the camera field of view.</p> </li> </ul> <p>[TODO]</p> <p>VisionAI app is available at a Azure Market place, one can download and use it by following steps mentioned here</p>"},{"location":"scenarios/no-smoking/#features","title":"Features","text":"<p>The VisionAI solution is the most efficient way of implementing this scenario, as evidenced by the following features:</p> <ul> <li> <p>Unmatched accuracy</p> <p>Trained and Tested to give the best results. Our systems are trained to detect Fire and Smoke at the earliest detection with an accuracy of 99%</p> </li> <li> <p>Lightning Fast and Response Time</p> <p>Our Ultra-fast Processing provides real-time inference results and feedback (~30 frames per second processing). </p> </li> <li> <p>Minimizing false-positives/negatives</p> <p>Our systems create a fail-proof system by ensuring there are no false-positives or false-negatives. </p> </li> <li> <p>Scalability and Deployment </p> <p>Our models can be deployed instantly and are camera independent which means they can be pre-installed with existing cameras on site. We also offer cameras, IoT sensors and edge devices with strategic placement that helps scale a large workplace area with minimum installations. </p> </li> <li> <p>Custom Integrations</p> <p>Our detection system can be integrated with other safety systems, such as building management systems or alarm systems, allowing for a coordinated response to emergencies.</p> </li> </ul>"},{"location":"scenarios/no-smoking/#training-with-custom-data","title":"Training with custom data","text":"<p>The scenario is provided as part of our GPL-v3 package for VisionAI. If you wish to train this with custom datasets, please contact us and we can provide you with the training code. You can do custom training with your own datasets for free, as long as it complies with GPLv3 license (you give back the code to the community). If you are interested in a custom license, please (contact us)[contact.md].</p>"},{"location":"scenarios/no-smoking/#contact-us","title":"Contact Us","text":"<ul> <li>For technical issues, you can open a Github issue here.</li> <li>For business inquiries, you can contact us through our website.</li> </ul>"},{"location":"scenarios/occupancy-metrics/","title":"Occupancy Analytics &amp; Space Optimization","text":"<p>Transform your workplace efficiency with AI-powered occupancy analytics that helps optimize space utilization, ensure safety compliance, and make data-driven facility management decisions.</p> <p> </p> Real-time occupancy monitoring and analytics"},{"location":"scenarios/occupancy-metrics/#business-impact-of-space-management","title":"Business Impact of Space Management","text":"<p>Poor space utilization and occupancy management leads to:</p> <ul> <li>30-40% of office space typically underutilized</li> <li>$12,000 average annual cost per unused workspace</li> <li>$3.6M annual loss for a mid-sized facility due to inefficient space use</li> <li>Increased safety risks from overcrowded areas</li> </ul>"},{"location":"scenarios/occupancy-metrics/#transform-your-facility-management","title":"Transform Your Facility Management","text":"<p>VisionAI's occupancy analytics provides:</p>"},{"location":"scenarios/occupancy-metrics/#1-real-time-occupancy-monitoring","title":"1. Real-Time Occupancy Monitoring","text":"<ul> <li>Live occupancy counting</li> <li>Maximum capacity management</li> <li>Zone-based monitoring</li> <li>Automated alerts for overcrowding</li> </ul>"},{"location":"scenarios/occupancy-metrics/#2-space-utilization-analytics","title":"2. Space Utilization Analytics","text":"<ul> <li>Occupancy trends analysis</li> <li>Peak usage patterns</li> <li>Underutilized area identification</li> <li>Resource optimization insights</li> </ul>"},{"location":"scenarios/occupancy-metrics/#3-safety-compliance","title":"3. Safety &amp; Compliance","text":"<ul> <li>Social distancing monitoring</li> <li>Emergency evacuation support</li> <li>Restricted area management</li> <li>Compliance documentation</li> </ul>"},{"location":"scenarios/occupancy-metrics/#4-operational-efficiency","title":"4. Operational Efficiency","text":"<ul> <li>Staff allocation optimization</li> <li>Energy usage optimization</li> <li>Maintenance scheduling</li> <li>Cleaning service optimization</li> </ul> Dynamic heatmap showing people and forklift movement patterns"},{"location":"scenarios/occupancy-metrics/#industry-applications","title":"Industry Applications","text":""},{"location":"scenarios/occupancy-metrics/#corporate-offices","title":"Corporate Offices","text":"<ul> <li>Workspace utilization</li> <li>Meeting room analytics</li> <li>Common area monitoring</li> <li>Parking optimization</li> </ul>"},{"location":"scenarios/occupancy-metrics/#manufacturing","title":"Manufacturing","text":"<ul> <li>Production area monitoring</li> <li>Break room utilization</li> <li>Safety zone compliance</li> <li>Resource allocation</li> </ul>"},{"location":"scenarios/occupancy-metrics/#retail-commercial","title":"Retail &amp; Commercial","text":"<ul> <li>Customer flow analysis</li> <li>Queue management</li> <li>Staff allocation</li> <li>Layout optimization</li> </ul>"},{"location":"scenarios/occupancy-metrics/#healthcare-facilities","title":"Healthcare Facilities","text":"<ul> <li>Waiting area management</li> <li>Patient flow optimization</li> <li>Staff deployment</li> <li>Resource utilization</li> </ul>"},{"location":"scenarios/occupancy-metrics/#business-benefits","title":"Business Benefits","text":"<p>\u2713 Cost Reduction</p> <ul> <li>Optimize space utilization</li> <li>Reduce energy costs</li> <li>Improve resource allocation</li> <li>Lower operational costs</li> </ul> <p>\u2713 Enhanced Safety</p> <ul> <li>Prevent overcrowding</li> <li>Monitor restricted areas</li> <li>Support emergency response</li> <li>Ensure compliance</li> </ul> <p>\u2713 Improved Operations</p> <ul> <li>Data-driven decisions</li> <li>Efficient staff deployment</li> <li>Better maintenance planning</li> <li>Enhanced user experience</li> </ul> <p>\u2713 Future Planning</p> <ul> <li>Space requirement forecasting</li> <li>Renovation planning</li> <li>Expansion strategies</li> <li>Resource planning</li> </ul>"},{"location":"scenarios/occupancy-metrics/#key-features","title":"Key Features","text":"Feature Description Business Impact Real-Time Monitoring Live occupancy tracking across zones Immediate response to occupancy issues Historical Analytics Trend analysis and pattern recognition Data-driven planning and optimization Automated Alerts Customizable notifications for threshold violations Proactive management of space issues Compliance Reporting Automated documentation of occupancy metrics Simplified regulatory compliance Integration Capability Works with existing systems Seamless implementation Privacy Protection Anonymous occupancy counting GDPR and privacy compliance"},{"location":"scenarios/occupancy-metrics/#learn-more","title":"Learn More","text":"<ul> <li>Quick Start</li> <li>Camera Placement Guide</li> <li>Supported Scenarios</li> <li>Camera Management</li> <li>FAQs</li> </ul>"},{"location":"scenarios/occupancy-metrics/#contact-information","title":"Contact Information","text":"contact_phone Sales Inquiries <p>Get in touch with our sales team for demos and pricing information.</p> <ul> <li>Email: sales@visionify.ai</li> <li>Phone: +1 720-449-1124</li> </ul> support_agent Technical Support <p>Need help? Visit our support portal or contact our technical team.</p> <ul> <li>https://support.visionify.ai</li> <li>support@visionify.ai</li> </ul> calendar_month Schedule a Demo <p>See VisionAI in action with a personalized demo from our team.</p> event                 Book Your Demo"},{"location":"scenarios/occupancy-policies/","title":"Occupancies Policies","text":"<p>Ensuring security and controlled access at the workplace is vital for organizations, but conventional surveillance and crowd management techniques are complex, expensive, and heavily reliant on human intervention. Furthermore, these systems are often unable to provide desired, foolproof results due to limitations, inaccuracies, and the inability to provide multiple metrics.</p> <p>One of the significant challenges with current systems for workplace crowd management is the constantly evolving workplace dynamics. For instance, frequent changes in access requirements can make it difficult to reconfigure one-time installation measures and create a tedious and time-consuming task. As a result, these systems may be limited in terms of flexibility, adaptability, and scalability, making them less effective in certain situations and unable to adapt to changing needs or circumstances. This challenge highlights the need for more dynamic and adaptable solutions to accommodate the evolving nature of workplaces.</p>"},{"location":"scenarios/occupancy-policies/#visionifys-workplace-safety-suite-for-occupancy-policies","title":"Visionify\u2019s Workplace Safety Suite for Occupancy Policies","text":"<p>Enhance the safety and intelligence of your workplace with our cutting-edge VisionAI suite designed for effective crowd management. Our Crowd Management suite offers a complete solution set that helps you regulate access, enforce security policy adherence and deter intruders effectively. Our fully automated and ready-to-deploy models enable real-time monitoring for the detection of unauthorized access attempts, ensuring that your facility is guarded 24/7. Instant alerts are sent to prevent security breaches before they happen. Our system guarantees reliable detection and can be seamlessly integrated with your existing camera infrastructure, making it easy to scale your system with just a few clicks.</p> <p>What\u2019s included in this suite:</p> <ul> <li>Max occupancy</li> <li>Restricted areas/times</li> <li>Dwell time</li> <li>Authorized personnel</li> </ul>"},{"location":"scenarios/ppe-detection/","title":"PPE Detection","text":"<p>Transform Workplace Safety with Intelligent Vision AI Solutions from Visionify</p> <p> </p> Visionify PPE Compliance Solution"},{"location":"scenarios/ppe-detection/#business-impact","title":"Business Impact","text":"<p>In 2021, workplace injuries resulted in over $167 billion in costs to businesses, with a significant portion attributed to PPE non-compliance. Our Vision AI solution helps organizations:</p> <ul> <li>Reduce Liability: Protect your organization from legal damages and worker compensation claims</li> <li>Maintain Productivity: Prevent accidents that lead to downtime and reduced output</li> <li>Ensure Compliance: Achieve 24/7 automated monitoring of PPE requirements</li> <li>Protect Workforce: Safeguard your most valuable asset - your employees</li> </ul>"},{"location":"scenarios/ppe-detection/#solution-overview","title":"Solution Overview","text":"<p>Visionify's PPE Compliance Solution leverages advanced AI to monitor and enforce safety equipment requirements in real-time. Our system integrates with your existing camera infrastructure to provide:</p> <p> </p> PPE Compliance Sample Event"},{"location":"scenarios/ppe-detection/#comprehensive-detection","title":"Comprehensive Detection","text":"<ul> <li>\u2713 Helmets &amp; Hard Hats</li> <li>\u2713 Safety Gloves</li> <li>\u2713 Protective Eyewear</li> <li>\u2713 High-Visibility Vests</li> <li>\u2713 Safety Footwear</li> <li>\u2713 Face Masks &amp; Shields</li> <li>\u2713 Fall Protection Equipment</li> </ul> Configure PPE compliance with Zones"},{"location":"scenarios/ppe-detection/#enterprise-grade-features","title":"Enterprise-Grade Features","text":"<ul> <li>Real-Time Monitoring: Continuous surveillance across all shifts and locations</li> <li>Instant Alerts: Immediate notifications when violations are detected</li> <li>Compliance Reporting: Detailed analytics and trends for safety management</li> <li>Multi-Site Support: Centralized monitoring across facilities</li> <li>Custom Integration: APIs and webhooks for your existing safety systems</li> </ul>"},{"location":"scenarios/ppe-detection/#implementation-benefits","title":"Implementation Benefits","text":"<ol> <li> <p>Rapid Deployment</p> <ul> <li>Uses existing security cameras</li> <li>Edge-based processing for minimal IT overhead</li> <li>Quick setup and configuration</li> </ul> </li> <li> <p>Proven Reliability</p> <ul> <li>Trained on 100,000+ real-world images</li> <li>Optimized for various environments and lighting conditions</li> <li>Industry-leading accuracy rates</li> </ul> </li> <li> <p>Cost-Effective</p> <ul> <li>Reduces manual monitoring needs</li> <li>Prevents costly accidents and violations</li> <li>Scalable pricing based on deployment size</li> </ul> </li> </ol>"},{"location":"scenarios/ppe-detection/#industry-applications","title":"Industry Applications","text":"<ul> <li>Manufacturing &amp; Industrial</li> <li>Construction Sites</li> <li>Warehousing &amp; Logistics</li> <li>Oil &amp; Gas Facilities</li> <li>Mining Operations</li> <li>Food Processing Plants</li> </ul>"},{"location":"scenarios/ppe-detection/#success-metrics","title":"Success Metrics","text":"<ul> <li>Up to 85% reduction in PPE-related incidents</li> <li>90% decrease in manual safety monitoring costs</li> <li>Average ROI within 6-8 months of deployment</li> </ul>"},{"location":"scenarios/ppe-detection/#events-supported","title":"Events Supported","text":"<p>Table: PPE Compliance Events and Detection Details</p> Status Scenario name Supported Events Event Details More Info \u2705 PPE Compliance <code>No Helmet</code> Person detected without helmet <code>No Gloves</code> Person detected without gloves <code>No Safety Boots</code> Person detected without safety boots <code>No High-Vis Vest</code> Person detected without high-vis vest <code>No Goggles</code> Person detected without goggles <code>No Mask</code> Person detected without mask <code>No Cap</code> Person detected without cap <code>No Apron</code> Person detected without apron <code>No Hairnet</code> Person detected without hairnet <code>No Face Shield</code> Person detected without face shield (Welding) <code>No Coveralls</code> Person detected without coveralls <code>No Safety Harness</code> Personal Fall Arrest System (PFAS) <code>No Earmuffs</code> Person detected without earmuffs"},{"location":"scenarios/ppe-detection/#getting-started","title":"Getting Started","text":"<ol> <li>Schedule a Demo</li> <li>Review our Implementation Guide</li> <li>Deploy with our expert support team</li> </ol>"},{"location":"scenarios/ppe-detection/#next-steps","title":"Next Steps","text":"<ul> <li>Quick Start</li> <li>Camera Placement Guide</li> <li>Supported Scenarios</li> <li>Camera Management</li> <li>FAQs</li> </ul>"},{"location":"scenarios/ppe-detection/#contact-information","title":"Contact Information","text":"contact_phone Sales Inquiries <p>Get in touch with our sales team for demos and pricing information.</p> <ul> <li>Email: sales@visionify.ai</li> <li>Phone: +1 720-449-1124</li> </ul> support_agent Technical Support <p>Need help? Visit our support portal or contact our technical team.</p> <ul> <li>https://support.visionify.ai</li> <li>support@visionify.ai</li> </ul> calendar_month Schedule a Demo <p>See VisionAI in action with a personalized demo from our team.</p> event                 Book Your Demo"},{"location":"scenarios/rust-and-corrosion-hazard/","title":"Equipment monitoring","text":""},{"location":"scenarios/rust-and-corrosion-hazard/#rust-and-corrosion-detection","title":"Rust and Corrosion Detection","text":"<p>Ensure the safety of employees by inspecting machine equipment for the presence of rust/corrosion. </p> <p></p>"},{"location":"scenarios/rust-and-corrosion-hazard/#overview","title":"Overview","text":"<p>Visual inspection of industrial environments is a common requirement across heavy industries, such as transportation, construction, and shipbuilding, and typically requires qualified experts to perform the inspection. Inspection locations can often be remote or in adverse environments that put humans at risk, such as bridges, skyscrapers, and offshore oil rigs. </p> <p>Many of these industries deal with huge metal surfaces and harsh environments. A common problem across these industries is metal corrosion and rust. Although corrosion and rust are used interchangeably across different industries (we also use the terms interchangeably in this post), these two phenomena are different. </p> <p>Visionify\u2019s AI Vision Model for Rust/Corrosion Detection is designed to detect instances of rust/corrosion if any in machine parts, manufacturing equipments etc. </p>"},{"location":"scenarios/rust-and-corrosion-hazard/#events","title":"Events","text":"<p>VisionAI model's generated events would be:</p> <ul> <li>Rust or corrosion event detected</li> </ul>"},{"location":"scenarios/rust-and-corrosion-hazard/#model-details","title":"Model Details","text":""},{"location":"scenarios/rust-and-corrosion-hazard/#dataset","title":"Dataset","text":"<p>The dataset for this scenario is based on rust/corrosion detection algorithms. The dataset is made up of images and videos gathered from various sources where instances of rust were found. The dataset has been catalogued to ensure real-world situations. It has an even distribution of:</p> <ul> <li>Variations of pieces of equipment</li> <li>Different(indoor/outdoor) environments</li> <li>Different rust severity</li> <li>Variations in camera orientations</li> <li>Using security camera feeds</li> </ul> <p>Total number of images used was 5572.</p>"},{"location":"scenarios/rust-and-corrosion-hazard/#model","title":"Model","text":"<p>The model is based off of the YOLOv5 algorithm. The model is trained on a custom dataset of images and videos. The model is trained based on the above dataset compiled by our team.</p>"},{"location":"scenarios/rust-and-corrosion-hazard/#model-card","title":"Model card","text":"Dataset size Version Camera support Precision Recall  mAP   2326 v5 Straight 79% 49% 56% <p>The model is adaptable enough to run on any edge computing device.</p>"},{"location":"scenarios/rust-and-corrosion-hazard/#scenario-details","title":"Scenario details","text":"<p>The business logic for this scenario is as follows: </p> <ul> <li>We use existing camera feeds from the premises to monitor the equipments in the workplace. </li> <li>VisionAI system is able to run on edge devices. It uses camera feeds for processing. </li> <li>We detect instances of rust/corrosion if any in machine parts, manufacturing equipments.</li> </ul> Test now with online Web-CamWith RTSP Camera - PipelinesWith Azure Setup <p>To test this model &amp; scenario, you can use the following steps:</p> <ul> <li> <p>Install the visionai package from PyPI</p> <pre><code>$ pip install visionai\n</code></pre> </li> <li> <p>Test the scenario from your local web-cam</p> <pre><code>$ visionai scenario test rust-detection\n\nDownloading models for scenario: rust-detection\nModel: rust-detection: https://workplaceos.blob.core.windows.net/models/yolov5s-people/yolov5s-people-0.0.4.zip\n\n\nStarting scenario: rust-detection..\n</code></pre> </li> <li> <p>You should be able to see the events generated on your console window with the detections of smoking/vaping event within the camera field of view.</p> </li> </ul> <p>[TODO]</p> <p>VisionAI app is available at a Azure Market place, one can download and use it by following steps mentioned here</p>"},{"location":"scenarios/rust-and-corrosion-hazard/#training-with-custom-data","title":"Training with custom data","text":"<p>The scenario is provided as part of our GPL-v3 package for VisionAI. If you wish to train this with custom datasets, please contact us and we can provide you with the training code. You can do custom training with your own datasets for free, as long as it complies with GPLv3 license (you give back the code to the community). If you are interested in a custom license, please contact us.</p>"},{"location":"scenarios/rust-and-corrosion-hazard/#learn-more","title":"Learn More","text":"<ul> <li>Quick Start</li> <li>Camera Placement Guide</li> <li>Supported Scenarios</li> <li>Camera Management</li> <li>FAQs</li> </ul>"},{"location":"scenarios/rust-and-corrosion-hazard/#contact-information","title":"Contact Information","text":"contact_phone Sales Inquiries <p>Get in touch with our sales team for demos and pricing information.</p> <ul> <li>Email: sales@visionify.ai</li> <li>Phone: +1 720-449-1124</li> </ul> support_agent Technical Support <p>Need help? Visit our support portal or contact our technical team.</p> <ul> <li>https://support.visionify.ai</li> <li>support@visionify.ai</li> </ul> calendar_month Schedule a Demo <p>See VisionAI in action with a personalized demo from our team.</p> event                 Book Your Demo"},{"location":"scenarios/sexual-harassment/","title":"Sexual Harassment","text":"<p>Create a safer and more respectful workplace for all employees</p> <p> </p> Monitoring of Sexual Harassment event"},{"location":"scenarios/sexual-harassment/#overview","title":"Overview","text":"<p>Sexual harassment in the workplace is a serious issue that can have significant negative impacts on employees' mental health, job satisfaction, and overall well-being. In addition, it can also result in decreased productivity and increased turnover, leading to financial costs for the company.</p> <p>Implementing a sexual harassment detection model can also send a clear message to employees that the organization takes sexual harassment seriously and is committed to creating a safe and respectful workplace for all. This can help to foster a culture of respect and trust within the organization, which can have positive impacts on employee morale and overall job satisfaction.</p> <p>Overall, a sexual harassment detection model can help organizations to create a safer and more respectful workplace for all employees, which can lead to increased productivity, reduced turnover, and improved organizational outcomes.</p>"},{"location":"scenarios/sexual-harassment/#visionai-based-monitoring","title":"VisionAI Based Monitoring","text":"<p>Sexual harassment detection using VisionAI based solution can help to prevent inappropriate behavior and create safer environments. Our models can analyze video footage or images and identify patterns or actions that are indicative of sexual harassment.</p> <p>To detect sexual harassment our model is trained on a dataset of video footage or images with labeled instances of sexual harassment. The algorithm can learn to recognize patterns in the data that are associated with inappropriate behavior, such as physical contact, gestures, or facial expressions.</p> <p>Our trained model now, can be used to analyze live video footage or images in real-time which can further help in enabling alert to authorities or trigger an alarm when it detects suspicious behavior, allowing them to intervene and prevent further harassment.</p>"},{"location":"scenarios/sexual-harassment/#model-card","title":"Model card","text":"Dataset size Version Camera support Precision Recall  mAP   4126 v5 Both(Ceiling and Straight) 84%  77%  74%"},{"location":"scenarios/sexual-harassment/#contact-us","title":"Contact Us","text":"<ul> <li>For technical issues, you can open a Github issue here.</li> <li>For business inquiries, you can contact us through our website.</li> </ul>"},{"location":"scenarios/shipping-activity/","title":"Shipping Activity Detection","text":"<p>Stay vigilant even after hours with our advanced suspicious shipping activity solution.</p> <p>Detection of suspicious shipping activity event</p>"},{"location":"scenarios/shipping-activity/#overview","title":"Overview","text":"<p>Shipping activity detection refers to the use of technology to identify and monitor shipping activity that may be indicative of illicit activity. Shipping activity detection technologies may include sensors, cameras, and other monitoring systems that can detect and track shipping activity. Some of these technologies can be integrated with machine learning and artificial intelligence (AI) algorithms to analyze data and identify patterns of behavior that may be indicative of suspicious shipping activity.</p> <p>Shipping activity detection technologies can be used in a variety of settings, including ports, harbors, and other areas where shipping activity may occur. These technologies can help identify potential security threats, such as vessels that may be carrying weapons or engaging in suspicious activities.</p> <p>The Suspicious shipping activity detected from non-designated area and during after-hours model is an important tool to identify potential threats and take appropriate action to mitigate risks.</p>"},{"location":"scenarios/shipping-activity/#vision-ai-based-monitoring","title":"Vision AI based monitoring","text":"<p>VisionAI's shipping activity detection solutions can be used to for the detection of suspicious shipping activity events by providing real-time video feeds of the shipping area. The cameras scan every frame and raise an event when a suspicious entry detected from an usually closed location or during off-hours and/or for extended duration of time.</p> <p>Suspicious Shipping Activity Detection model is an important tool for helping to prevent fraudulent or criminal activity in the shipping industry, and it works in real time to help ensure that potentially suspicious activity is identified and addressed as quickly as possible.</p>"},{"location":"scenarios/shipping-activity/#model-details","title":"Model Details","text":""},{"location":"scenarios/shipping-activity/#dataset","title":"Dataset","text":"<p>The dataset of Suspicious shipping activity detected from non-designated area and during after-hours is a collection of data points that provide insights into potential illicit activities taking place in the shipping industry.  One key feature of this dataset is the inclusion of information on shipping activity outside of designated areas and during after-hours. These factors are often indicators of suspicious behavior, as they suggest that the vessel is attempting to avoid detection and operate outside of normal shipping patterns. By analyzing this data, security personnel can identify potential threats and take appropriate action to prevent harm.</p>"},{"location":"scenarios/shipping-activity/#model-card","title":"Model card","text":"Dataset size Version Camera support Precision Recall  mAP   4126 v5 Both(Ceiling and Straight) 84.0% 87.5% 81.4%"},{"location":"scenarios/shipping-activity/#scenario-details","title":"Scenario details","text":"<p>Our VisionAI solution for Suspicious shipping activity detection works in different scenarios.</p> <ul> <li> <p>The model works by continuously monitoring shipping data from various sources and then analyzes the data to identify patterns and anomalies that may be indicative of suspicious activity.</p> </li> <li> <p>The model may flag a shipment as suspicious if it originates from a non-designated area or if it is being shipped during after-hours.</p> </li> <li> <p>Once the model identifies a potentially suspicious shipment, it can trigger an alert to notify relevant personnel or authorities, who can then  investigate further and take appropriate action as needed.</p> </li> </ul> Test now with online Web-CamWith RTSP Camera - PipelinesWith Azure Setup <p>To test this model &amp; scenario, you can use the following steps:</p> <ul> <li> <p>Install the visionai package from PyPI</p> <pre><code>$ pip install visionai\n</code></pre> </li> <li> <p>Test the scenario from your local web-cam</p> <pre><code>$ visionai scenario test shipping-activity-detection\n\nDownloading models for scenario: shipping-activity-detection\nModel: shipping-activity-detection: https://workplaceos.blob.core.windows.net/models/yolov5s-shipping-activity-detection/yolov5s-shipping-activity-detection-0.0.1.zip\n\n\nStarting scenario: shipping-activity-detection..\n</code></pre> </li> <li> <p>You should be able to see the information generated on your console window with suspicious shipping activity detection events within the camera field of view.</p> </li> </ul> <p>[TODO]</p> <p>VisionAI app is available at a Azure Market place, one can download and use it by following steps mentioned here</p>"},{"location":"scenarios/shipping-activity/#features","title":"Features","text":"<ul> <li> <p>Real-time monitoring: The solution is designed to monitor shipping data in real-time, allowing for rapid detection and response to suspicious shipping activity. </p> </li> <li> <p>Alert system: The model is programmed to send alerts or notify the security personnel in case of any suspicious shipping activity.</p> </li> <li> <p>Easy to deploy: The solution can be deployed easily with minimal effort and can be integrated with the existing camera infrastructure.</p> </li> <li> <p>Customizable: The solution can be customized to meet the specific requirements of the organization.</p> </li> </ul>"},{"location":"scenarios/shipping-activity/#training-with-custom-data","title":"Training with custom data","text":"<p>The scenario is provided as part of our GPL-v3 package for VisionAI. If you wish to train this with custom datasets, please contact us and we can provide you with the training code. You can do custom training with your own datasets for free, as long as it complies with GPLv3 license (you give back the code to the community). If you are interested in a custom license, please contact us.</p>"},{"location":"scenarios/shipping-activity/#contact-us","title":"Contact Us","text":"<ul> <li>For technical issues, you can open a Github issue here.</li> <li>For business inquiries, you can contact us through our website.</li> </ul>"},{"location":"scenarios/slip-and-fall-detection/","title":"Slip and Fall Detection &amp; Prevention","text":"<p>Protect your workforce and reduce liability with AI-powered slip and fall detection. Get instant alerts, comprehensive analytics, and documented compliance.</p> <p> </p> Real-time slip and fall monitoring across your facility"},{"location":"scenarios/slip-and-fall-detection/#the-challenge","title":"The Challenge","text":"<p>Slip and fall incidents remain one of the leading causes of workplace injuries and liability claims:</p> <ul> <li>$70 billion annual cost to U.S. businesses</li> <li>30% of workplace injuries are slip and fall related</li> <li>95% of serious falls require hospitalization</li> <li>Average claim costs $20,000 in direct expenses</li> </ul>"},{"location":"scenarios/slip-and-fall-detection/#transform-your-safety-program","title":"Transform Your Safety Program","text":"<p>VisionAI's slip and fall detection system provides:</p>"},{"location":"scenarios/slip-and-fall-detection/#1-immediate-response","title":"1. Immediate Response","text":"<ul> <li>Real-time fall detection across your facility</li> <li>Instant alerts to safety personnel</li> <li>Automated emergency response protocols</li> <li>Critical response time reduction</li> </ul>"},{"location":"scenarios/slip-and-fall-detection/#2-comprehensive-coverage","title":"2. Comprehensive Coverage","text":"<ul> <li>Monitor high-risk areas 24/7</li> <li>Cover multiple locations from one dashboard</li> <li>Protect workers in isolated areas</li> <li>Support for all lighting conditions</li> </ul>"},{"location":"scenarios/slip-and-fall-detection/#3-risk-prevention","title":"3. Risk Prevention","text":"<ul> <li>Identify high-risk areas and patterns</li> <li>Proactive hazard notifications</li> <li>Slip and trip prevention analytics</li> <li>Custom safety zone monitoring</li> </ul>"},{"location":"scenarios/slip-and-fall-detection/#industry-applications","title":"Industry Applications","text":""},{"location":"scenarios/slip-and-fall-detection/#manufacturing-warehousing","title":"Manufacturing &amp; Warehousing","text":"<ul> <li>Loading dock monitoring</li> <li>Wet floor detection</li> <li>High-traffic area surveillance</li> <li>Material handling zones</li> </ul>"},{"location":"scenarios/slip-and-fall-detection/#construction","title":"Construction","text":"<ul> <li>Scaffold and ladder monitoring</li> <li>Open pit protection</li> <li>Multi-level site coverage</li> <li>Equipment area safety</li> </ul>"},{"location":"scenarios/slip-and-fall-detection/#healthcare-assisted-living","title":"Healthcare &amp; Assisted Living","text":"<ul> <li>Patient fall prevention</li> <li>Bathroom and corridor monitoring</li> <li>Quick staff response enablemen</li> <li>Privacy-compliant monitoring</li> </ul>"},{"location":"scenarios/slip-and-fall-detection/#retail-commercial","title":"Retail &amp; Commercial","text":"<ul> <li>Customer safety monitoring</li> <li>Back-of-house protection</li> <li>Loading area surveillance</li> <li>Maintenance alert system</li> </ul>"},{"location":"scenarios/slip-and-fall-detection/#business-benefits","title":"Business Benefits","text":"<p>\u2713 Reduce Incidents</p> <ul> <li>Up to 60% reduction in slip and fall incidents</li> <li>Prevent serious injuries through early detection</li> <li>Minimize workplace disruptions</li> </ul> <p>\u2713 Lower Costs</p> <ul> <li>Reduce insurance premiums</li> <li>Decrease worker compensation claims</li> <li>Minimize litigation expenses</li> </ul> <p>\u2713 Improve Compliance</p> <ul> <li>Automated incident documentation</li> <li>OSHA compliance support</li> <li>Risk assessment reports</li> </ul> <p>\u2713 Enhance Operations</p> <ul> <li>Optimize safety protocols</li> <li>Improve response procedures</li> <li>Data-driven safety decisions</li> </ul>"},{"location":"scenarios/slip-and-fall-detection/#success-story","title":"Success Story","text":"<p>\"After implementing VisionAI's slip and fall detection, we saw a 45% reduction in incident response times and a 30% decrease in our insurance premiums. The system paid for itself within the first year.\" </p> <p>- Safety Director, Major Distribution Center</p>"},{"location":"scenarios/slip-and-fall-detection/#easy-implementation","title":"Easy Implementation","text":"<ol> <li> <p>Quick Setup</p> <ul> <li>Uses existing security cameras</li> <li>No additional hardware needed</li> <li>Privacy-compliant installation</li> </ul> </li> <li> <p>Seamless Integration</p> <ul> <li>Works with your current systems</li> <li>Custom alert configurations</li> <li>Mobile app access</li> </ul> </li> <li> <p>Ongoing Support</p> <ul> <li>24/7 technical assistance</li> <li>Regular system updates</li> <li>Dedicated success manager</li> </ul> </li> </ol>"},{"location":"scenarios/slip-and-fall-detection/#learn-more","title":"Learn More","text":"<ul> <li>Quick Start</li> <li>Camera Placement Guide</li> <li>Supported Scenarios</li> <li>Camera Management</li> <li>FAQs</li> </ul>"},{"location":"scenarios/slip-and-fall-detection/#contact-information","title":"Contact Information","text":"contact_phone Sales Inquiries <p>Get in touch with our sales team for demos and pricing information.</p> <ul> <li>Email: sales@visionify.ai</li> <li>Phone: +1 720-449-1124</li> </ul> support_agent Technical Support <p>Need help? Visit our support portal or contact our technical team.</p> <ul> <li>https://support.visionify.ai</li> <li>support@visionify.ai</li> </ul> calendar_month Schedule a Demo <p>See VisionAI in action with a personalized demo from our team.</p> event                 Book Your Demo"},{"location":"scenarios/smoke-and-fire-detection/","title":"Early Fire Detection &amp; Prevention","text":"<p>Protect your facility and workforce with AI-powered early fire detection. </p> <p> </p> Real-time smoke and fire detection across your facility"},{"location":"scenarios/smoke-and-fire-detection/#important-safety-notice","title":"Important Safety Notice","text":"<p>VisionAI's fire detection system is designed to complement, not replace, your primary fire detection infrastructure. While our AI system achieves ~90% accuracy in early detection, it should be used alongside traditional fire alarm systems, smoke detectors, and established safety protocols.</p>"},{"location":"scenarios/smoke-and-fire-detection/#complementary-detection-system","title":"Complementary Detection System","text":"<ul> <li>Works alongside traditional fire alarms</li> <li>Provides visual verification capability</li> <li>Adds an extra layer of safety</li> <li>Helps reduce false alarm costs</li> </ul>"},{"location":"scenarios/smoke-and-fire-detection/#system-performance","title":"System Performance","text":"<ul> <li>~90% detection accuracy</li> <li>Early visual warning system</li> <li>Real-time monitoring capability</li> <li>Integration with existing safety systems</li> </ul>"},{"location":"scenarios/smoke-and-fire-detection/#recommended-usage","title":"Recommended Usage","text":"<ul> <li>\u2713 Secondary monitoring system</li> <li>\u2713 Visual verification tool</li> <li>\u2713 Early warning capability</li> <li>\u2717 Not a replacement for fire alarms</li> <li>\u2717 Not a primary life safety system</li> </ul>"},{"location":"scenarios/smoke-and-fire-detection/#the-business-impact-of-fire-incidents","title":"The Business Impact of Fire Incidents","text":"<p>Fire incidents create devastating impacts on businesses:</p> <ul> <li>$15 billion annual fire damage costs in U.S. industrial facilities</li> <li>3,000 workplace fires per year in manufacturing alone</li> <li>70% of businesses fail within 3 years of a major fire</li> <li>Average downtime of 3-4 months after significant fire damage</li> </ul>"},{"location":"scenarios/smoke-and-fire-detection/#beyond-traditional-fire-detection","title":"Beyond Traditional Fire Detection","text":"<p>While conventional systems wait for heat or smoke to reach sensors, VisionAI detects the earliest signs of fire:</p>"},{"location":"scenarios/smoke-and-fire-detection/#1-earlier-detection","title":"1. Earlier Detection","text":"<ul> <li>Spot smoke and fire in 30 seconds where as traditional systems take around 6 minutes</li> <li>Audio / Speaker based alerting</li> <li>Instant Text Message alerts with video verification</li> <li>Reduce response time dramatically</li> </ul>"},{"location":"scenarios/smoke-and-fire-detection/#2-comprehensive-coverage","title":"2. Comprehensive Coverage","text":"<ul> <li>Monitor high-risk areas 24/7</li> <li>Cover large spaces effectively</li> <li>Detect fires in hard-to-reach areas</li> <li>Works in all lighting conditions</li> </ul>"},{"location":"scenarios/smoke-and-fire-detection/#3-reduced-false-alarms","title":"3. Reduced False Alarms","text":"<ul> <li>AI-powered verification</li> <li>Visual confirmation of threats</li> <li>Distinguish between steam and smoke</li> <li>Minimize costly evacuations</li> </ul>"},{"location":"scenarios/smoke-and-fire-detection/#industry-applications","title":"Industry Applications","text":""},{"location":"scenarios/smoke-and-fire-detection/#manufacturing","title":"Manufacturing","text":"<ul> <li>Production line monitoring</li> <li>Equipment overheating detection</li> <li>Chemical storage areas</li> <li>Electrical panel surveillance</li> </ul>"},{"location":"scenarios/smoke-and-fire-detection/#warehousing-logistics","title":"Warehousing &amp; Logistics","text":"<ul> <li>High-rack storage monitoring</li> <li>Loading dock surveillance</li> <li>Battery charging stations</li> <li>Waste management areas</li> </ul>"},{"location":"scenarios/smoke-and-fire-detection/#industrial-processing","title":"Industrial Processing","text":"<ul> <li>Heat-intensive processes</li> <li>Combustible material storage</li> <li>Ventilation system monitoring</li> <li>Chemical processing areas</li> </ul>"},{"location":"scenarios/smoke-and-fire-detection/#commercial-facilities","title":"Commercial Facilities","text":"<ul> <li>Server rooms</li> <li>Electrical rooms</li> <li>Kitchen areas</li> <li>Waste collection points</li> </ul>"},{"location":"scenarios/smoke-and-fire-detection/#business-benefits","title":"Business Benefits","text":"<p>\u2713 Faster Response</p> <ul> <li>Up to 10 minutes earlier detection</li> <li>Precise location information</li> <li>Automated emergency protocols</li> <li>Mobile team notifications</li> </ul> <p>\u2713 Lower Costs</p> <ul> <li>Reduce insurance premiums</li> <li>Minimize false alarm costs</li> <li>Prevent major damage</li> <li>Decrease downtime</li> </ul> <p>\u2713 Better Compliance</p> <ul> <li>Meet NFPA standards</li> <li>Automated documentation</li> <li>Incident investigation support</li> <li>Risk assessment reports</li> </ul> <p>\u2713 Operational Excellence</p> <ul> <li>24/7 facility monitoring</li> <li>Multi-site management</li> <li>Integration with existing systems</li> <li>Predictive maintenance alerts</li> </ul>"},{"location":"scenarios/smoke-and-fire-detection/#learn-more","title":"Learn More","text":"<ul> <li>Quick Start</li> <li>Camera Placement Guide</li> <li>Supported Scenarios</li> <li>Camera Management</li> <li>FAQs</li> </ul>"},{"location":"scenarios/smoke-and-fire-detection/#contact-information","title":"Contact Information","text":"contact_phone Sales Inquiries <p>Get in touch with our sales team for demos and pricing information.</p> <ul> <li>Email: sales@visionify.ai</li> <li>Phone: +1 720-449-1124</li> </ul> support_agent Technical Support <p>Need help? Visit our support portal or contact our technical team.</p> <ul> <li>https://support.visionify.ai</li> <li>support@visionify.ai</li> </ul> calendar_month Schedule a Demo <p>See VisionAI in action with a personalized demo from our team.</p> event                 Book Your Demo"},{"location":"scenarios/social-distance/","title":"Social Distancing","text":"<p>Creating Safe Workplaces: Companies Implement Measures to Ensure Social Distancing in the Workplace with Vision AI.</p> <p> </p> Detection of Social distancing event"},{"location":"scenarios/social-distance/#overview","title":"Overview","text":"<p>Maintaining social distancing in workplaces and industries is crucial to prevent the spread of diseases including COVID-19 and protect the health and safety of employees or workers. </p> <p>In workplaces and industries, where employees or workers are often in close proximity to each other for extended periods, social distancing can help to reduce the spread of the virus. By keeping a safe distance from each other, employees or workers can avoid coming into contact with respiratory droplets and reduce the risk of infection.</p> <p>Overall, maintaining social distancing in workplaces and industries is an important part of a comprehensive approach to controlling the spread of certain diseases. By implementing social distancing measures and other best practices, employers can help to protect the health and safety of their employees or workers and prevent the spread of the virus.</p>"},{"location":"scenarios/social-distance/#vision-ai-based-monitoring","title":"Vision AI based monitoring","text":"<p>Vision AI based monitors can be used to push out events for different people observed in the frame and the distances between them by providing real-time video feeds of the factory area. The cameras scan every frame to ensure social distancing is well maintained.</p>"},{"location":"scenarios/social-distance/#events","title":"Events","text":"<p>VisionAI model's generated events would be: - Person distance events detected</p>"},{"location":"scenarios/social-distance/#camera-placement","title":"Camera Placement","text":"<ul> <li>Install cameras in high traffic areas, such as entrances, exits, and common areas.</li> <li>Place cameras in areas where social distancing violations are most likely to occur, such as checkout lines or waiting areas.</li> </ul>"},{"location":"scenarios/social-distance/#camera-height","title":"Camera Height","text":"<ul> <li> <p>Cameras should be installed at a height of 7-8 feet above the floor level.</p> </li> <li> <p>Place the camera 10-12 feet from the focal point.</p> </li> </ul>"},{"location":"scenarios/social-distance/#camera-angle-mounting-ranges","title":"Camera Angle Mounting Ranges","text":"<ul> <li>Place the camera at an angle that captures a wide area and any social distancing violations.</li> </ul> <p>Find more details about camera placement here.</p>"},{"location":"scenarios/social-distance/#model-details","title":"Model Details","text":""},{"location":"scenarios/social-distance/#dataset","title":"Dataset","text":"<p>The dataset for this scenario is based on real-world social distancing events. The dataset consists of images and videos collected from various sources. </p>"},{"location":"scenarios/social-distance/#model-card","title":"Model card","text":"Dataset size Version Camera support Precision Recall  mAP   6580 v1 Both(Ceiling and Straight) 89.0%  91.6%  84.0%"},{"location":"scenarios/social-distance/#scenario-details","title":"Scenario details","text":"<p>The business logic for this scenario is as follows:</p> <ul> <li>We use existing camera feeds from the premises and raise social distancing events.</li> <li>VisionAI system is able to run on edge devices. It uses camera feeds for processing.</li> <li>We detect people and the distance between them form the camera feed and raise a alert if social distancing is not maintained.</li> </ul> Test now with online Web-CamWith RTSP Camera - PipelinesWith Azure Setup <p>To test this model &amp; scenario, you can use the following steps:</p> <ul> <li> <p>Install the visionai package from PyPI</p> <pre><code>$ pip install visionai\n</code></pre> </li> <li> <p>Test the scenario from your local web-cam</p> <pre><code>$ visionai scenario test social-distancing\n\nDownloading models for scenario: social distancing\n\n\n\nStarting scenario: social distancing..\n</code></pre> </li> <li> <p>You should be able to see the events generated on your console window with the detections of social distancing within the camera field of view.</p> </li> </ul> <p>[TODO]</p> <p>VisionAI app is available at a Azure Market place, one can download and use it by following steps mentioned here</p>"},{"location":"scenarios/social-distance/#features","title":"Features","text":"<p>The VisionAI solution is the most efficient way of implementing this scenario, as evidenced by the following features:</p> <ul> <li> <p>Unmatched accuracy</p> <p>Trained and Tested to give the best results. Our systems are trained to detect social distancing with an accuracy of 99%</p> </li> <li> <p>Lightning Fast and Response Time</p> <p>Our Ultra-fast Processing provides real-time inference results and feedback (~30 frames per second processing). </p> </li> <li> <p>Minimizing false-positives/negatives</p> <p>Our systems create a fail-proof system by ensuring there are no false-positives or false-negatives. </p> </li> <li> <p>Scalability and Deployment </p> <p>Our pre-trained/custom models can be deployed instantly and are camera independent which means they can be pre-installed with existing cameras on site. We also offer cameras, IoT sensors and edge devices with strategic placement that helps scale a large workplace area with minimum installations. </p> </li> <li> <p>Custom Integrations</p> <p>Our detection system can be integrated with other safety systems, such as building management systems or alarm systems, allowing for a coordinated response to emergencies.</p> </li> </ul>"},{"location":"scenarios/social-distance/#training-with-custom-data","title":"Training with custom data","text":"<p>The scenario is provided as part of our GPL-v3 package for VisionAI. If you wish to train this with custom datasets, please contact us and we can provide you with the training code. You can do custom training with your own datasets for free, as long as it complies with GPLv3 license (you give back the code to the community). If you are interested in a custom license, please contact us.</p>"},{"location":"scenarios/social-distance/#contact-us","title":"Contact Us","text":"<ul> <li>For technical issues, you can open a Github issue here.</li> <li>For business inquiries, you can contact us through our website.</li> </ul>"},{"location":"scenarios/solicitation/","title":"Solicitation Detection","text":"<p>A smarter way to unveil solicitation</p> <p> </p> Detection of Solicitation detection event"},{"location":"scenarios/solicitation/#overview","title":"Overview","text":"<p>Solicitation is the act of requesting or offering something in return for a favor, service, or product. In industries, Solicitation can take various forms, for example, employees soliciting other employees for money in exchange for job-related favors, any outsiders approaching factory employees or workers for different purposes like obtaining confidential information, for employment etc. Solicitation can also occur in public places, including malls, hotels, casinos, public transportation, clubs, etc. However, solicitation is often prohibited in these areas due to some specific rules and regulations depending upon the location and jurisdiction. </p> <p>To maintain a safe work environment, sustain an organization\u2019s values and prevent unethical behaviors within the companies and in public spaces, it is important to detect solicitation, take appropriate measures to address such behaviors and prevent it from happening. Computer Vision solutions can help effectively detect acts of solicitation before they occur.</p>"},{"location":"scenarios/solicitation/#vision-ai-based-monitoring","title":"Vision AI based monitoring","text":"<p>Implement VisionAI solution to address the problems associated with Solicitation by timely detection of any unethical behaviors in public spaces or companies. Our AI and deep learning-based solution can identify behavioral anomalies that may indicate solicitation.    </p> <p>Our smart solution seamlessly integrates with the existing camera infrastructure and analyzes the real-time video feed. It can help in different ways and offers a comprehensive solution for Solicitation;</p> <ul> <li>Facial recognition technology can help identify individuals involved in solicitation activities</li> <li>The algorithm can also analyze patterns of behaviors associated with solicitation, such as loitering or approaching strangers</li> <li>The algorithm also detects objects generally related to solicitation, like signs, posters, and flyers</li> <li>The algorithm can identify any unusual or suspicious behaviors in public spaces that indicate solicitation and help security and law enforcement personnel to respond more quickly to potential issues </li> </ul>"},{"location":"scenarios/solicitation/#model-details","title":"Model Details","text":""},{"location":"scenarios/solicitation/#dataset","title":"Dataset","text":"<p>The dataset consists of images and videos in large numbers collected from diverse sources and is designed to reflect real-world scenarios. The dataset is representative of all types of people from different ages, genders and backgrounds engaging in solicitation behavior. Also, it includes all settings, situations and different types of solicitation behavior, such as advertising or sales pitches. It is evenly distributed with;</p> <ul> <li> <p>Different locations - in public places, there are various locations where solicitation can take place, like walkways, public parks, parking lots, public transportation hubs, malls, clubs, hotels, casinos, and retail environments.</p> </li> <li> <p>Different angles and perspectives - The dataset includes images or videos captured from different angles and lighting conditions to ensure that the model can detect solicitation behavior in various real-world scenarios.</p> </li> <li> <p>Different versions - The dataset undertakes different types of solicitation to ensure the model is robust enough and can generalize well to any new situation.</p> </li> </ul>"},{"location":"scenarios/solicitation/#model-card","title":"Model card","text":"Dataset size Version Camera support Precision Recall  mAP   4810 v1 Both(Ceiling and Straight) 92.0%  91.6%  88.0%"},{"location":"scenarios/solicitation/#scenario-details","title":"Scenario details","text":"<p>Our VisionAI solution for solicitation detection works in different scenarios to detect any unethical behavior indicating solicitation within an industrial setting or in public spaces. The model is equipped to detect the following;</p> <ul> <li>Identify through facial recognition: known solicitors</li> <li>Identify a single person going and talking to multiple people</li> <li>Identify and track scantily clad persons and whether they are talking to people</li> <li>Identify similar patterns like one person repeating the same type of behavior</li> </ul> Test now with online Web-CamWith RTSP Camera - PipelinesWith Azure Setup <p>To test this model &amp; scenario, you can use the following steps:</p> <ul> <li> <p>Install the visionai package from PyPI</p> <pre><code>$ pip install visionai\n</code></pre> </li> <li> <p>Test the scenario from your local web-cam</p> <pre><code>$ visionai scenario test solicitation-detection\n\nDownloading models for scenario: solicitation-detection\nModel: solicitation-detection: https://workplaceos.blob.core.windows.net/models/yolov5s-solicitation-detection/yolov5s-solicitation-detection-0.0.1.zip\n\n\nStarting scenario: solicitation-detection..\n</code></pre> </li> <li> <p>You should be able to see the events generated on your console window with the detections of light sensor monitoring within the camera field of view.</p> </li> </ul> <p>[TODO]</p> <p>VisionAI app is available at a Azure Market place, one can download and use it by following steps mentioned here</p>"},{"location":"scenarios/solicitation/#features","title":"Features","text":"<ul> <li> <p>Real-time monitoring: The model can be deployed in real-time to monitor the public spaces and industrial settings for any unethical behavior indicating solicitation.</p> </li> <li> <p>Easy to deploy: The solution can be deployed easily with minimal effort and can be integrated with the existing camera infrastructure.</p> </li> <li> <p>Customizable: The solution can be customized to meet the specific requirements of the organization.</p> </li> </ul>"},{"location":"scenarios/solicitation/#training-with-custom-data","title":"Training with custom data","text":"<p>The scenario is provided as part of our GPL-v3 package for VisionAI. If you wish to train this with custom datasets, please contact us and we can provide you with the training code. You can do custom training with your own datasets for free, as long as it complies with GPLv3 license (you give back the code to the community). If you are interested in a custom license, please contact us.</p>"},{"location":"scenarios/solicitation/#contact-us","title":"Contact Us","text":"<ul> <li>For technical issues, you can open a Github issue here.</li> <li>For business inquiries, you can contact us through our website.</li> </ul>"},{"location":"scenarios/solicitation/#learn-more","title":"Learn More","text":"<ul> <li>Quick Start</li> <li>Camera Placement Guide</li> <li>Supported Scenarios</li> <li>Camera Management</li> <li>FAQs</li> </ul>"},{"location":"scenarios/solicitation/#contact-information","title":"Contact Information","text":"contact_phone Sales Inquiries <p>Get in touch with our sales team for demos and pricing information.</p> <ul> <li>Email: sales@visionify.ai</li> <li>Phone: +1 720-449-1124</li> </ul> support_agent Technical Support <p>Need help? Visit our support portal or contact our technical team.</p> <ul> <li>https://support.visionify.ai</li> <li>support@visionify.ai</li> </ul> calendar_month Schedule a Demo <p>See VisionAI in action with a personalized demo from our team.</p> event                 Book Your Demo"},{"location":"scenarios/spills-and-leaks-hazard/","title":"Spills &amp; Leaks detection","text":"<p>Spills and Leaks detection through Vision AI.</p>"},{"location":"scenarios/spills-and-leaks-hazard/#overview","title":"Overview","text":"<p>Spills and leaks in industries can have significant health impacts on both humans and wildlife. The severity of the health impact depends on the type of substance that is spilled or leaked, the duration and extent of the exposure, and the vulnerability of the exposed population. Some potential health impacts of spills and leaks are Respiratory problems, skin irritation, Neurological effects, Cancer, Reproductive problems and Environmental impact.</p> <p>Preventing and mitigating spills and leaks is crucial for protecting the environment and human health. Existing solitions could be regular inspections and maintenance of equipment. Manual inspection is not foolproof and can be prone to errors and oversights. Human inspectors may miss small leaks or spills that may go undetected until they become larger and more severe.</p>"},{"location":"scenarios/spills-and-leaks-hazard/#vision-ai-based-monitoring","title":"Vision AI based monitoring","text":"<p>Manual inspections can be time-consuming and labor-intensive, which can make them impractical for large or complex industrial facilities.</p> <p>Vision AI-based model is designed to detect spills and leaks including water puddles, water leaks and slippery surfaces. The model can analyze images and video footage to identify visual anomalies, such as the appearance of a spill or leak, which can be missed by human inspectors.</p> Oil leak Water leak in pipes"},{"location":"scenarios/spills-and-leaks-hazard/#events","title":"Events","text":"<p>VisionAI model's generated events would be:</p> <ul> <li>Water puddle detected</li> <li>Water leak from equipment detected</li> <li>Spill event detected</li> <li>Slippery sign detected</li> </ul>"},{"location":"scenarios/spills-and-leaks-hazard/#model-details","title":"Model Details","text":""},{"location":"scenarios/spills-and-leaks-hazard/#dataset","title":"Dataset","text":"<p>Dataset for spills/leakages is properly curated and validated to ensure that the models are accurate and reliable. </p> <p>Some of the sources used to take images are:</p> <ul> <li>CAMEO Chemicals dataset</li> <li>The NOAA Hazardous Material Incident database</li> <li> <p>The Oil Spill Dataset</p> </li> <li> <p>The Pipeline and Hazardous Materials Safety Administration (PHMSA) dataset</p> </li> <li> <p>The Spill Impact Mitigation Assessment (SIMA) dataset</p> </li> </ul>"},{"location":"scenarios/spills-and-leaks-hazard/#model-card","title":"Model card","text":"Dataset size Version Camera support Precision Recall  mAP   4170 v1 Both(Ceiling and Straight) 85.0%  91.6%  87.0%"},{"location":"scenarios/spills-and-leaks-hazard/#scenario-details","title":"Scenario details","text":"<p>The business logic for this scenario is as follows: </p> <ul> <li>We use existing camera feeds from the premises to monitor the signs of leakage, spills in the workplace to ensure the safety of human lives in the workplace. </li> <li>VisionAI system is able to run on edge devices. It uses camera feeds for processing. </li> <li>We detect any kind of leakage in the camera feed.</li> <li>An alarming system is inplace as part of solution.</li> </ul> Test now with online Web-CamWith RTSP Camera - PipelinesWith Azure Setup <p>To test this model &amp; scenario, you can use the following steps:</p> <ul> <li> <p>Install the visionai package from PyPI</p> <pre><code>$ pip install visionai\n</code></pre> </li> <li> <p>Test the scenario from your local web-cam</p> <pre><code>$ visionai scenario test no-leak-detection\n\nDownloading models for scenario: no-smoking-detection\nModel: no-leak-detection: https://workplaceos.blob.core.windows.net/models/yolov5s-people/yolov5s-people-0.0.4.zip\n\n\nStarting scenario: no-leak-detection..\n</code></pre> </li> <li> <p>You should be able to see the events generated on your console window with the detections of spills and leak within the camera field of view.</p> </li> </ul> <p>[TODO]</p> <p>VisionAI app is available at a Azure Market place, one can download and use it by following steps mentioned here</p>"},{"location":"scenarios/spills-and-leaks-hazard/#features","title":"Features","text":"<p>VisionAI's Spill and leak detection  identifies and classifies spills and leaks in real-time. Here are some features of spill and leak detection:</p> <ul> <li> <p>Real-time monitoring: AI-based spill and leak detection systems can continuously monitor facilities and pipelines in real-time, allowing for quick detection and response times.</p> </li> <li> <p>Automated detection and alerts: AI-based systems can detect spills and leaks automatically and issue alerts to relevant personnel or systems, allowing for quick response and mitigation of the issue.</p> </li> <li> <p>Increased accuracy and reliability: VisionAI models can analyze large amounts of data quickly and accurately, allowing for the identification of even small leaks or spills that may be missed by human inspectors.</p> </li> <li> <p>Integration with other systems: VisionAI solution can be integrated with other systems such as alarm systems and spill response plans, allowing for a more comprehensive and effective response to spills and leaks.</p> </li> <li> <p>Predictive analytics: VisionAI models  can analyze historical data and patterns to identify potential risks and prevent future spills and leaks.</p> </li> <li> <p>Remote monitoring:  The system allows continuous monitoring of facilities and pipelines in remote or hard-to-reach areas.</p> </li> </ul> <p>Note</p> <p>Overall, spill and leak detection using our VisionAI's solution provides a powerful tool for industries to improve the accuracy, speed, and efficiency of spill and leak detection and response. The use of AI can also help to reduce the risk of human exposure to hazardous materials and prevent environmental damage caused by spills and leaks.</p>"},{"location":"scenarios/spills-and-leaks-hazard/#training-with-custom-data","title":"Training with custom data","text":"<p>The scenario is provided as part of our GPL-v3 package for VisionAI. If you wish to train this with custom datasets, please contact us and we can provide you with the training code. You can do custom training with your own datasets for free, as long as it complies with GPLv3 license (you give back the code to the community). If you are interested in a custom license, please (contact us)[contact.md].</p>"},{"location":"scenarios/spills-and-leaks-hazard/#learn-more","title":"Learn More","text":"<ul> <li>Quick Start</li> <li>Camera Placement Guide</li> <li>Supported Scenarios</li> <li>Camera Management</li> <li>FAQs</li> </ul>"},{"location":"scenarios/spills-and-leaks-hazard/#contact-information","title":"Contact Information","text":"contact_phone Sales Inquiries <p>Get in touch with our sales team for demos and pricing information.</p> <ul> <li>Email: sales@visionify.ai</li> <li>Phone: +1 720-449-1124</li> </ul> support_agent Technical Support <p>Need help? Visit our support portal or contact our technical team.</p> <ul> <li>https://support.visionify.ai</li> <li>support@visionify.ai</li> </ul> calendar_month Schedule a Demo <p>See VisionAI in action with a personalized demo from our team.</p> event                 Book Your Demo"},{"location":"scenarios/spills-and-leaks/","title":"Spills &amp; Leaks detection","text":"<p>Spills and Leaks detection through Vision AI.</p>"},{"location":"scenarios/spills-and-leaks/#overview","title":"Overview","text":"<p>Spills and leaks in industries can have significant health impacts on both humans and wildlife. The severity of the health impact depends on the type of substance that is spilled or leaked, the duration and extent of the exposure, and the vulnerability of the exposed population. Some potential health impacts of spills and leaks are Respiratory problems, skin irritation, Neurological effects, Cancer, Reproductive problems and Environmental impact.</p> <p>Preventing and mitigating spills and leaks is crucial for protecting the environment and human health. Existing solitions could be regular inspections and maintenance of equipment. Manual inspection is not foolproof and can be prone to errors and oversights. Human inspectors may miss small leaks or spills that may go undetected until they become larger and more severe.</p>"},{"location":"scenarios/spills-and-leaks/#vision-ai-based-monitoring","title":"Vision AI based monitoring","text":"<p>Manual inspections can be time-consuming and labor-intensive, which can make them impractical for large or complex industrial facilities.</p> <p>Vision AI-based model is designed to detect spills and leaks including water puddles, water leaks and slippery surfaces. The model can analyze images and video footage to identify visual anomalies, such as the appearance of a spill or leak, which can be missed by human inspectors.</p> Oil leak Water leak in pipes"},{"location":"scenarios/spills-and-leaks/#events","title":"Events","text":"<p>VisionAI model's generated events would be:</p> <ul> <li>Water puddle detected</li> <li>Water leak from equipment detected</li> <li>Spill event detected</li> <li>Slippery sign detected</li> </ul>"},{"location":"scenarios/spills-and-leaks/#model-details","title":"Model Details","text":""},{"location":"scenarios/spills-and-leaks/#dataset","title":"Dataset","text":"<p>Dataset for spills/leakages is properly curated and validated to ensure that the models are accurate and reliable. </p> <p>Some of the sources used to take images are:</p> <ul> <li>CAMEO Chemicals dataset</li> <li>The NOAA Hazardous Material Incident database</li> <li> <p>The Oil Spill Dataset</p> </li> <li> <p>The Pipeline and Hazardous Materials Safety Administration (PHMSA) dataset</p> </li> <li> <p>The Spill Impact Mitigation Assessment (SIMA) dataset</p> </li> </ul>"},{"location":"scenarios/spills-and-leaks/#model-card","title":"Model card","text":"Dataset size Version Camera support Precision Recall  mAP   4170 v1 Both(Ceiling and Straight) 85.0%  91.6%  87.0%"},{"location":"scenarios/spills-and-leaks/#scenario-details","title":"Scenario details","text":"<p>The business logic for this scenario is as follows: </p> <ul> <li>We use existing camera feeds from the premises to monitor the signs of leakage, spills in the workplace to ensure the safety of human lives in the workplace. </li> <li>VisionAI system is able to run on edge devices. It uses camera feeds for processing. </li> <li>We detect any kind of leakage in the camera feed.</li> <li>An alarming system is inplace as part of solution.</li> </ul> Test now with online Web-CamWith RTSP Camera - PipelinesWith Azure Setup <p>To test this model &amp; scenario, you can use the following steps:</p> <ul> <li> <p>Install the visionai package from PyPI</p> <pre><code>$ pip install visionai\n</code></pre> </li> <li> <p>Test the scenario from your local web-cam</p> <pre><code>$ visionai scenario test no-leak-detection\n\nDownloading models for scenario: no-smoking-detection\nModel: no-leak-detection: https://workplaceos.blob.core.windows.net/models/yolov5s-people/yolov5s-people-0.0.4.zip\n\n\nStarting scenario: no-leak-detection..\n</code></pre> </li> <li> <p>You should be able to see the events generated on your console window with the detections of spills and leak within the camera field of view.</p> </li> </ul> <p>[TODO]</p> <p>VisionAI app is available at a Azure Market place, one can download and use it by following steps mentioned here</p>"},{"location":"scenarios/spills-and-leaks/#features","title":"Features","text":"<p>VisionAI's Spill and leak detection  identifies and classifies spills and leaks in real-time. Here are some features of spill and leak detection:</p> <ul> <li> <p>Real-time monitoring: AI-based spill and leak detection systems can continuously monitor facilities and pipelines in real-time, allowing for quick detection and response times.</p> </li> <li> <p>Automated detection and alerts: AI-based systems can detect spills and leaks automatically and issue alerts to relevant personnel or systems, allowing for quick response and mitigation of the issue.</p> </li> <li> <p>Increased accuracy and reliability: VisionAI models can analyze large amounts of data quickly and accurately, allowing for the identification of even small leaks or spills that may be missed by human inspectors.</p> </li> <li> <p>Integration with other systems: VisionAI solution can be integrated with other systems such as alarm systems and spill response plans, allowing for a more comprehensive and effective response to spills and leaks.</p> </li> <li> <p>Predictive analytics: VisionAI models  can analyze historical data and patterns to identify potential risks and prevent future spills and leaks.</p> </li> <li> <p>Remote monitoring:  The system allows continuous monitoring of facilities and pipelines in remote or hard-to-reach areas.</p> </li> </ul> <p>Note</p> <p>Overall, spill and leak detection using our VisionAI's solution provides a powerful tool for industries to improve the accuracy, speed, and efficiency of spill and leak detection and response. The use of AI can also help to reduce the risk of human exposure to hazardous materials and prevent environmental damage caused by spills and leaks.</p>"},{"location":"scenarios/spills-and-leaks/#training-with-custom-data","title":"Training with custom data","text":"<p>The scenario is provided as part of our GPL-v3 package for VisionAI. If you wish to train this with custom datasets, please contact us and we can provide you with the training code. You can do custom training with your own datasets for free, as long as it complies with GPLv3 license (you give back the code to the community). If you are interested in a custom license, please (contact us)[contact.md].</p>"},{"location":"scenarios/spills-and-leaks/#learn-more","title":"Learn More","text":"<ul> <li>Quick Start</li> <li>Camera Placement Guide</li> <li>Supported Scenarios</li> <li>Camera Management</li> <li>FAQs</li> </ul>"},{"location":"scenarios/spills-and-leaks/#contact-information","title":"Contact Information","text":"contact_phone Sales Inquiries <p>Get in touch with our sales team for demos and pricing information.</p> <ul> <li>Email: sales@visionify.ai</li> <li>Phone: +1 720-449-1124</li> </ul> support_agent Technical Support <p>Need help? Visit our support portal or contact our technical team.</p> <ul> <li>https://support.visionify.ai</li> <li>support@visionify.ai</li> </ul> calendar_month Schedule a Demo <p>See VisionAI in action with a personalized demo from our team.</p> event                 Book Your Demo"},{"location":"scenarios/staircase-safety/","title":"Staircase Safety","text":"<p>Slips &amp; Falls from stairs are one of the most common workplace accidents.</p> <p>Staircase Safety</p> <p>Visionify's Staircase Safety Suite focuses on preventing accidents and injuries in one of the most common yet hazardous areas of any facility - staircases. This suite monitors various unsafe behaviors including failure to use handrails, running on stairs, using mobile phones while climbing/descending, and skipping steps. These behaviors are leading causes of workplace accidents, often resulting in serious injuries.</p> <p>By identifying these risky behaviors in real-time, organizations can take proactive measures to prevent staircase-related incidents. The suite helps safety managers enforce proper staircase usage protocols and create awareness about safe staircase practices among employees.</p>"},{"location":"scenarios/staircase-safety/#staircase-safety-features","title":"Staircase Safety Features","text":"Key Detection Capabilities <ul> <li>Running on stairs</li> <li>Skipping stairs</li> <li>Not holding bannister</li> <li>Mobile phone usage on stairs</li> </ul> Real-Time Announcements <p>When a violation is detected, real-time speaker announcements are made to alert the individual. We support integration with Hikvision and Axis IP speakers.</p> Proactive Safety Changes <p>This proactive approach helps in bringing about safety changes and reducing the risk of staircase-related incidents.</p> <p>Table: Staircase Safety Events and Detection Details</p> Scenario name Supported? Event Event Details More Info Staircase Safety \u2705 <code>No Bannister Usage</code> Person not holding handrail while using stairs More details \u2705 <code>Running on Stairs</code> Person running on staircase \u2705 <code>Phone Usage on Stairs</code> Person using mobile phone while on stairs \u2705 <code>Skipping Steps</code> Person skipping steps while using stairs"},{"location":"scenarios/staircase-safety/#learn-more","title":"Learn More","text":"<ul> <li>Quick Start</li> <li>Camera Placement Guide</li> <li>Supported Scenarios</li> <li>Camera Management</li> <li>FAQs</li> </ul>"},{"location":"scenarios/staircase-safety/#contact-information","title":"Contact Information","text":"contact_phone Sales Inquiries <p>Get in touch with our sales team for demos and pricing information.</p> <ul> <li>Email: sales@visionify.ai</li> <li>Phone: +1 720-449-1124</li> </ul> support_agent Technical Support <p>Need help? Visit our support portal or contact our technical team.</p> <ul> <li>https://support.visionify.ai</li> <li>support@visionify.ai</li> </ul> calendar_month Schedule a Demo <p>See VisionAI in action with a personalized demo from our team.</p> event                 Book Your Demo"},{"location":"scenarios/station-occupancy/","title":"Station Occupancy","text":"<p>Revolutionize your workspace with our Smart Desk Occupancy Tracker.</p>"},{"location":"scenarios/station-occupancy/#overview","title":"Overview","text":"<p>Tracking Workplace Metrics is key for identifying problems and driving growth. One such metric that organizations need to keep tabs on is desk occupancy. Tracking Desk Occupancy provides multiple valuable insights like worker productivity, worker behavioral analysis, floor planning, and utilization of space, all of which are required for workspace optimization and efficient resource management.</p> <p>Despite the increasing adoption of desk occupancy measurement across industries, present systems utilized to measure desk occupancy are fraught with several limitations, exhibit limited accuracy, lack the ability to provide multiple metrics, and can incur substantial installation costs.</p>"},{"location":"scenarios/station-occupancy/#vision-ai-based-monitoring","title":"Vision AI based monitoring","text":"<p>Introducing our fully automated Vision AI system for monitoring Desk Occupancy. Our next-gen AI models detect and count the presence of people within a specific area, whether they are performing a particular task or not, their dwell time, occupancy density and many more metrics. </p> <p>Our robust occupancy monitoring systems offer higher accuracy compared to current solutions, are cost-effective, and are capable of seamlessly integrating with existing cameras and infrastructure. With our system, there's no need to install multiple sensors or measurement devices, as a single camera can cover a wide area and enable users to easily leverage our AI-based real-time detection with minimal effort.</p> <p> </p> monitoring desk occupancy"},{"location":"scenarios/station-occupancy/#events","title":"Events","text":"<p>VisionAI model's generated events would be:</p> <ul> <li>Daily summary of occupancy metrics on a per desk/station basis</li> </ul> <p>It is recommended that any instance of an absence of a person from his/her desk be reported to the appropriate authority. An event data for desk occupancy scenario may include information such as:</p> <ul> <li>Date and time of the event</li> <li>Location of the event</li> </ul>"},{"location":"scenarios/station-occupancy/#model-details","title":"Model Details","text":""},{"location":"scenarios/station-occupancy/#dataset","title":"Dataset","text":"<p>The dataset consists of images and videos collected from diverse sources and is designed to reflect real-world scenarios. It is evenly distributed with:</p> <ul> <li> <p>Positive images: The dataset includes images that contain people sitting at desks. These images should show a clear view of the desk and the person occupying it.</p> </li> <li> <p>Negative images: The dataset includes images that do not contain people sitting at desks. They could show empty desks or other objects in the workspace.</p> </li> <li> <p>Images with occlusions: The dataset includes images where the view of the person occupying the desk is partially obstructed, for example, by another object or person.</p> </li> <li> <p>Images with different lighting conditions: The dataset includes images that are taken under different lighting conditions, such as bright daylight, low-light, or artificial light.</p> </li> <li> <p>Images with different camera angles: The dataset includes images that are taken from different camera angles, such as top-down, side view, or angled view.</p> </li> <li> <p>Images with different desk layouts: The dataset includes images that show different types of desks, such as standing desks, shared desks, or cubicles.</p> </li> </ul>"},{"location":"scenarios/station-occupancy/#model-card","title":"Model card","text":"Dataset size Version Camera support Precision Recall  mAP   1280 v1 Ceiling 95.0%  91.6%  88.0%"},{"location":"scenarios/station-occupancy/#scenario-details","title":"Scenario details","text":"<p>Real-time detection and alerts for different scenarios includes but are not limited to:</p> <ul> <li>When a person sits down at a desk that was previously unoccupied, the model can detect the change in occupancy.</li> <li>When a person gets up from a desk, the model can detect that the desk is now unoccupied.</li> <li>If the model detects an object on the desk that obstructs the view of the person occupying it, it may not be able to detect occupancy until the obstruction is removed.</li> <li>If the lighting conditions in the room change, the model may need to adjust its settings to continue accurately detecting occupancy.</li> <li>The model can also detect occupancy in real-time as people move around the workspace, allowing it to track changes in occupancy throughout the day.</li> </ul> Test now with online Web-CamWith RTSP Camera - PipelinesWith Azure Setup <p>To test this model &amp; scenario, you can use the following steps:</p> <ul> <li> <p>Install the visionai package from PyPI</p> <pre><code>$ pip install visionai\n</code></pre> </li> <li> <p>Test the scenario from your local web-cam</p> <pre><code>$ visionai scenario test desk-occupancy\n</code></pre> <p>Downloading models for scenario: desk-occupancy Model: miss-fire-exting-detection: https://workplaceos.blob.core.windows.net/models/yolov5s-people/yolov5s-people-0.0.4.zip</p> <p>Starting scenario: desk-occupancy..</p> <p>```</p> </li> <li> <p>You should be able to see the events generated on your console window with the detections of desk occupancy within the camera field of view.</p> </li> </ul> <p>[TODO]</p> <p>VisionAI app is available at a Azure Market place, one can download and use it by following steps mentioned here</p>"},{"location":"scenarios/station-occupancy/#features","title":"Features","text":"<p>Some potential features of VisionAI for monitoring desk occupancy could include:</p> <ul> <li> <p>Object Detection: This feature can help to monitor the occupancy of the desks and alert if a desk is occupied or not.</p> <ul> <li> <p>Heat Map: This feature can help to optimize the usage of the workspace and identify hotspots where there may be congestion.</p> </li> <li> <p>Occupancy Monitoring: This feature can help to optimize the usage of the workspace and ensure that all desks are being used efficiently.</p> </li> <li> <p>Desk Usage Patterns: This feature can help to optimize the usage of the workspace and identify areas that need improvement.</p> </li> <li> <p>Desk Reservation: This feature can help to optimize the usage of the workspace and ensure that all desks are being used efficiently.</p> </li> </ul> </li> </ul>"},{"location":"scenarios/station-occupancy/#training-with-custom-data","title":"Training with custom data","text":"<p>The scenario is provided as part of our GPL-v3 package for VisionAI. If you wish to train this with custom datasets, please contact us and we can provide you with the training code. You can do custom training with your own datasets for free, as long as it complies with GPLv3 license (you give back the code to the community). If you are interested in a custom license, please contact us.</p>"},{"location":"scenarios/station-occupancy/#contact-us","title":"Contact Us","text":"<ul> <li>For technical issues, you can open a Github issue here.</li> <li>For business inquiries, you can contact us through our website.</li> </ul>"},{"location":"scenarios/suspicious-activity/","title":"Suspicious Activity","text":""},{"location":"scenarios/suspicious-activity/#overview","title":"Overview","text":"<p>Suspicious activity detection refers to the process of identifying behavior or actions that deviate from the norm or expected patterns, and may indicate potential threats or risks. </p> <p>In security, suspicious activity detection can help identify potential threats or breaches in systems, networks, or physical environments. This can involve monitoring of access logs, network traffic, user behavior, or physical activity using video surveillance or other sensors.</p> <p>What\u2019s included in this suite:</p> <ul> <li>Vandalism &amp; property destruction</li> <li>Firearms &amp; knives</li> </ul>"},{"location":"scenarios/suspicious-package-detection/","title":"Suspicious Package Detection","text":"<p>Reliable and accurate Suspicious package detection for a safe and secure workplace environment</p> <p> </p> Detection of Suspicious Package event"},{"location":"scenarios/suspicious-package-detection/#overview","title":"Overview","text":"<p>Manual inspection of every package or parcel is time-consuming and can lead to delays in delivering important items. An automated detection model can quickly screen packages and prioritize those that require additional inspection. By detecting suspicious packages early, it may be possible to prevent an incident from occurring. This can save lives and minimize damage to property.</p> <p>Suspicious packages could contain hazardous materials such as explosives or chemicals, which could pose a significant risk to the safety of employees and the public. A detection model can quickly identify potential threats and allow for timely evacuation or other appropriate actions.</p> <p>Implementing a suspicious package detection model can enhance workplace safety and security, improve operational efficiency, and ensure compliance with legal requirements.</p>"},{"location":"scenarios/suspicious-package-detection/#vision-ai-based-monitoring","title":"Vision AI based monitoring","text":"<p>VisionAI suspicious package detection model is trained on a large dataset of known suspicious packages, as well as non-suspicious packages, to learn to recognize the characteristics that are most indicative of a threat.  VisionAI based suspicious package monitoring can be used to analyze new packages and determine whether they are suspicious or not. If a package is flagged as suspicious, security personnel can be alerted to investigate further and take appropriate action.</p>"},{"location":"scenarios/suspicious-package-detection/#model-details","title":"Model Details","text":""},{"location":"scenarios/suspicious-package-detection/#dataset","title":"Dataset","text":"<p>The dataset for this type of model typically consists of a large number of images or videos, captured from a variety of angles and under different lighting conditions. The images or videos may be collected from surveillance cameras or from other sources, such as social media posts or news reports.</p> <p>To ensure that the model is able to generalize to new and unseen images or videos, the dataset should include a diverse range of packages, with different sizes, shapes, colors, and markings. The dataset should also include examples of packages that are not suspicious or abandoned, in order to provide a balanced training set.</p>"},{"location":"scenarios/suspicious-package-detection/#model-card","title":"Model card","text":"Dataset size Version Camera support Precision Recall  mAP   7810 v1 Both(Ceiling and Straight) 95.0%  91.6%  88.0%"},{"location":"scenarios/suspicious-package-detection/#scenario-details","title":"Scenario details","text":"<p>The business logic for this scenario is as follows:</p> <ul> <li>We use existing camera feeds from the premises to monitor suspicious packages within the camera field of view.</li> <li>The model is able to detect suspicious packages and an alert system is in place to notify the appropriate authorities in the event that a suspicious package is detected. It is designed to minimize false alarms and provide timely and accurate information.</li> </ul> Test now with online Web-CamWith RTSP Camera - PipelinesWith Azure Setup <p>To test this model &amp; scenario, you can use the following steps:</p> <ul> <li> <p>Install the visionai package from PyPI</p> <pre><code>$ pip install visionai\n</code></pre> </li> <li> <p>Test the scenario from your local web-cam</p> <pre><code>$ visionai scenario test suspicious-package-detection\n\nDownloading models for scenario: suspicious-package-detection\nModel: suspicious-package-detection: https://workplaceos.blob.core.windows.net/models/yolov5s-suspicious-package-detection/yolov5s-suspicious-package-detection-0.0.1.zip\n\n\nStarting scenario: suspicious-package-detection..\n</code></pre> </li> <li> <p>You should be able to see the events generated on your console window with the detections of aggressive behavior within the camera field of view.</p> </li> </ul> <p>[TODO]</p> <p>VisionAI app is available at a Azure Market place, one can download and use it by following steps mentioned here</p>"},{"location":"scenarios/suspicious-package-detection/#features","title":"Features","text":"<ul> <li> <p>Real-time monitoring: The model is able to analyze data in real-time to detect potential suspicious packages.</p> </li> <li> <p>Integration with other systems: The model is able to integrate with other security systems, such as access control systems, to provide a comprehensive approach to package security.</p> </li> <li> <p>Alert system: The model is having an alert system that can notify the appropriate authorities in the event that a suspicious package is detected. It is designed to minimize false alarms and provide timely and accurate information.</p> </li> </ul>"},{"location":"scenarios/suspicious-package-detection/#training-with-custom-data","title":"Training with custom data","text":"<p>The scenario is provided as part of our GPL-v3 package for VisionAI. If you wish to train this with custom datasets, please contact us and we can provide you with the training code. You can do custom training with your own datasets for free, as long as it complies with GPLv3 license (you give back the code to the community). If you are interested in a custom license, please contact us.</p>"},{"location":"scenarios/suspicious-package-detection/#contact-us","title":"Contact Us","text":"<ul> <li>For technical issues, you can open a Github issue here.</li> <li>For business inquiries, you can contact us through our website.</li> </ul>"},{"location":"scenarios/theft/","title":"Shoplifting or Theft Detection","text":"<p>Ensure prevention of Shoplifting, employee theft, minimize insurance loss and other related damages across the retail sector.</p> <p> </p> Detection of shoplifting or theft event"},{"location":"scenarios/theft/#overview","title":"Overview","text":"<p>Typically considered one of the most accessible and in many cases least-sophisticated types of crime, shoplifting persists as an undeniably damaging affliction across the retail sector. In fact, the National Retail Security Survey reported that loss of inventory cost U.S. retailers an estimated $49 billion USD in 2016, with 70 percent of the loss caused by employee theft and shoplifting.</p> <p>Theft or shoplifting detection models can provide businesses with a proactive approach to preventing losses due to theft or shoplifting, promoting employee safety, complying with legal requirements, and deterring potential offenders.</p> <p>There are several reasons why theft or shoplifting detection models are necessary at workplaces:</p> <ul> <li> <p>Loss prevention: Theft or shoplifting can result in significant financial losses for businesses. By implementing theft or shoplifting detection models, businesses can identify and prevent such losses.</p> </li> <li> <p>Employee safety: Theft or shoplifting incidents can also put employees at risk, especially if they attempt to intervene. Detection models can provide a safer way to monitor and prevent such incidents.</p> </li> <li> <p>Legal compliance: Some industries are required by law to implement security measures to prevent theft or shoplifting. Implementing a detection model can help businesses comply with these regulations.</p> </li> <li> <p>Deterrent effect: The presence of a theft or shoplifting detection model can act as a deterrent to potential offenders, reducing the likelihood of theft or shoplifting incidents.</p> </li> </ul>"},{"location":"scenarios/theft/#visionai-based-monitoring","title":"VisionAI Based Monitoring","text":"<p>Theft or shoplifting detection using our solution can prove to be an important application in retail settings, as it can help to prevent loss and increase security. </p> <p>To detect theft or shoplifting our model is trained on a dataset of video footage with labeled instances of theft or shoplifting. The state-of-the-art model is then learned, to recognize patterns in the video data that are associated with suspicious behavior, such as loitering near a display or concealing merchandise in a bag or pocket.</p> <p>Our trained model can be used to analyze live video footage from surveillance cameras in real-time. The system can alert security personnel or trigger an alarm when it detects suspicious behavior, allowing them to intervene and prevent the theft or shoplifting from occurring. Our systems for theft or shoplifting detection uses various techniques, such as object detection, tracking, and activity recognition. These techniques can be combined to create a more robust and accurate system.</p>"},{"location":"scenarios/theft/#model-card","title":"Model card","text":"Dataset size Version Camera support Precision Recall  mAP   1280 v1 Both(Ceiling and Straight) 95.0%  91.6%  88.0%"},{"location":"scenarios/theft/#contact-us","title":"Contact Us","text":"<ul> <li>For technical issues, you can open a Github issue here.</li> <li>For business inquiries, you can contact us through our website.</li> </ul>"},{"location":"scenarios/vandalism/","title":"Vandalism and property destruction","text":"<p>Safeguard your assets with our advanced vandalism detection model.</p> <p>Vandalism/Graffiti detection event</p>"},{"location":"scenarios/vandalism/#overview","title":"Overview","text":"<p>Vandalism and property destruction can have serious consequences, both for individuals and for society as a whole. For example, it can lead to physical harm, emotional distress, financial losses, and damage to public infrastructure. By developing a model that can accurately detect and predict incidents of vandalism and property destruction, we can take proactive measures to prevent them from occurring or minimize their impact if they do occur. This can include increasing surveillance, enhancing security measures, and improving emergency response protocols. Ultimately, a vandalism and property destruction model can help protect people and property, reduce costs associated with damage, and promote a safer and more secure society. We need a vandalism and property destruction model to help prevent and mitigate damage caused by these types of incidents. </p> <p>Technically, vandalism is described as a video event that is instantiated by a video object that inflicts temporally consistent static changes (such as damage) inside a preset restricted region that is purportedly left unaltered by normal (i.e., legal) interaction with video objects.</p>"},{"location":"scenarios/vandalism/#visionai-based-monitoring","title":"VisionAI Based Monitoring","text":""},{"location":"scenarios/vandalism/#vandalism","title":"Vandalism","text":"<p>VisionAI based Monitoring is an effective approach to investigate if the site has temporally  consistent and significant static changes, indicative of damage, when an object is detected departing such a place. A vandalism event is declared and the vandals are located if there are such changes and given that the site is typically unaltered following legal use. The proposed method has a 96% detection rate when applied to video clips of actual and simulated vandalism in action. It recognises several types of vandalism, including theft and graffiti, and it can deal with abrupt illumination changes, occlusions, and segmentation mistakes. The frame rate of the suggested approach is 13 frames per second.</p>"},{"location":"scenarios/vandalism/#constraints","title":"Constraints","text":"<p>The automatic detection of vandalism in video surveillance is a challenging task because of: - The complex and unpredictable nature of a vandalism act and the speed at which it may occur - The underlying difficulty of finding a unique definition for vandalism which may vary based on social contexts and applications - The difficulty in distinguishing between normal and vandal interaction between persons and vandalism-prone objects or sites and - The lack of real vandalism test video sequences publicly available for training or testing.</p>"},{"location":"scenarios/vandalism/#proposed-method-for-detection-of-vandalism","title":"Proposed Method for detection of vandalism","text":"<p>A video object refers to a temporally consistent region (over a short period)in a video sequence. Video objects have spatio-temporal features such as contour,area, motion, and trajectory. For example, a video object has a unique identifier (ID) maintained by the tracking algorithm during the life-time of an object in the videosequence. A video event is an interpreted spatio-temporal relationship associating one or multiple objects (e.g., moving, staying long and is inside). Video events have information associated with them such as the IDs of the video objects involved in the event, the time at which it is detected, and its duration which is the number of consecutive frames the event is detected.We only consider rigid vandalism-prone objects that do not change over time.This includes pay-phones, vending machines, and paying stations in parking lots.</p> <p>For example, vandalism of electronic street signs switching content periodically is not considered. Also, we expect that the vandalism act alters the normal appearance of objects. Meaning, after the site is vandalized, there is visible damage (i.e., change) to the site. We use video object segmentation and ID tracking.</p>"},{"location":"scenarios/vandalism/#graffiti","title":"Graffiti","text":"<p>Graffiti can have a negative effect on a community's property value and tourism. Moreover, it may cause a decline in retail sales and an increase in public dread, both of which might drain tax funds intended for prevention. </p> <p>The Graffiti Image classifier can help law enforcement more effectively recognise Graffiti Images on the streets in order to lessen damage.</p> <p>VisionAI based solution is focused on improving the performance of Graffiti \u201cclassifier\u201d using the ResNet50 neural network by tuning parameters like Learning Rate, Batch Size and identifying the best freezing layer.</p>"},{"location":"scenarios/vandalism/#model-details","title":"Model Details","text":""},{"location":"scenarios/vandalism/#dataset","title":"Dataset","text":"<p>The dataset consists of images and videos collected from various sources. </p>"},{"location":"scenarios/vandalism/#model-card","title":"Model card","text":"Dataset size Version Camera support Precision Recall mAP 4126 v1 Both(Ceiling and Straight) 95.0%  78.6%  91.0%"},{"location":"scenarios/vandalism/#scenario-details","title":"Scenario details","text":"<p>The business logic for this scenario is as follows:</p> <ul> <li> <p>We use existing camera feeds from the premises to monitor an area or property in real-time, detecting any instances of vandalism or destruction as they occur.</p> </li> <li> <p>VisionAI system is able to run on edge devices. It uses camera feeds for processing.</p> </li> <li> <p>When instances of vandalism or destruction is detected, an alert will be raised.</p> </li> </ul> Test now with online Web-CamWith RTSP Camera - PipelinesWith Azure Setup <p>To test this model &amp; scenario, you can use the following steps:</p> <ul> <li> <p>Install the visionai package from PyPI</p> <pre><code>$ pip install visionai\n</code></pre> </li> <li> <p>Test the scenario from your local web-cam</p> <pre><code>$ visionai scenario test vandalism-graffiti-detection\n\nDownloading models for scenario: vandalism-graffiti-detection\nModel: vandalism-graffiti-detection: https://workplaceos.blob.core.windows.net/models/yolov5s-vandalism-graffiti-detection/yolov5s-vandalism-graffiti-detection-0.0.1.zip\n\n\nStarting scenario: vandalism-graffiti-detection..\n</code></pre> </li> <li> <p>You should be able to see the events generated on your console window with graffiti vandalism being detected within the camera field of view.</p> </li> </ul> <p>[TODO]</p> <p>VisionAI app is available at a Azure Market place, one can download and use it by following steps mentioned here</p>"},{"location":"scenarios/vandalism/#features","title":"Features","text":"<p>The VisionAI solution is the most efficient way of implementing this scenario, as evidenced by the following features:</p> <ul> <li> <p>Prediction: Our vandalism graffiti detection model uses data and historical patterns to predict when and where vandalism and destruction might occur. For example, it can analyze patterns of past vandalism incidents to predict where future incidents might occur.</p> </li> <li> <p>Real-time monitoring: Vandalism graffiti detection model can continuously monitor an area or property in real-time, detecting any instances of vandalism or destruction as they occur. This allows for a rapid response and intervention.</p> </li> <li> <p>Automated alerts: Alerts can automatically be generated to authorities or property owners when incidents of vandalism or destruction are detected. This can help to improve response times and prevent further damage.</p> </li> </ul>"},{"location":"scenarios/vandalism/#training-with-custom-data","title":"Training with custom data","text":"<p>The scenario is provided as part of our GPL-v3 package for VisionAI. If you wish to train this with custom datasets, please contact us and we can provide you with the training code. You can do custom training with your own datasets for free, as long as it complies with GPLv3 license (you give back the code to the community). If you are interested in a custom license, please contact us.</p>"},{"location":"scenarios/vandalism/#contact-us","title":"Contact Us","text":"<ul> <li> <p>For technical issues, you can open a Github issue here</p> </li> <li> <p>For business inquiries, you can contact us through our website</p> </li> </ul>"},{"location":"scenarios/worker-health-and-safety/","title":"Worker Health and Safety","text":"<p>Workplace injuries are a growing concern for employers and employees. In 2021, the US recorded 5,190 fatal work injuries, with the private sector alone reporting 2.6 million non-fatal injuries. These numbers highlight the need for companies to prioritize workplace safety and implement measures to prevent injuries. Unsafe workplace environments not only result in injuries and fatalities but also account for downtime, reduced productivity, increased healthcare costs, and legal fines.</p> <p>Despite advancements in safety equipment and protective gear, injuries still occur due to non-compliance with protocols and Standard Operating Procedures (SOPs). Therefore, employers are responsible for providing up-to-date safety gear and equipment and ensuring their correct usage and compliance. This should involve live monitoring and enforcing adherence to established protocols and SOPs. By taking these measures, employers can effectively mitigate workplace hazards and prevent injuries from occurring.</p> <p>Establishing protocols and guidelines and providing safety gear might not seem difficult, but ensuring that every individual is consistently complying is challenging. A lapse in compliance and usage of protective equipment (PPE), even for a short duration, can result in a workplace accident. Therefore, you need a mechanism to ensure everyone complies and adheres to guidelines. But the question is, how do you do it?</p>"},{"location":"scenarios/worker-health-and-safety/#eliminate-occupational-hazards-with-visionifys-workplace-health-and-safety-suite","title":"Eliminate Occupational Hazards with Visionify\u2019s Workplace Health and Safety Suite","text":"<p>Leverage Fully Automated, Vision AI-based real-time Detection and Monitoring systems for different workplace scenarios and eliminate occupational hazards and injury risks. Stay on top of the situation with instant alerts and notifications that allow for quick response and resolution of any potential safety concerns, ensuring the well-being of your employees and promoting a culture of safety within your organization. Our next-gen Vision AI models Pre-trained can be deployed instantly to work with any existing camera infrastructure.</p> <p>What\u2019s included in this suite:</p> <ul> <li>PPE Detection </li> <li>Slip and Fall Detection </li> <li>Working at Heights </li> <li>Environment monitoring</li> <li>Slip, trip and fall detection</li> <li>Posture &amp; Ergonomics</li> <li>Empty pallets</li> <li>Spills &amp; Leaks detection</li> <li>Hand-wash</li> <li>Confined spaces monitoring</li> </ul>"},{"location":"scenarios/working-at-heights/","title":"Working at Heights","text":"<p>Ensure the safety of employees at workplace.</p> <p> </p> Events: Working at heights"},{"location":"scenarios/working-at-heights/#overview","title":"Overview","text":"<p>Working at heights poses significant risks, including serious injuries or fatalities. Vision AI offers a robust solution to enhance workplace safety by preventing falls and ensuring compliance with safety regulations. Our system provides real-time monitoring and alerts, enabling timely interventions and reducing the risk of accidents.</p>"},{"location":"scenarios/working-at-heights/#what-our-solution-can-detect","title":"What our solution can detect","text":"<ul> <li>Climbing/Restricted Height: Is the person climbing or above a restricted height.</li> <li>Harness usage: Is the person wearing a harness if above a restricted height.</li> <li>No Safety Shoes: Is the person not wearing safety shoes.</li> <li>No Helmet: Is the person not wearing a helmet.</li> <li>No Fall Arrest System: Is the person not wearing a fall arrest system.</li> </ul>"},{"location":"scenarios/working-at-heights/#key-benefits","title":"Key Benefits","text":"<ul> <li>24x7 Monitoring: Utilize existing camera feeds to continuously monitor work environments for potential incidents.</li> <li>Real-time Alerts: Enable real-time alerts through Text, Mobile App notification when an incident is observed. </li> <li>High Accuracy: Our AI model is trained on diverse real-world scenarios, minimizing them robust and reducing false positives.</li> <li>Compliance Increase: Our solution is able to increase compliance by 85% at the workplace.</li> </ul>"},{"location":"scenarios/working-at-heights/#how-it-works","title":"How It Works","text":"<ul> <li>Hybrid or On-Prem Deployments: VisionAI supports On-prem, Hybrid, and Cloud options for deployment.</li> <li>Edge Device Compatibility: Vision AI operates efficiently on edge devices, processing camera feeds locally to detect human poses and identify slip and fall accidents.</li> <li>Scalable Solution: Easily integrate with existing infrastructure to provide comprehensive safety coverage across multiple sites.</li> </ul>"},{"location":"scenarios/working-at-heights/#next-steps","title":"Next Steps","text":"<ul> <li>Quick Start</li> <li>Camera Placement Guide</li> <li>Supported Scenarios</li> <li>Camera Management</li> <li>FAQs</li> </ul>"},{"location":"scenarios/working-at-heights/#contact-us","title":"Contact Us","text":"contact_phone Sales Inquiries <p>Contact our sales team for tailored solutions and pricing information.</p> <ul> <li>Email: sales@visionify.ai</li> <li>Phone: +1 720-449-1124</li> </ul> support_agent Technical Support <p>Access our support portal or reach out to our technical team for assistance.</p> <ul> <li>https://support.visionify.ai</li> <li>support@visionify.ai</li> </ul> calendar_month Schedule a Demo <p>Experience Vision AI in action with a personalized demo from our team.</p> event                 Book Your Demo"}]}